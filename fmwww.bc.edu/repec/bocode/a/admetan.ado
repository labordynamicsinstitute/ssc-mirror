* admetan.ado
* "Aggregate-data" meta-analysis, including two-stage IPDMA if called from ipdmetan.ado

* originally written by David Fisher, June 2013

* version 1.0  David Fisher  31jan2014

*! version 2.0  David Fisher  11may2017
* Major update to extend functionality beyond estimation commands; now has most of the functionality of -metan-
//  - Reworked so that ipdmetan.ado does command processing and looping, and admetan.ado does RE estimation (including -metan- functionality)
//  - Hence, ipdover calls ipdmetan (but never admetan); ipdmetan calls admetan (if not called by ipdover); admetan can be run alone.
//      Any of the three may call forestplot, which of course can also be run alone.

* Notes on version 2.0:

* On the logic of "summstat", "method" and "re_model"
// Construction of _ES and _seES from raw data (`method') can be done as follows:
//  - Generic (i.e. _ES and _seES are supplied by user)
//  - Peto OR (count data)
//  - Non-Peto OR/RR/RD (count data)
//  - Logrank HR (O-E & V)
//  - WMD/Cohen/Glass/Hedges (continuous data)
// Meanwhile, the only options for *pooling* (`re_model', `vce_model') are M-H, fe and re.
// Hence, if `method' = peto, logrank, cohen, glass or hedges, we can also specify random-effects.

* So, valid combinations of options are as follows (with separate `breslow' and `logrank' options):
//																				`summstat'		`method'			`re_model'
// If M-H, then M-H heterogeneity and no RE (i.e. M-H pooling)					or/rr/rd		mh					mh
// If random-effects and count data (peto only if OR):							or/rr/rd		mh/iv/peto			re
// But if specifically FE I-V then cannot be M-H het							or/rr/rd		iv/peto				fe
// If Peto/logrank, then Peto heterogeneity but can also have RE				hr				iv/peto (+logrank)	fe/re
// If Cohen/Glass/Hedges, then Cochran heterogeneity but can also have RE		wmd/smd			cohen etc.			fe/re

* On the classification of random-effects methods:
//  - tausq estimation methods:	     dl/dlb/mp/vc/sj2s/b0/bp/ml/reml
//  - "variance inflation" methods:  hk/kr/bs/ivh/fv (uses `vce_model')
//  - other methods:				 pl/sa/qe
// (of which hk/dlb/ivh/qe/fv/sj2s require an initial estimate of tausq, typically D-L)

* Note: in version 2.0, some RE methods have suboptions
//  - using the syntax "re([re_model], [options])"
//  - Doi's Quality Effects model now added

* Other things to note:
//  - Now that _ES _seES are not necessarily generated by estimation commands, the ad() option has been generalised.
//    Instead of IPD+AD, it's more like "dataset of type 1" + "dataset of type 2", e.g. _ES _seES in one, a b c d (2x2) in the other.
//  - Corrected error whereby tausq could not be found by iterative methods if >> 0
//    due to assumptions based on me mostly using ratio statistics, where tausq < 1, and not mean differences where tausq can be any magnitude.


program define admetan, rclass

	version 11.0
	local version : di "version " string(_caller()) ":"
	
	syntax varlist(min=2 max=6 numeric) [if] [in] [, ///
		STUDY(string) LABEL(string) BY(string) BYAD SORTBY(passthru) NPTS(varname numeric) ///
		CItype(string) /*INTERaction*/ WGT(varname numeric) ZTOL(passthru) ///
		noKEEPVars noRSample noINTeger FORESTplot(string asis) ///
		AD(string asis) * ]
	
	local invlist `"`varlist'"'		// list of "original" vars passed by the user to the program 
	local params : word count `invlist'
	
	marksample touse, novarlist		// `novarlist' option so that entirely missing/nonexistent studies/subgroups may be included
	

	** Process outcome measure summary statistics (summstat) and methods of deriving _ES and _seES
	if `"`options'"'!=`""' {

		// -cc- and -nocc- (N.B. need to do this now, as otherwise the options will conflict later)
		local 0 `", `options'"'
		syntax [, CC(string) * ]
		local yescc `"`cc'"'
		local 0 `", `options'"'
		syntax [, noCC * ]
		if `"`cc'"'!=`""' & `"`yescc'"'!=`""' {
			if `"`yescc'"'!=`"0"' {
				disp as err `"Cannot specify both {bf:cc()} and {bf:nocc}; please choose one or the other"'
				exit 198
			}
			else local cc `"cc(0)"'
		}
		else {
			if `"`yescc'"'!=`""' {
				confirm number `yescc'
			}
			local cc = cond(`"`cc'"'!=`""', `"cc(0)"', cond(`"`yescc'"'!=`""', `"cc(`yescc')"', `""'))	// "`cc'"=="" if not supplied by user
		}																								// will default to 0.5 later, if appropriate
	
		// METHODS of analysis for AD (*can* be passed from ipdmetan)
		// (N.B. random-effects methods are dealt with in MainRoutine)
		local 0 `", `options'"'
		syntax [, FE IV LOGRank MH PETO COHen GLAss HEDges noSTANdard BREslow COCHranq IVQ CHI2 CORnfield EXact WOolf * ]
		
		// for clarity: `chi2opt' is the option (on/off); `chi2' will later hold the value itself
		local chi2opt `chi2'
		local chi2
		
		* Parse, and quickly check, "method" options explicitly supplied in the command line
		// (more detailed checking, and assigning of defaults if necessary, will be done later by ProcessInputVarlist)
		local iv = cond("`fe'`ivq'`cochranq'"!="", "iv", "`iv'")			// synonyms
		opts_exclusive `"`iv' `mh' `peto' `cohen' `glass' `hedges' `standard'"' `""' 184
		local method `"`iv'`mh'`peto'`cohen'`glass'`hedges'`standard'"'
		
		macro drop fe iv /*mh*/ peto cohen glass hedges standard cochranq ivq
		// N.B. don't drop `mh' yet; needed later to test for M-H and RE being simultaneously requested by user
	}
	
	
	** Original AD data is in memory (not processed by -ipdmetan-; i.e. no `ipdfile')
	local 0 `", `options'"'
	syntax [, IPDMETAN2 IPDMETAN(string) * ]
	if !missing(`"`ipdmetan'"') {
		local options2 `"`options'"'
		local 0 `", `ipdmetan'"'
		syntax, [IPDFILE(string asis) *]
		local options `"`options2'"'		// the rest of the ipdmetan() options will be parsed later
	}
	else if !missing(`"`ipdmetan2'"') local ipdmetan ipdmetan	// non-missing `ipdmetan' implies "-ipdmetan- was run" (albeit possibly on AD) ...	
	
	// `newstudy' and `newby' may be needed to replace string variables,
	//  either here (if original AD in memory) or in an `ADfile', so declare them now (i.e. outside of any loops/clauses)
	if `"`ipdfile'"'==`""' | `"`ad'"'!=`""' {
		tempname newstudylab newbylab
		tempvar  newstudy    newby
	}

	if `"`ipdfile'"'==`""' {									// ... while non-missing `ipdfile' implies "processed by -ipdmetan-" (i.e. definitely not AD).
		if `"`invlist'"'==`""' {								// ==> this section of code deals with "AD only" data;
			nois disp as err `"{it:varlist} not supplied"'		// ==> either -admetan- was the original command, or -ipdmetan- with one obs per study.
			exit 111
		}
		qui count
		local origN = r(N)
		
		// Process -eform- options for admetan
		cap nois MyGetEFormOpts, `options'
		if _rc {
			if _rc==1 disp as err "User break"
			else disp as err `"Error in {bf:admetan.MyGetEFormOpts}"'
			c_local err "noerr"		// tell ipdmetan not to also report an "error in {bf:admetan}"
			exit _rc
		}
		local eform = cond(`"`r(eform)'"'!=`""', "eform", "")	// convert to simple on/off option
		local log         `"`r(log)'"'
		local summstat    `"`r(summstat)'"'
		local seffect     `"`r(effect)'"'		// N.B. `seffect' contains automatic effect text from -eform-; `effect' contains user-specified text
		local options_adm `"`r(options)'"'		// N.B. if passed from -ipdmetan-, this now contains contents of `options_ipdm'

	
		** If necessary, parse forestplot options to extract those relevant to admetan
		// N.B. Certain options may be supplied EITHER to admetan directly, OR as sub-options to forestplot()
		//  with "forestplot options" prioritised over "admetan options" in the event of a clash.
		
		// These options are:
		// -eform- options (plus extra stuff parsed by MyGetEformOpts e.g. `rr', `rd', `md', `smd', `wmd', `log')
		// nograph, nohet, nooverall, nosubgroup, nowarning, nowt
		// effect, hetstat (ovstat), lcols, rcols, plotid, ovwt, sgwt, sgweight
		// cumulative, efficacy, influence, interaction
		// counts, group1, group2 (for compatibility with metan.ado)
		// rfdist, rflevel (for compatibility with metan.ado)

		// N.B. this has already been done within -ipdmetan- if `"`ipdfile'"'!=`""'
		
		if trim(`"`forestplot'"') != `""' {
		
			ParseFPlotOpts, cmdname(`cmdname') `eform' `log' mainprog(admetan) summstat(`summstat') seffect(`seffect') ///
				mainopts(`options_adm') fplotopts(`forestplot')
			
			if _rc {
				if _rc==1 nois disp as err `"User break in {bf:admetan.ParseFPlotOpts}"'
				else nois disp as err `"Error in {bf:admetan.ParseFPlotOpts}"'
				c_local err "noerr"		// tell ipdmetan not to also report an "error in {bf:admetan}"
				exit _rc
			}
			
			local eform    `"`r(eform)'"'
			local log      `"`r(log)'"'
			local summstat `"`r(summstat)'"'
			local seffect  `"`r(seffect)'"'		// N.B. `seffect' contains automatic effect text from -eform-; `effect' contains user-specified text
			
			local options_adm `"`r(parsedopts)' `r(mainopts)'"'		// options as listed above, plus other options supplied directly to admetan
			local fplotopts   `"`r(fplotopts)'"'					// other options supplied as sub-options to forestplot() 
		}
		
		// Now parse options once more, if they are needed within -admetan- *before* passing to MainRoutine.
		// (any other options can simply be parsed by MainRoutine itself.)
		local 0 `", `options_adm'"'
		syntax [, noOVerall noSUbgroup noWT EFFect(string) LCols(string asis) RCols(string asis) SGWt SGWEIGHT ///
			CUmulative EFFIcacy INFluence INTERaction RFDist SAVING(string asis) * ]
		
		local sgwt = cond("`sgweight'"!="", "sgwt", "`sgwt'")			// sgweight is a synonym (for compatibility with metan.ado)
		local fplotopts = trim(itrim(`"`macval(fplotopts)' `wt'"'))		// add straight to fplotopts; not needed any more by admetan

		// Re-assemble options_adm for sending to MainRoutine
		// (though don't include any options that may be modified before MainRoutine is run!)
		// (i.e. the options below just need to be *consulted* in the meantime.)
		local options_adm = trim(`"`macval(options)' `cumulative' `efficacy' `influence' `interaction' `rfdist' `sgwt'"')
		if `"`lcols'"'!=`""' local options_adm `"`macval(options_adm)' lcols(`lcols')"'
		if `"`rcols'"'!=`""' local options_adm `"`macval(options_adm)' rcols(`rcols')"'
		if `"`saving'"'!=`""' local options_adm `"`macval(options_adm)' saving(`saving')"'
		
				
		** Parse `by'
		// N.B. do this before `study' in case `by' is string and contains missings.
		// Stata sorts string missings to be *first* rather than last.
		if `"`by'"'!=`""' {
			local 0 `"`by'"'
			syntax name [, Missing]		// only a single (var)name is allowed

			cap confirm var `namelist'
			if _rc {
				if `"`ad'"'==`""' {
					nois disp as err `"variable {bf:`namelist'} not found"'
					exit 111
				}
			}
			else {
				local _BY `namelist'		// `"`_BY'"'!=`""' is a marker of `by' being present in the current data
				if `"`missing'"'==`""' markout `touse' `_BY', strok
			}
		}
		
		** Now, parse `study'
		// label([namevar=namevar], [yearvar=yearvar]) is only for compatibility with metan.ado
		// and is not documented as part of the idpmetan/admetan package
		// [hence e.g. won't work with ad()]
		if `"`label'"'!=`""' {
			if `"`study'"'!=`""' {
				disp as err `"Cannot specify both {bf:label()} and {bf:study()}; please choose just one"'
				exit 198
			}
			
			// while loop taken directly from metan.ado by Ross Harris:
			tokenize "`label'", parse("=,")
			while "`1'"!="" {
				cap assert inlist(`"`1'"', "namevar", "yearvar")
				if _rc local rc = _rc
				else {
					cap confirm var `3'
					if _rc & `: word count `3''==1 {
						disp as err `"Variable {bf:`3'} not found in option {bf:label()}"'
						exit _rc
					}
					local rc = _rc
				}
				if `rc' {
					disp as err `"Syntax of option {bf:label()} is {bf:label(}[{bf:namevar}={it:namevar}]{bf:,} [{bf:yearvar}={it:yearvar}]{bf:)}"'
					exit _rc
				}
				local `1' "`3'"
				mac shift 4
			}
			
			// put name/year variables into appropriate macros
			if `: word count `namevar' `yearvar''==1 local study `namevar' `yearvar'
			else {
				tempvar study
				cap confirm string var `namevar'
				if !_rc local namestr `namevar'
				else {
					tempvar namestr
					cap decode `namevar', gen(`namestr')
					if _rc==182 qui gen `namestr' = string(`namevar')	// no value label
				}
				cap confirm string var `yearvar'
				if !_rc local yearstr `yearvar'
				else {
					tempvar yearstr
					cap decode `yearvar', gen(`yearstr')
					if _rc==182 qui gen `yearstr' = string(`yearvar')	// no value label
				}

				qui gen `study' = `namestr' + " (" + `yearstr' + ")"
				label variable `study' `"`: variable label `namevar'' (`: variable label `yearvar'')"'
				if "`namestr'"!="" & "`namestr'"!="`namevar'" {
					qui drop `namestr'
				}
				if "`yearstr'"!="" & "`yearstr'"!="`yearvar'" {
					qui drop `yearstr'
				}
			}
			local _STUDY `study'
		}

		// If `study' not supplied, start by assuming entire dataset is to be used
		// remove any observations with no (i.e. missing) data in `invlist'.
		// (code fragment taken from _grownonmiss.ado)
		if `"`study'"'==`""' {
			tokenize `invlist'
			tempvar g
			qui gen byte `g' = (`1'<.) if `touse'
			mac shift
			while "`1'" != "" {
				qui replace `g' = `g' + (`1'<.) if `touse'
				mac shift
			}
			qui replace `g' = . if `g' == 0		// set to missing for benefit of markout
			markout `touse' `g'
			drop `g'
		}
		else {
			local 0 `"`study'"'
			syntax varname [, Missing]			// only a single (var)name is allowed,
			local _STUDY `varlist'				// and it must exist in the data currently in memory
			if `"`missing'"'==`""' markout `touse' `_STUDY', strok
		}
		
		// N.B. `newby' and `newbylab' will only be needed if `by' is string
		cap nois ProcessLabels if `touse', ///
			study(`_STUDY') newstudy(`newstudy') newstudylab(`newstudylab') ///
			by(`_BY')       newby(`newby')       newbylab(`newbylab')
		
		if _rc {
			if _rc==1 nois disp as err `"User break in {bf:admetan.ProcessLabels}"'
			else nois disp as err `"Error in {bf:admetan.ProcessLabels}"'
			c_local err "noerr"		// tell ipdmetan not to also report an "error in {bf:admetan}"
			exit _rc
		}

		// if r(newstudy) was returned, use it if applicable
		// (N.B. if `study' not supplied by user, next preference is to use `lcols' if supplied,
		//        in which case `study' will continue to be undefined)
		local svarlab "Study"
		if `"`_STUDY'"'!=`""' {
			local studylab : value label `_STUDY'			// if `study' exists, use its value label (N.B. will be empty if string)
			local svarlab : variable label `_STUDY'			// and *original* variable label...
			local svarlab = cond(`"`svarlab'"'!=`""', `"`svarlab'"', `"`_STUDY'"')
		}													// ...but if r(newstudy) was returned, use new labels in preference
		if `"`_STUDY'"'!=`"`r(newstudy)'"' & `"`r(newstudy)'"'!=`""' ///
			& (`"`_STUDY'"'!=`""' | `"`lcols'"'==`""') {	// N.B. this part just means "if either `study' was either directly supplied...
															// ...or `lcols' is to be used as per deprecated -metan- syntax (see help metan)

			// If IPD+AD, we may also need to know if `study' was originally (i.e. in IPD) string: this is `ipdstr'
			if `"`ad'"'!=`""' {
				local ad `"`ad' ipdstr"'
			}
												
			local _STUDY `r(newstudy)'
			local studylab = cond(`"`r(newstudylab)'"'!=`""', `"`r(newstudylab)'"', `"`studylab'"')
			label values `_STUDY' `studylab'				// apply labels to *new* study var
		}
		if `"`_STUDY'"'!=`""' label variable `_STUDY' `"`svarlab'"'
		
		// same logic now applies to `by'
		if "`_BY'"!=`""' {
			local bylab : value label `_BY'					// if `by' exists, use its value label (N.B. will be empty if string)
			local byvarlab : variable label `_BY'			// and variable label...
			local byvarlab = cond(`"`byvarlab'"'!=`""', `"`byvarlab'"', `"`_BY'"')
		}													// ...but if r(newby) was returned, use new labels in preference
		if `"`_BY'"'!=`"`r(newby)'"' & `"`r(newby)'"'!=`""' {
			local _BY `r(newby)'
			local bylab = cond(`"`r(newbylab)'"'!=`""', `"`r(newbylab)'"', `"`bylab'"')
			label values `_BY' `bylab'						// apply labels to *new* by var
		}
		if "`_BY'"!=`""' label variable `_BY' `"`byvarlab'"'
		
		// Set to default `invlist' if not supplied
		tempvar _USE
		qui gen byte `_USE' = 1 if `touse'		// N.B. `_USE' only defined iff `touse'
												// in other words, !missing(`_USE') <==> `touse'

		// Now process the `invlist' to finalise `summstat' and `method'
		cap nois ProcessInputVarlist `_USE' `invlist' if `touse', summstat(`summstat') method(`method') ///
			`log' `logrank' `breslow' `cc' `chi2opt' `cornfield' `exact' `woolf' `integer' `level' `ztol'

		if _rc {
			if _rc==2000 nois disp as err "No studies found with sufficient data to be analysed"
			else if _rc==1 nois disp as err `"User break in {bf:admetan.ProcessInputVarlist}"'
			else nois disp as err `"Error in {bf:admetan.ProcessInputVarlist}"'
			c_local err "noerr"		// tell ipdmetan not to also report an "error in {bf:admetan}"
			exit _rc
		}

		local seffect = cond(`"`seffect'"'!=`""', `"`seffect'"', `"`r(effect)'"')	// don't override user-specified value
		local summstat `"`r(summstat)'"'
		local method   `"`r(method)'"'
		local switchoff `"`r(switchoff)'"'
		
		// If `params'==4, default to eform unless Risk Diff.
		local eform = cond(`params'==4 & `"`log'"'==`""' & `"`summstat'"'!=`"rd"', `"eform"', `"`eform'"')
				
		// Process "npts(varname)": only permitted with 2- or 3-element varlist AD;
		// that is, "ES, seES", "ES, LCI, UCI", or "OE, V"
		// (N.B. "varname numeric" already established)
		if `"`npts'"'!=`""' {
			if `params' > 3 {
				nois disp as err `"Note: {bf:npts(}{it:varname}{bf:)} syntax only valid with generic inverse-variance model or with logrank (O-E & V) HR"'
				exit 198
			}
			else {
				if "`integer'"=="" {
					cap assert int(`npts')==`npts' if `touse'
					if _rc {
						nois disp as err `"Non-integer counts found in {bf:npts()} option"'
						exit _rc
					}
				}
				local _NN `npts'
				local options_adm `"`macval(options_adm)' npts"' 	// send simple on/off option to MainRotuine
			}														// (for saved dataset and/or forestplot)
		}
					
		// Generate _rsample (unless `norsample'): this is the only permanent change to the data in this section of code
		local oldrsample = 111
		if "`rsample'"==`""' {
			cap confirm var _rsample
			local oldrsample = _rc					// whether or not a variable named _rsample already existed
		
			cap drop _rsample
			qui gen long _rsample = `_USE'==1		// this will show which observations were used
		}
	}		// end if `"`ipdfile'"'==`""'

	
	** Processed data from ipdmetan are in memory (either first stage of two-stage "estimation model" MA, or processed "raw data")
	// Data should already be in the correct format, and all data is to be used (`touse' is not present yet, but would be 1 throughout if it were).
	// `method' may not yet be defined, but `summstat' definitely should
	else {

		// quick checks
		confirm numeric var _USE
		confirm numeric var _STUDY
		assert !missing(_USE)
		local _USE "_USE"
		local _STUDY "_STUDY"

		cap confirm numeric var _BY
		local _BY = cond(!_rc, "_BY", "")

		cap confirm numeric var _NN
		local _NN = cond(!_rc, "_NN", "")

		// Check outcome measures passed from ipdmetan alone -- should be passed in summstat()
		// Therefore if the following error messages are seen, it suggests a bug rather than user error
		cap nois MyGetEFormOpts, `options'
		if !_rc {
			cap assert `"`r(summstat)'"'==`""'
			if _rc {
				nois disp as err `"Error in communication between {bf:ipdmetan} and {bf:admetan}"'
				exit _rc
			}
		}
		local eform = cond(`"`r(eform)'"'!=`""', "eform", "")	// convert to simple on/off option
		local log `"`r(log)'"'

		// Now parse options to find those that are needed within -admetan- *before* passing to MainRoutine.
		// (any other options can simply be parsed by MainRoutine itself.)
		local 0 `", `r(options)'"'
		syntax [, noOVerall noSUbgroup noWT EFFect(string) LCols(string asis) RCols(string asis) SGWt SGWEIGHT ///
			CUmulative EFFIcacy INFluence INTERaction RFDist SAVING(string asis) * ]

		local sgwt = cond("`sgweight'"!="", "sgwt", "`sgwt'")			// sgweight is a synonym (for compatibility with metan.ado)
		local fplotopts = trim(itrim(`"`macval(fplotopts)' `wt'"'))		// add straight to fplotopts; not needed any more by admetan

		// Re-assemble options_adm for sending to MainRoutine
		// (though don't include any options that may be modified before MainRoutine is run!)
		// (i.e. the options below just need to be *consulted* in the meantime.)
		local options_adm = trim(`"`macval(options)' `cumulative' `efficacy' `influence' `interaction' `rfdist' `sgwt'"')
		if `"`lcols'"'!=`""'  local options_adm `"`macval(options_adm)' lcols(`lcols')"'
		if `"`rcols'"'!=`""'  local options_adm `"`macval(options_adm)' rcols(`rcols')"'
		if `"`saving'"'!=`""' local options_adm `"`macval(options_adm)' saving(`saving')"'		
		
		// Parse options passed through from -ipdmetan-
		local 0 `", `ipdmetan'"'
		syntax, CMDSTRUC(string) ///
			[IPDFILE(string asis) SUMMSTAT(string) ESTVAR(passthru) LRVLIST(passthru) EXTRALINE ]

		local options_adm = trim(`"`macval(options_adm)' `estvar' `lrvlist' `extraline'"')	// to pass on to MainRoutine
		local fplotopts = trim(`"`forestplot'"')			// to match with AD code
		local ipdmetan ipdmetan								// henceforth `ipdmetan' is a simple on/off option
			
		if "`cmdstruc'"=="generic" {
			local params = 2
			local method = cond("`method'"=="", "iv", "`method'")	// this is otherwise done by ProcessInputVarlist
		}
		else {		// N.B. no need for if `touse' since already processed by -ipdmetan-
			cap nois ProcessInputVarlist `_USE' `invlist', summstat(`summstat') method(`method') ///
				`log' `logrank' `breslow' `cc' `chi2opt' `cornfield' `exact' `woolf' `integer' `level' `ztol'
			
			if _rc {
				if _rc==2000 nois disp as err "No studies found with sufficient data to be analysed"
				if _rc==1 nois disp as err `"User break in {bf:admetan.ProcessInputVarlist}"'
				else nois disp as err `"Error in {bf:admetan.ProcessInputVarlist}"'
				c_local err "noerr"		// tell ipdmetan not to also report an "error in {bf:admetan}"
				exit _rc
			}
			
			local summstat  `"`r(summstat)'"'
			local method    `"`r(method)'"'
			local switchoff `"`r(switchoff)'"'

		}	// end else (i.e. if "`cmdstruc'"=="specific")
	}
	
	
	** Process `adfile'
	// N.B. Within this section, "IPD" refers to data already in memory, and "AD" to the data referred to in the ad() option.
	// (even if the "IPD" is also, in fact, aggregate)
	
	// "estimation command" file from ipdmetan will contain _USE, _STUDY, _ES, _seES, _NN (+ optional _BY)
	// "raw data" file from ipdmetan will contain _USE, _STUDY (+ optional _BY) + `invlist' (+ optional _NN if logrank)
	// aggregate data from admetan will contain `_USE', `study', `invlist' (+ optional `by', _NN)
	
	// use locals `_STUDY', `_BY' to refer to *current* vars in memory (whether AD "`study'" or IPD "_STUDY")
	// and locals `study', `by' to refer to vars originally specified by user, ==> found in "ad()" dataset?

	if `"`ad'"'!=`""' {

		// -ipdmetan- must have been the originally-run program; if not, exit with error
		if `"`ipdmetan'"'==`""' {
			disp as err `"Cannot use {bf:ad()} option with {help admetan}; please use {help ipdmetan} instead"'
			exit 198
		}
		
		// Declare tempvars, if required:
		//  - `adtouse' (need to get this back from ProcessAD in order to reset main `touse' if necessary)
		//  - recycle previously-declared tempvars `newstudy' and `newby' for use with AD
		//  - use _SOURCE to store source of data (IPD or AD).
		tempvar adtouse _SOURCE
		local tvlist `"`newstudy' `newby' `_SOURCE'"'
		local uselist `"`_USE' `_STUDY' `_BY'"'

		cap nois ProcessAD if `touse', ad(`ad') adtouse(`adtouse') ipdfile(`ipdfile') wgt(`wgt') `eform' `log' `sortby' ///
			summstat(`summstat') method(`method') `mh' `logrank' `breslow' `cc' `cornfield' `exact' `woolf' `integer' `chi2opt' `ztol' ///
			by(`by') `byad' study(`study') invlist(`invlist') uselist(`uselist') npts(`npts') tvlist(`tvlist') lrcols(`lcols' `rcols')
		
		if _rc {
			if _rc==2000 {
				disp as err `"Note: No valid observations in aggregate dataset; {bf:ad()} will be ignored"'
				local ad
			}
			else {
				if `"`err'"'==`""' {
					if _rc==1 nois disp as err `"User break in {bf:admetan.ProcessAD}"'
					else nois disp as err `"Error in {bf:admetan.ProcessAD}"'
				}
				c_local err "noerr"		// tell ipdmetan not to also report an "error in {bf:admetan}"
				exit _rc
			}
		}
		local ad = cond(`"`ad'"'==`""', "", "ad")		// henceforth `ad' is a simple on/off option

	}	// end if `"`ad'"'!=`""'
	
	// start again in case `ad' has been switched off
	if `"`ad'"'!=`""' {

		local overall  = cond(`"`overall'"'==`""', `"`r(overall)'"',  `"`overall'"')
		local summstat = cond(`"`sumstat'"'==`""', `"`r(summstat)'"', `"`summstat'"')
		local effect   = cond(`"`effect'"'==`""',  `"`r(effect)'"',   `"`effect'"')
		
		local _NN  = cond(`"`_NN'"'==`""', `"`r(npts)'"', `"`_NN'"')
		local wgt  = cond(`"`wgt'"'==`""', `"`r(wgt)'"',  `"`wgt'"')

		if `"`npts'"'==`""' & `"`r(npts)'"'!=`""' {
			local options_adm `"`macval(options_adm)' npts"' 	// convert to simple on/off option to send to MainRoutine
		}														// (for saved dataset and/or forestplot)

		if `"`_BY'"'==`""' local _BY `r(by)'
		else assert `"`r(by)'"'==`"`_BY'"'
				
		local adinvlist `"`r(invlist)'"'
		local ADfile `"`r(adfile)'"'
		local adlogrank `r(logrank)'	
		local method `r(method)'
		local adswitchoff `"`r(switchoff)'"'
		local ad_iv `r(ad_iv)'	
		local byad `r(byad)'
		local eform `r(eform)'
		local log `r(log)'

		local options_adm `"`macval(options_adm)' source(`_SOURCE')"'		
		
	}	// end if `"`ad'"'!=`""'
	
	// Switch off incompatible options
	if trim(`"`switchoff'"')!=`""' {
		foreach opt of local switchoff {
			local `opt'
		}
	}
	if trim(`"`adswitchoff'"')!=`""' {
		foreach opt of local adswitchoff {
			local `opt'
		}
	}
	
	// Validity of names in lcols/rcols -- cannot be any of the names admetan.ado uses for other things
	// (N.B. already done by -ipdmetan- if `"`ipdfile'"'!=`""')
	if `"`ipdfile'"'==`""' & trim(`"`lcols'`rcols'"')!=`""' & `"`saving'"'!=`""' {
		local badnames `"_ES _seES"'
		if `"`_STUDY'"'!=`""'   local badnames `"`badnames' _STUDY"'
		if `"`_BY'"'!=`""'      local badnames `"`badnames' _BY"'
		if `"`_SOURCE'"'!=`""'  local badnames `"`badnames' _SOURCE"'
		if `"`_NN'"'!=`""'      local badnames `"`badnames' _NN"'
		if `"`cumulative'`influence'"'!=`""' local badnames `"`badnames' _Q _sigmasq _tausq"'
		if `"`rfdist'"'!=`""'   local badnames `"`badnames' _rfLCI _rfUCI"'
		if `"`efficacy'"'!=`""' local badnames `"`badnames' _VE"'
		if `"`counts'"'!=`""'   local badnames `"`badnames' _counts1 _counts1msd _counts0 _counts0msd"'
		if `"`oev'"'!=`""'      local badnames `"`badnames' _OE _V"'

		local lrcols `lcols' `rcols'
		local badnames : list lrcols & badnames
		if `"`badnames'"'!=`""' {
			local badname1 : word 1 of `badnames'
			disp as err `"Variable name {bf:`badname1'} in {bf:lcols()} or {bf:rcols()} is reserved for use by the {bf:ipdmetan} package"'
			disp as err `"In order to save the results set, please rename this variable or use {help clonevar}."'
			exit 101
		}
		
		// bad (value) *label* names: just _BY, _STUDY, _SOURCE as applicable
		foreach v of local lrcols {
			local lrlab : value label `v'
			if `"`lrlab'"'!=`""' {
			
				// allowed to have same value label name *only if* a clone in terms of observations
				local check
				if `"`_BY'"'!=`""' {
					local check = (`v'==_BY     & `"`lrlab'"'==`"`: value label `_BY''"')
				}
				if `"`check'"'==`""' & `"`_STUDY'"'!=`""' {
					local check = (`v'==_STUDY  & `"`lrlab'"'==`"`: value label `_STUDY''"')
				}
				if `"`check'"'==`""' & `"`_SOURCE'"'!=`""' {
					local check = (`v'==_SOURCE & `"`lrlab'"'==`"`: value label `_SOURCE''"')
				}
				
				if `check' {
					disp as err `"Label name {bf:`lrlab'} attached to variable {bf:`v'} in {bf:lcols()} or {bf:rcols()}"'
					disp as err `"  is reserved for use by the {bf:ipdmetan} package"'
					disp as err `"In order to save the results set, please rename the label attached to this variable."'
					exit 101
				}
			}
		}
	}

	
	* Setup `tvlist' = list of elements of `outvlist' that need to be generated as tempvars
	// N.B. need to take into account `ADfile' data
	//   _ES, _seES etc. might already exist in the `ADfile', in variable names stored in `adinvlist'
	// so, something like: if ADfile data is "iv" & !"logrank" (i.e. params=2 representing _ES and _seES),
	//    then point `_ES', `_seES' etc to the existing vars.
	// o/w, proceed as normal

	// N.B. we are already ensuring that any overlapping elements in `invlist' and `outvlist' point to the same actual vars
	
	// `ad_iv' or `ipd_iv' 									==> _ES
	// (`ipd_iv' & `params'==2) | (`ad_iv' & `adparams'==2)	==> _ES, _seES
	// (`ipd_iv' & `params'==3) | (`ad_iv' & `adparams'==3)	==> _ES, _LCI, _UCI
	
	local tvlist											// clear macro
	local adparams : word count `adinvlist'
	local ipd_iv = cond(inlist(`params', 2, 3)  & "`logrank'"=="",  "ipd_iv", "")
	tokenize `invlist'

	if "`ipd_iv'"!="" {
		if `params'==2 & "`logrank'"=="" {					// method is I-V with...
			args _ES _seES									// ...`_ES' and `_seES' supplied
			if "`ad_iv'"!="" & `"`adparams'"'==`"3"' {		// ("3" as string, since `adparams' may not exist)
				tokenize `adinvlist'
				args _ES _LCI _UCI							// ...and `_LCI', `_UCI' supplied by AD
			}
			else local tvlist `"_LCI _UCI"'					// ...else `_LCI', `_UCI' need to be created
		}
		else if `params'==3 {								// method is I-V with...
			args _ES _LCI _UCI								// ...ES, LCI and UCI supplied
			if "`ad_iv'"!="" & `"`adparams'"'==`"2"' {		// ("2" as string, since `adparams' may not exist)
				tokenize `adinvlist'
				args _ES _seES								// ...and `_seES' supplied by AD
			}
			else local tvlist `"_seES"'						// ...else `_seES' needs to be created
		}
		if `adparams'>3 & "`_NN'"=="" local tvlist `"`tvlist' _NN"'	// if AD not I-V/logrank, _NN will be available; hence create var if necessary
	}
		
	// Else, if IPD is not I-V, check whether AD is
	else if "`ad_iv'"!="" {
		tokenize `adinvlist'
		if `adparams'==3 {
			args _ES _LCI _UCI				// `_LCI', `_UCI' supplied by AD
			local tvlist `"_seES"'			// ...and `_seES' needs to be created
		}
		else {
			args _ES _seES					// `_seES' supplied by AD
			local tvlist `"_LCI _UCI"'		// ...and `_LCI', `_UCI' need to be created
		}
		if `params'>3 & "`_NN'"=="" local tvlist `"`tvlist' _NN"'	// if IPD not I-V/logrank, _NN will be available; hence create var if necessary
	}

	// else, neither are I-V, so must be compatible (either `params'>3 or logrank)
	else {
		local tvlist `"_ES _seES _LCI _UCI"'								// need to create everything
		if `"`adlogrank'`logrank'"'==`""' local tvlist `"`tvlist' _NN"'		// including _NN unless `logrank' (as that uses optional `npts')
	}
	
	// Finally, _WT always needs to be generated as tempvar
	local tvlist `"`tvlist' _WT"'
	
	* Create tempvars based on `tvlist'
	// and finally create `outvlist' = list of "standard" vars (_ES, seES, _LCI, _UCI, _WT, _NN) used by e.g. -forestplot-
	foreach tv of local tvlist {
		tempvar `tv'
		qui gen double ``tv'' = .
	}
	local outvlist `"`_ES' `_seES' `_LCI' `_UCI' `_WT' `_NN'"'
	
	
	* Setup `toprocess' (that is, `touse' for ProcessPoolingVarlist, within PerformMetaAnalysis)
	// Identifies non-IV part of the data, on which to run ProcessPoolingVarlist.
	// If AD is I-V and IPD not, `toprocess' = 1 if AD and 0 otherwise (i.e. if IPD)
	// If IPD is I-V and AD not, `toprocess' = 1 if IPD and 0 otherwise (i.e. if AD)

	if `"`ad'"'!=`""' {
		qui replace `adtouse' = `adtouse' * (`touse'!=1)	// no overlap
		qui count if `adtouse'
		if !r(N) {
			disp as err `"Note: No valid observations in aggregate dataset; {bf:ad()} will be ignored"'
			local ad
		}
		else {	
			qui replace `touse' = `touse' | `adtouse'

			// if only one or other is I-V but not both
			if (`"`ad_iv'"'!=`""') + (`"`ipd_iv'"'!=`""') == 1 {
				local inv2list = cond("`ad_iv'"!="", `"`invlist'"', `"`adinvlist'"')					// "non-IV" invlist
				local logrank =  cond("`ad_iv'"!="", `"`logrank'"', `"`adlogrank'"')					// "non-IV" logrank
				qui replace `adtouse' = `touse' * cond("`ad_iv'"!="", (`adtouse'!=1), (`adtouse'==1))	// this is now `toprocess'
				local options_adm `"`options_adm' toprocess(`adtouse') inv2list(`inv2list')"'
				
				local invlist  = cond("`ad_iv'"!="", `"`adinvlist'"', `"`invlist'"')					// I-V invlist				
			}
		}
	}
	
	* Other bits and bobs
	local effect = cond(`"`effect'"'!="", `"`effect'"', ///
		cond(`"`seffect'"'!=`""', `"`seffect'"', "Effect"))
	
	if `"`log'"'!=`""'         local effect `"log `effect'"'
	if `"`interaction'"'!=`""' local effect `"Interact. `effect'"'
	
	// Finalise citype
	if `"`citype'"'==`""' local citype `cornfield'`exact'`woolf'
	local citype = cond(inlist(`"`citype'"', `""', `"z"'), `"normal"', `"`citype'"')
	return local citype `"`citype'"'
	

	* Now, need to start making changes to the data
	// If AD, want to restore data if exit with error (incl. user break)
	// Hence, place all subsequent code into a subroutine, to be called with "capture noisily"
	
	// If IPD, data is already preserved.
	// So, only -preserve- if "AD only" in memory *and* -noRSample- is specified
	local keepvars = cond(trim(`"`rsample'`ipdfile'"')!=`""', "nokeepvars", "`keepvars'")	// -noRSample- or ipdfile implies -noKEEPVars-
	local ipdfile = cond(`"`ipdfile'"'!=`""', "ipdfile", "")								// convert to simple on/off
	if `"`ipdfile'"'==`""' & "`rsample'"!="" preserve

	cap nois MainRoutine `_USE' `invlist' if `touse', study(`_STUDY') `sortby' method(`method') summstat(`summstat') ///
		cmdstruc(`cmdstruc') citype(`citype') by(`_BY') `byad' `ad' effect(`effect') `eform' `log' ///
		`overall' `subgroup' wgt(`wgt') /*npts(`npts')*/ `logrank' `breslow' `cc' `chi2opt' ///
		tvlist(`tvlist') outvlist(`outvlist') `keepvars' forestplot(`fplotopts') `ipdfile' `options_adm'
		
	if _rc {
		if `"`err'"'==`""' {
			if _rc==1 nois disp as err `"User break in {bf:admetan.MainRoutine}"'
			else nois disp as err `"Error in {bf:admetan.MainRoutine}"'
		}
		c_local err "noerr"		// tell ipdmetan not to also report an "error in {bf:admetan}"
		local rc = _rc

		// restore original dataset before exiting
		// (will actually be done by -ipdmetan- if that was the original command)
		cap restore
		qui drop if `touse' & !inlist(`_USE', 1, 2)		// in case *not* under -preserve- (e.g. if _rsample required)
		exit `rc'
	}
	
	return add

	
	** Tidying up after successful analysis
	
	// if original data in memory was AD
	if `"`ipdfile'"'==`""' {

		// if -noKEEPVars- specified, check for existence of pre-existing vars named _ES, _seES etc. and give warning if found
		if "`keepvars'"!="" {
			if "`rsample'"!="" {
				restore
			
				// if -noRSample-, give warning if variable named _rsample already existed
				cap confirm var _rsample
				if !_rc {
					disp as err _n `"Warning: option {bf:norsample} specified, but "stored" variable {bf:_rsample} already exists"'
					disp as err  "Note that this variable is therefore NOT associated with the most recent analysis."
				}
			}
			
			else {
				local rc = 111
				foreach v in _ES _seES _LCI _UCI _WT _NN {
					cap confirm var `v'
					local rc = min(`rc', _rc)
				}
				local rc = min(`rc', `oldrsample')
				if !`rc' {
					disp as err _n `"Warning: option {bf:nokeepvars} specified, but one or more "stored" variables already exist"'
					disp as err  "(i.e. one or more of {bf:_ES}, {bf:_seES}, {bf:_LCI}, {bf:_UCI}, {bf:_WT}, {bf:_NN} or {bf:_rsample})"
					disp as err  "Note that these variables are therefore no longer associated with the most recent analysis."
				}
			}
		}
		
		// Finally, unless -noRSample- ( ==> data was preserved, now restored), need to drop newly-created obs
		// to return dataset to its original state
		if "`rsample'" == "" {
			qui drop if `touse' & !inlist(`_USE', 1, 2)			// drop newly-created obs (for holding pooled effect sizes etc.)
			if `"`ADfile'"'!=`""' qui drop if `_SOURCE'==2		// drop extra obs from `ADfile'
			qui count
			cap assert r(N) == `origN'
			if _rc {
				disp as err _n "Error in admetan.ado: dataset was not returned to its original state"
			}
		}
	}
	
	// if IPD was collapsed (Syntax 2) and _rsample is needed (already done if IPD and command-based syntax, i.e. Syntax 1)
	else {
		qui drop if `touse' & `_USE'!=1						// drop newly-created obs (for holding pooled effect sizes etc.)
		if `"`ADfile'"'!=`""' qui drop if `_SOURCE'==2		// drop extra obs from `ADfile'
	}			
	
	
end
	
	


	
	

**********************************************************************

*********************
* Stata subroutines *
*********************


* MainRoutine
// Program to run the core meta-analysis code
// done in a subroutine so that any errors can be "capture"-d and the original dataset restored
// (in the case of AD)

// called directly by admetan.ado; sort of a continuation under "capture" and "sortpreserve"

program define MainRoutine, rclass sortpreserve

	syntax varlist(min=3 max=7 numeric) [if] [in], METHOD(string) CItype(string) ///
		[STUDY(varname numeric) BY(varname numeric) BYAD SORTBY(varname) SUMMSTAT(string) DF(varname numeric) EFORM LOG MH ///
		CMDSTRUC(string) noOVerall noSUbgroup SUMMARYONLY OVWt SGWt ALTWt WGT(varname numeric) CUmulative EFFIcacy INFluence INTERaction ///
		LEVEL(passthru) CC(passthru) CHI2opt T noKEEPVars KEEPAll KEEPOrder EFFect(string) BREslow LOGRank AD ///
		TVLIST(namelist max=6) OUTVLIST(varlist numeric min=5 max=6) RFDIST RFLEVEL(passthru) EXTRALINE ///
		COunts GROUP1(string asis) GROUP2(string asis) LRVLIST(varlist numeric) /*NPTS(varname numeric)*/ NPTS ///
		HETStat(string) OVStat(string) LCols(namelist) RCols(namelist) SAVING(string asis) FORESTplot(string asis) IPDFILE PLOTID(string) ///
		noRSample noGRaph noTABle noHET noWARNing ESTVAR(string) SOURCE(varname numeric) OEV ZTOL(passthru) * ]
		
	marksample touse, novarlist	// -novarlist- option prevents -marksample- from setting `touse' to zero if any missing values in `varlist'
								// we want to control this behaviour ourselves, e.g. by using KEEPALL option
	
	local options_adm `"`options'"'
	
	gettoken _USE invlist : varlist
	local params : word count `invlist'

	tokenize `outvlist'
	args _ES _seES _LCI _UCI _WT _NN
	
	// if `byad', let `by' contain `source'
	if `"`byad'"'!=`""' {
		local by `source'
		tempname _SOURCE
		label define `_SOURCE' 1 "IPD" 2 "Aggregate data"
		label values `by' `_SOURCE'
	}
	
	// cumulative and influence
	if `"`cumulative'"'!=`""' & `"`influence'"'!=`""' {
		disp as err `"Cannot specify both {bf:cumulative} and {bf:influence}; please choose just one"'
		exit 198
	}
	if `"`cumulative'"'!=`""' {
		if `"`subgroup'"'!=`""' {
			disp as err `"Note: {bf:nosubgroup} is not compatible with {bf:cumulative} and will be ignored"'
			local subgroup
		}
		if `"`summaryonly'"'!=`""' {
			disp as err `"Options {bf:cumulative} and {bf:summaryonly} are not compatible"'
			exit 198
		}
		if `"`by'"'==`""' {
			if `"`overall'"'!=`""' {
				disp as err `"Note: {bf:nooverall} is not compatible with {bf:cumulative}, but will be re-interpreted as {bf:notable}"'
				local overall
				local table "notable"
			}
		}
		else {
			if `"`overall'"'!=`""' {
				disp as err `"Note: {bf:nooverall} is compulsory with {bf:cumulative} and {bf:by()}; will be re-interpreted as {bf:notable}"'
				local table "notable"
			}
			// local overall "nooverall"
		}
	}
	else if `"`influence'"'!=`""' & `"`summaryonly'"'!=`""' {
		disp as err `"Note: {bf:influence} is not compatible with {bf:summaryonly} and will be ignored"'
		local influence
	}
	
	// Compatibility tests for ovwt, sgwt, altwt
	if `"`by'"'==`""' {
		if `"`sgwt'"'!=`""' {
			local orbyad = cond("`ad'"!="", "(or {bf:byad}) ")
			disp as err `"Note: {bf:sgwt} is not applicable without {bf:by()} `orbyad'and will be ignored"'
		}
		local sgwt
		local ovwt "ovwt"
	}
	else if `"`cumulative'`influence'"'!=`""' {
		if `"`ovwt'"'!=`""' disp as err `"Note: {bf:ovwt} is not compatible with {bf:`cumulative'`influence'} and {bf:by()}, and will be ignored"'
		local ovwt
		local sgwt "sgwt"
	}
	if `"`ovwt'"'!=`""' & `"`sgwt'"'!=`""' {
		disp as err `"Cannot specify both {bf:ovwt} and {bf:sgwt}; please choose just one"'
		exit 198
	}
	if `"`altwt'"'!=`""' & `"`cumulative'`influence'"'==`""' {
		disp as err `"Note: {bf:altwt} is not applicable without {bf:cumulative} or {bf:influence}, and will be ignored"'
		exit 198
	}	

	// set ovwt/sgwt defaults
	if `"`ovwt'`sgwt'"'==`""' {
		if `"`by'"'!=`""' & `"`overall'"'!=`""' & `"`subgroup'"'==`""' local sgwt "sgwt"
		else local ovwt "ovwt"
	}

	
	* Random effects
	if `"`options_adm'"'!=`""' {

		// Synonyms for compatibility with metan.ado
		if `"`randomi'"'!=`""' local options `"`options_adm' re iv"'
		if `"`fixedi'"'!=`""'  local options `"`options_adm' fe iv"'
		if `"`fixed'"'!=`""'   local options `"`options_adm' fe"'

		// Now start to parse random-effects methods
		// (N.B. more than one permitted syntax; Stata options are RIGHTMOST)
		local random
		local 0 `", `options'"'
		syntax [, QE(varname numeric) RE RE(string) RAndom RAndom(string) * ]
		if `: word count `qe' `re' `random'' > 1 {
			if `"`qe'"'!=`""' {
				nois disp as err `"Cannot specify both {bf:qe} and {bf:re};"'
				nois disp as err `" to specify an alternative tau{c 178} estimator, use the syntax {bf:re(}{it:tausq_est}{bf:, qe(}{it:qe}{bf:))}"'
				exit 198
			}
			if `"`re'"'!=`""' & `"`random'"'!=`""' {
				nois disp as err `"Cannot specify both {bf:re} and {bf:random}; please choose just one"'
				exit 198
			}
		}
		if `"`re'"'!=`""' {
			local random `re'		// `re' is a synonym for `random'; use the latter
			local re_orig "re"		// but store actual supplied option for error displays
		}
		else {
			syntax [, QE(varname numeric) RE(string) RE RAndom(string) RAndom * ]
			if `: word count `qe' `re' `random'' > 1 {
				if `"`qe'"'!=`""' {
					nois disp as err `"Cannot specify both {bf:qe} and {bf:re};"'
					nois disp as err `" to specify the tau{c 178} estimator, use the syntax {bf:re(}{it:tausq_est}{bf:, qe(}{it:qe}{bf:)}"'
					exit 198
				}
				if `"`re'"'!=`""' & `"`random'"'!=`""' {
					nois disp as err `"Cannot specify both {bf:re} and {bf:random}; please choose just one"'
					exit 198
				}
			}
			if `"`re'"'!=`""' {
				local random `re'		// `re' is a synonym for `random'; use the latter
				local re_orig "re"		// but store actual supplied option for error displays
			}
		}
		if `"`qe'"'!=`""' {
			summ `qe', meanonly
			cap {
				assert r(min)>=0
				assert r(max)<=1
			}
			if _rc {
				disp as err "Quality scores must be between zero and one"
				exit 198
			}
			local random `"dl, qe(`qe')"'
		}
		local options_adm `"`options'"'
		
		if `"`random'"'!=`""' {
			local re_orig = cond("`re_orig'"=="", "random", "`re_orig'")	// for error displays
		
			// Classification of RE methods (as used in ipdmetan v1.x)
			// (1) tausq estimation methods:	  dl/dlb/mp/vc/sj2s/b0/bp/ml/reml
			// (2) "variance inflation" methods:  hk/kr/bs/ivh/fv
			// (3) other methods:				  pl/sa
		
			// Parse RE models and synonyms
			local t_old `t'
			local 0 `"`random'"'
			syntax [anything(name=re_model id="random-effects model")] ///
				[, T Gamma BS BT HKsj IVHet QE(varname numeric) KR EIM OIM ///
				ITOL(passthru) MAXTausq(passthru) REPS(passthru) MAXITer(passthru) QUADPTS(passthru) ISQ(real 80) noTRUNCate ]

			// DerSimonian-Laird is default
			if inlist("`re_model'", "", "r", "random", "rand", "re", "dl") local re_model "dl"

			// Other tausq estimators with synonyms
			else if inlist("`re_model'", "f", "fe", "fixed") local re_model "fe"			// Fixed-effects
			else if inlist("`re_model'", "bdl", "dlb") local re_model "dlb"					// Bootstrap DerSimonian-Laird (Kontopantelis)
			else if inlist("`re_model'", "mp", "pm", "q", "gq", "genq", "vb", "eb") local re_model "mp"	// Mandel-Paule aka Generalised Q aka Empirical Bayes
			else if inlist("`re_model'", "vc", "ca", "he") local re_model "vc"				// Variance-component aka Cochran's ANOVA-type aka Hedges
			else if inlist("`re_model'", "sens", "sa") local re_model "sa"					// Sensitivity analysis (at fixed Isq) as suggested by Kontopantelis
			else if inlist("`re_model'", "sj2", "sj2s") local re_model "sj2s"				// SJ2s = (improved) two-step Sidik-Jonkman
			
			// "Variance inflation" or "overdispersion" methods
			local vce_model
			if `"`gamma'`bt'`bs'"'!=`""' local gamma "gamma"						// synonyms
			opts_exclusive `"`gamma' `hksj' `ivhet' `kr'"' `"`re_orig'"' 184
			
			// Hartung-Knapp-Sidik-Jonkman variance correction
			if "`hksj'"!="" {
				cap assert inlist("`re_model'", "fe", "dl", "hk", "ml", "reml", "mp", "sa")
				if _rc {
					nois disp as err `"Specified random-effects model is incompatible with Hartung-Knapp-Sidik-Jonkman variance estimator"'
					exit _rc
				}
				local vce_model "hksj"
			}
			else if inlist("`re_model'", "dlt", "hk", "hksj", "kh") {	// can be used with various tausq estimates (see above)...
				local re_model "dl"										//  ...but DL is default
				local vce_model "hksj"
			}
						
			// Kenward-Roger variance correction
			else if "`kr'"!="" {
				cap assert inlist("`re_model'", "reml", "kr")
				if _rc {
					nois disp as err "Kenward-Roger variance estimator may only be combined"
					nois disp as err " with the REML estimator of tau{c 178}"
					exit 198
				}
				local vce_model "kr"
			}
			else if "`re_model'"=="kr" {
				local re_model "reml"									// can only be used with REML
				local vce_model "kr"
			}
			
			// Biggerstaff-Tweedie approximate Gamma variance estimator
			else if "`gamma'"!="" {
				cap assert "`re_model'"=="dl"
				if _rc {
					nois disp as err "Biggerstaff-Tweedie variance estimator may only be combined"
					nois disp as err " with the DerSimonian-Laird estimate of tau{c 178}"
					exit 198
				}
				local vce_model "gamma"
			}
			else if inlist("`re_model'", "g", "ga", "gam", "gamm", "gamma", "bt", "bs") {
				local re_model "dl"										// can only be used with D+L... I think?
				local vce_model "gamma"									// ...also see code for PerformPooling
			}

			// "IVHet" model of Doi et al (CCT 2015)
			else if "`ivhet'"!="" local vce_model "ivhet"
			else if inlist("`re_model'", "ivh", "ivhet") {				// can be used with any tausq estimate...
				local re_model "dl"										//  ...but DL is default)
				local vce_model "ivhet"
			}
			
			// "Quality effects" (QE) model of Doi et al (CCT 2015)
			else if "`qe'"!="" local vce_model "qe"
			else if "`re_model'"=="qe" {								// can be used with any tausq estimate...
				local re_model "dl"										//  ...but DL is default)
				local vce_model "qe"
			}

			// "Full variance" estimator suggested by Sandercock
			else if "`re_model'"=="fv" {
				local re_model "fe"
				local vce_model "fv"
			}

			else if !inlist("`re_model'", "fe", "dl", "dlb", "mp", "vc", "sa", "sj2s") ///
				& !inlist("`re_model'", "ml", "pl", "reml", "b0", "bp") {																				
				nois disp as err "Invalid random-effects model"
				nois disp as err "Please see {help admetan:help admetan} for a list of valid model names"
				exit 198
			}

			// dependencies
			if inlist("`re_model'", "mp", "ml", "pl", "reml") | "`vce_model'"=="gamma" {
				capture mata mata which mm_root()
				if _rc {
					nois disp as err `"Iterative tau-squared calculations require the Mata functions {bf:mm_root()} from {bf:moremata}"'
					nois disp as err `"Type {stata ssc describe moremata:ssc install moremata} to install it"'
					exit 499
				}
				if "`vce_model'"=="gamma" {
					capture mata mata which integrate()
					if _rc {
						nois disp as err `"Biggerstaff-Tweedie method requires the mata function {bf:integrate()}"'
						nois disp as err `"Type {stata ssc describe integrate:ssc install integrate} to install it"'
						exit 499
					}
				}
			}
			else if "`re_model'"=="dlb" {
				capture mata mata which mm_bs()
				local rc1 = _rc
				capture mata mata which mm_jk()
				if _rc | `rc1' {
					nois disp as err `"Bootstrap DerSimonian-Laird method requires the Mata functions {bf:mm_bs()} and {bf:mm_jk()} from {bf:moremata}"'
					nois disp as err `"Type {stata ssc describe moremata:ssc install moremata} to install it"'
					exit 499
				}
			}
		}
		local random			// clear macro

		if "`re_model'"=="sa" {
			if "`by'"!="" {
				nois disp as err `"Sensitivity analysis cannot be used with {bf:by()}"'
				exit 198
			}
			if `isq'<0 | `isq'>=100 {
				nois disp as err `"I{c 178} value for sensitivity analysis must be at least 0% and less than 100%"'
				exit 198
			}
		}
		else {
			if !inlist("`isq'", "", "80") {
				nois disp as err `"{bf:isq()} may only be specified when requesting a sensitivity analysis model"'
				exit 198
			}
		}
		
		// observed/expected information matrix for Kenward-Roger
		if `"`eim'`oim'"'!=`""' {
			if "`vce_model'"!="kr" {
				nois disp as err `"Note: Options {bf:eim} and {bf:oim} are only relevant to the Kenward-Roger variance estimator and will be ignored"' 
			}
			else {
				cap assert `: word count `eim' `oim'' == 1
				if _rc {
					nois disp as err `"May only specify one of {bf:eim} or {bf:oim}, not both"'
					exit _rc
				}
			}
		}
		else if "`vce_model'"=="kr" local eim "eim"
		
		// M-H and chi2 not compatible with random effects
		if "`mh'"!="" {
			nois disp as err "Cannot specify both Mantel-Haenszel and random-effects"
			exit 198
		}
		if "`chi2opt'"!="" {
			nois disp as err "Note: chi-squared test is not compatible with random-effects and will be ignored"
			local chi2opt
		}
	}			// end if `"`options'"'!=`""'
	
	local isqsa = cond(`"`isq'"'!=`""', `"`isq'"', `"80"')		// rename to differentiate from calculated Isq
	local isq													// clear macro	
	local options_re `"vcemodel(`vce_model') isqsa(`isqsa') qe(`qe') `itol' `maxtausq' `reps' `maxiter' `quadpts' `eim' `oim' `truncate'"'
	
	// Finalise method of POOLING (M-H; fixed IV; random IV)
	// (N.B. those are the only three possibilities, since Peto, logrank, SMD/WMD are all IV.)
	local re_model = cond("`re_model'"!="", "`re_model'", ///
		cond("`method'"=="mh", "mh", "fe"))					// if M-H method, set to M-H
															// otherwise, set to if I-V fixed-effects

	// t-distribution
	if `"`t'`t_old'"'!=`""' | inlist("`vce_model'", "hksj", "kr") {
		if "`chi2opt'"!="" {
			nois disp as err "Cannot specify both chi-squared and t distributions for test of pooled effect(s)"
			exit 198
		}
		local t "t"
	}

	// vaccine efficacy: OR and RR only
	if `"`efficacy'"'!=`""' {
		cap assert inlist("`summstat'", "or", "rr")
		if _rc {
			nois disp as err "Vaccine efficacy statistics only possible with odds ratios and risk ratios"
			exit _rc
        }
	}	
	
	// prediction intervals: iv with appropriate random-effects model only
	if "`rfdist'"!="" {
		cap assert inlist("`re_model'", "b0", "bp", "dl", "dlb", "mp") ///
			| inlist("`re_model'", "ml", "reml", "vc", "sa", "sj2s") | "`vce_model'"!=""
		if _rc {
			nois disp as err `"Note: prediction interval cannot be estimated under the specified model; {bf:rfdist} will be ignored"' 
			local rfdist
		}
	}

	// User-defined weights are IV FE only
	if `"`wgt'"'!=`""' {
		cap assert `"`method'"'==`"iv"'
		if _rc {
			nois disp as err "User-defined weights can only be used with inverse-variance method"
			exit _rc
		}
		cap assert `"`re_model'"'==`"fe"'
		if _rc {
			nois disp as err "Random-effects options cannot be used with user-defined weights"
			exit _rc
		}
	}

	if `"`cumulative'`influence'"'!=`""' {
		local tofind `"_ES _seES"'
		if `"`: list tofind & invlist'"'!=`""' {
			nois disp as err `"Caution: {bf:_ES} and {bf:_seES} are altered by {bf:admetan}; results will be unstable if analysis is repeated"'
		}
		
		tempvar use3
		qui gen byte `use3' = 0		// identifier of last estimate, for placement of dotted line in forestplot
			
		local xoutvlist `"_ES2 _seES2 _LCI2 _UCI2 _WT2 _Q"'							// "extra" outvlist
		if "`re_model'"!="mh" local xoutvlist `"`xoutvlist' _tausq _sigmasq"'
		if "`keepvars'`altwt'"=="" local xoutvlist `"`xoutvlist' _NN2"'				// so that cumul/infl _NN2 may be displayed on forestplot
		foreach v of local xoutvlist {												// but original study-level _NN is left behind
			tempvar `v'
			qui gen double ``v'' = .
		}
		local xoutvlist `"`_ES2' `_seES2' `_LCI2' `_UCI2' `_WT2' `_Q' `_tausq' `_sigmasq' `_NN2'"'

		// tempvar `df' might already exist, passed through from ipdmetan
		if inlist("`vce_model'", "hksj", "kr") & `"`df'"'==`""' {
			tempvar df
			local dftype = cond("`vce_model'"=="hksj", "int", "double")		// "double" if Kenward-Roger
			qui gen `dftype' `df' = .
		}
	}
	
	// Generate tempvars to store prediction interval (if applicable)
	if `"`rfdist'"'!=`""' {
		tempvar _rfLCI _rfUCI
		qui gen double `_rfLCI' = .		// do this now; will be updated within PerformMetaAnalysis
		qui gen double `_rfUCI' = .		// (N.B. other tvars are generated for _USE==1 within PerformMetaAnalysis, but rfvars only valid for _USE=3,5)
		local rfdlist `"`_rfLCI' `_rfUCI'"'
	}	


	* Initialise matrix to hold subgroup stats (matrix bystats)
	if `"`by'"'!=`""' {
		qui levelsof `by' if `touse' & `_USE'!=5, local(bylist) missing
		local nby : word count `bylist'
		
		tempname bystats
		local nc = 3 ///					// _BY, Q, k
			+ 2*("`re_model'"!="mh" & !("`re_model'"=="fe" & ("`method'"=="peto" | "`breslow'"!=""))) ///			// sigmasq, tausq (not applicable if Cochran's Q not used)
			+ 2*(inlist("`re_model'", "dlb", "mp", "ml", "pl", "reml") | inlist("`vce_model'", "gamma", "kr")) ///	// tsq_lci, tsq_uci
			+ (`"`_NN'"'!=`""') ///			// _NN
			+ (`"`vce_model'"'=="kr") ///	// df for Kenward-Roger
			+ (`"`chi2opt'"'!=`""')			// chi2 statistic (OR only)
		mat `bystats' = J(`nby', `nc', .)
		
		local colnames `"_BY Q k"'
		if "`re_model'"!="mh" & !("`re_model'"=="fe" & ("`method'"=="peto" | "`breslow'"!="")) local colnames `"`colnames' sigmasq tausq"'
		if inlist("`re_model'", "dlb", "mp", "ml", "pl", "reml") | inlist("`vce_model'", "gamma", "kr") local colnames `"`colnames' tsq_lci tsq_uci"'
		if `"`_NN'"'!=`""'     local colnames `"`colnames' _NN"'
		if `"`vce_model'"'=="kr" local colnames `"`colnames' df_kr"'
		if `"`chi2opt'"'!=""   local colnames `"`colnames' chi2"'
		matrix colnames `bystats' = `colnames'
	}	
	else if `"`subgroup'"'!=`""' & `"`byad'"'==`""' ///
			& !(`"`ipdmetan'"'!=`""' & `"`ad'"'==`""') {					// this condition has already been tested for by -ipdmetan-
		local orbyad = cond(`"`ad'"'!=`""', `"(or {bf:byad}) "', `""')
		nois disp as err `"Note: {bf:nosubgroup} cannot be specified without {bf:by()} `orbyad'and will be ignored"' 
		local subgroup
	}
	
	* Create new observations to hold subgroup & overall effects (_USE==3, 5)
	// These can simply be removed again to restore the original data.
	
	// Creating these new observations shouldn't be necessary if "original" ipdmetan command was run
	//   but e.g. `byad' throws up complications ("IPD-overall" created as _USE==5 but changed to _USE==3 within ProcessAD)
	// To cover all bases, simply check for a _USE==3 corresponding to each `by'-value,
	//   plus a single overall _USE==5 (if applicable).
	
	// if cumulative, don't need _USE==3, 5; remove (e.g. if created by -ipdmetan-)
	if `"`cumulative'"'!=`""' {
		qui drop if `touse' & inlist(`_USE', 3, 5)
	}
	
	else {
		// subgroup effects (`_USE'==3)
		if `"`by'"'!=`""' & `"`subgroup'"'==`""' {
			foreach byi of local bylist {
				qui count if `by'==`byi' & `_USE'==3 & `touse'
				if !r(N) {
					local newN = _N + 1
					qui set obs `newN'
					qui replace `by' = `byi' in `newN'
					qui replace `_USE' = 3 in `newN'
					qui replace `touse' = 1 in `newN'
				}
			}
		}

		// overall effect (`_USE'==5)
		if `"`overall'"'==`""' {
			qui count if `_USE'==5 & `touse'
			if !r(N) {		
				local newN = _N + 1
				qui set obs `newN'
				qui replace `_USE' = 5 in `newN'
				qui replace `touse' = 1 in `newN'
			}
		}
	}

	// Generate stable ordering to pass to subroutines... (PerformMetaAnalysis, DrawTable, forestplot)
	tempvar obs
	qui gen long `obs' = _n

	// ... and use this stable ordering to bring IPD above AD in the appended dataset (if applicable)
	if `"`ad'"' != `""' {
		sort `source' `_USE' `obs'
		qui replace `obs' = _n
	}
	isid `touse' `by' `_USE' `obs', missok

	cap nois PerformMetaAnalysis `_USE' `invlist' if `touse', ///
		sortby(`sortby' `obs') method(`method') summstat(`summstat') remodel(`re_model') ///
		by(`by') bylist(`bylist') bystats(`bystats') ///
		`cumulative' `influence' xoutvlist(`xoutvlist') use3(`use3') outvlist(`outvlist') rfdlist(`rfdlist') ///
		`logrank' `breslow' `cc' `chi2opt' `level' `rflevel' wgt(`wgt') df(`df') `sgwt' `ovwt' `altwt' `ztol' ///
		`options_re' `options_adm' `subgroup' `overall'

	if _rc {
		if `"`err'"'==`""' {
			if _rc==2000 {
				if "`cmdstruc'"=="generic" {
					nois disp as err `"No estimates found. Check:"'
					nois disp as err `"- model is able to be fitted within the entire dataset and/or a specific study"'
					nois disp as err `"- specification of exp_list and/or interaction option (if applicable)"'
				}
				else nois disp as err `"No estimates found"'
			}
			else if _rc==1 nois disp as err `"User break in {bf:admetan.PerformMetaAnalysis}"'
			else nois disp as err `"Error in {bf:admetan.PerformMetaAnalysis}"'
		}
		c_local err "noerr"		// tell admetan not to also report an "error in MainRoutine"
		exit _rc
	}

	// return k and n (totnpts)
	tempname k totnpts
	scalar `k' = r(k)
	scalar `totnpts' = r(totnpts)
	return scalar k = `k'
	return scalar n = cond(`totnpts'==0, ., `totnpts')
		
	// return measure, method and re_model
	if "`summstat'"!="" {
		local usummstat = upper("`summstat'")
		return local measure `"`log'`usummstat'"'
	}
	return local method "`method'"
	return local re_model = cond("`r(re_model)'"!="", "`r(re_model)'", "`re_model'")	
	return local vce_model `"`vce_model'"'

	
	** Return overall statistics, and/or derive and save for subsequent code
	if `"`overall'"'==`""' {

		local vce_model = cond(`"`r(re_model)'"'==`"`re_model'"', `"`vce_model'"', `""')
		local re_model `r(re_model)'
		local het = cond(`k'==1, "nohet", "`het'")		// don't present overall het stats if only one estimate
	
		// overall stats
		tempname Q eff se_eff
		scalar `Q' = r(Q)				// Generic heterogeneity statistic (including Peto, M-H, Breslow-Day)
		scalar `eff' = r(eff)	
		scalar `se_eff' = r(se_eff)
		return scalar eff=`eff'
		return scalar se_eff=`se_eff'

		if `params'==4 {
			if "`re_model'"=="mh" & "`summstat'"!="rd" {
				local usummstat = upper("`summstat'")
				return scalar `usummstat' = r(`usummstat')
			}
			if "`chi2opt'"!="" | "`method'"=="peto" {
				tempname chi2
				scalar `chi2' = r(chi2)
				return scalar chi2 = `chi2'
			}
			return scalar tger = r(tger)
			return scalar cger = r(cger)
		}
		else if "`method'"=="peto" {
			tempname chi2
			scalar `chi2' = r(chi2)
			return scalar chi2 = `chi2'
			return scalar OE = r(OE)
			return scalar V  = r(V)
		}
		
		// Heterogeneity stats
		// (N.B. Q-related stuff is meaningless for sensitivity analysis)
		if "`re_model'"!="sa" {
			return scalar Q = `Q'

			// Subgroup statistics
			// (N.B. `subgroup' since otherwise `Qsum' would not be calculated)
			if `"`by'"'!=`""' & `"`subgroup'"'==`""' {
				tempname Qdiff
				scalar `Qdiff' = `Q' - `r(Qsum)'	// between-subgroup heterogeneity (Qsum = within-subgroup het.)
				return scalar Qdiff = `Qdiff'
				
				tempname Fstat
				scalar `Fstat' = (`Qdiff'/(`nby' - 1)) / (`r(Qsum)'/(`k' - `nby'))		// corrected 17th March 2017
				return scalar F = `Fstat'
				return scalar nby = `nby'
			}
		}
		
		// tausq-related stuff (incl. Qr) is meaningless for M-H, and also for Peto or Breslow unless RE
		// (N.B. although this *does* include sensitivity analysis)
		if "`re_model'"!="mh" & !("`re_model'"=="fe" & ("`method'"=="peto" | "`breslow'"!=""))  {

			// tausq, sigmasq, Qr
			return scalar sigmasq = r(sigmasq)
			return scalar tausq = r(tausq)
			if "`re_model'"!="fe" return scalar Qr = r(Qr)
			local tsqlist `"`r(tausq)'"'
		
			// calculations involving Cochran's Q only (since it alone is defined in terms of tausq)
			tempname Isq HsqM
			scalar `Isq' = cond("`re_model'"=="sa", `isqsa'/100, ///	// sensitivity analysis
				cond(missing(r(tausq)), (r(Qc)-`k'+1)/r(Qc), ///		// non inverse-variance (or missing tausq)
					r(tausq)/(r(tausq) + r(sigmasq))))					// inverse-variance (non-missing tausq)
			return scalar Isq = `Isq'
			local Isqlist `"`=`Isq''"'
			
			scalar `HsqM' = cond("`re_model'"=="sa", `isqsa'/(100 - `isqsa'), ///	// sensitivity analysis
				cond(missing(r(tausq)), (r(Qc)-`k'+1)/(`k'-1), ///						// non inverse-variance
					r(tausq)/r(sigmasq)))												// inverse-variance
			
			return scalar HsqM = cond("`re_model'"=="sa", float(`HsqM'), `HsqM')		// If user-defined I^2 is a round(ish) number, so should H^2 be
			local Hsqlist `"`=`HsqM''"'
		
			// confidence limits for tausq, Isq and Hsq, plus error codes & messages
			if inlist(`"`re_model'"', "dlb", "mp", "ml", "pl", "reml") | inlist(`"`vce_model'"', "gamma", "kr") {
			
				local maxtausq2 = r(maxtausq)		// take maxtausq from PerformPooling (10* D+L estimate)
				local 0 `", `iteropts'"'
				syntax [, ITOL(real 1e-8) MAXTausq(real -9) REPS(real 1000) MAXITer(real 1000) QUADPTS(real 40)]

				// tausq, Hsq, Isq lists (for DrawTableAD)
				return scalar tsq_lci = r(tsq_lci)
				return scalar tsq_uci = r(tsq_uci)
				local tsqlist `"`tsqlist' `r(tsq_lci)' `r(tsq_uci)'"'
				local Hsqlist `"`Hsqlist' `=`r(tsq_lci)'/`r(sigmasq)'' `=`r(tsq_uci)'/`r(sigmasq)''"'
				local Isqlist `"`Isqlist' `=`r(tsq_lci)'/(`r(tsq_lci)' + `r(sigmasq)')' `=`r(tsq_uci)'/(`r(tsq_uci)' + `r(sigmasq)')'"'
				
				if `"`re_model'"'!="dlb" & `"`vce_model'"'!="gamma" {
					if r(rc_tausq)==1 nois disp as err `"Note: tau{c 178} point estimate failed to converge within `maxiter' iterations"'
					else if r(rc_tausq)==3 {
						if `maxtausq'==-9 nois disp as err `"Note: tau{c 178} greater than default value {bf:maxtausq(}`maxtausq2'{bf:)}; try increasing it"'
						else nois disp as err `"Note: tau{c 178} greater than `maxtausq'; try increasing {bf:maxtausq()}"'
					}
					else if missing(r(tausq)) {
						nois disp as err `"Note: tau{c 178} point estimate could not be found; possible discontinuity in search interval"'
						exit 498
					}
					return scalar rc_tausq = r(rc_tausq)		// whether tausq point estimate converged
				}
				
				if "`re_model'"!="dlb" {
					if r(rc_tsq_lci)==1 nois disp as err `"Note: Lower confidence limit of tau{c 178} failed to converge within `maxiter' iterations; try increasing {bf:maxiter()}"'
					else if missing(r(tsq_lci)) {
						nois disp as err `"Note: Lower confidence limit of tau{c 178} could not be found; possible discontinuity in search interval"'
					}
						
					if r(rc_tsq_uci)==1 nois disp as err `"Note: Upper confidence limit of tau{c 178} failed to converge within `maxiter' iterations; try increasing {bf:maxiter()}"'
					else if r(rc_tsq_uci)==3 {
						if `maxtausq'==-9 nois disp as err `"Note: Upper confidence limit of tau{c 178} greater than default value {bf:maxtausq(}`maxtausq2'{bf:)}; try increasing it"'
						else nois disp as err `"Note: Upper confidence limit of tau{c 178} greater than `maxtausq'; try increasing {bf:maxtausq()}"'
					}
					else if missing(r(tsq_uci)) {
						nois disp as err `"Note: Upper confidence limit of tau{c 178} could not be found; possible discontinuity in search interval"'
					}
					return scalar rc_tsq_lci = r(rc_tsq_lci)		// whether tausq lower confidence limit converged
					return scalar rc_tsq_uci = r(rc_tsq_uci)		// whether tausq upper confidence limit converged
				}

				if "`re_model'"=="pl" {
					if r(rc_eff_lci)==1 nois disp as err `"Note: Lower confidence limit of effect size failed to converge within `maxiter' iterations; try increasing {bf:maxiter()}"'
					else if r(rc_eff_lci)>1 | (missing(`_LCI') & `touse' & inlist(`_USE', 3, 5)) {
						nois disp as err `"Note: Lower confidence limit of effect size could not be found; possible discontinuity in search interval"'
					}
					if r(rc_eff_uci)==1 nois disp as err `"Note: Upper confidence limit of effect size failed to converge within `maxiter' iterations; try increasing {bf:maxiter()}"'
					else if r(rc_eff_uci)>1 | (missing(`_UCI') & `touse' & inlist(`_USE', 3, 5)) {
						nois disp as err `"Note: Upper confidence limit of effect size could not be found; possible discontinuity in search interval"'
					}				
					return scalar rc_eff_lci = r(rc_eff_lci)		// whether ES lower confidence limit converged
					return scalar rc_eff_uci = r(rc_eff_uci)		// whether ES upper confidence limit converged					
					return scalar eff_lci = r(eff_lci)
					return scalar eff_uci = r(eff_uci)
				}

				else if "`vce_model'"=="gamma" return scalar tsq_var = r(tsq_var)
				else if "`vce_model'"=="kr" {
					tempname df_kr
					scalar `df_kr' = r(df_kr)			// need to save this value separately, to pass to DrawTableAD
					return scalar df_kr = r(df_kr)
				}
			}
		}
	}
	
	// Finalise cumulative/influence effect-size vars
	if `"`xoutvlist'"'!=`""' {
		foreach v in _ES _seES _LCI _UCI _WT {
			if `"`ipdfile'"'!=`""' | `: list v in tvlist' {		// i.e. if `v' was created by either -ipdmetan- or -admetan-
				drop ``v''
				rename ``v'2' ``v''
			}
			else local `v' ``v'2'
		}
	}

	// Generate study-level CIs (unless pre-specified)
	qui count if `touse' & `_USE'==1 & missing(`_LCI', `_UCI')
	if r(N) {
		cap nois GenConfInts `invlist' if `touse' & `_USE'==1 & missing(`_LCI', `_UCI'), ///
			citype(`citype') df(`df') outvlist(`outvlist') `level' `ztol'

		if _rc {
			nois disp as err `"Error in {bf:admetan.GenConfInts}"'
			c_local err "noerr"		// tell admetan not to also report an "error in MainRoutine"
			exit _rc
		}
	}

	// Return `bystats' matrix
	if `"`by'"'!=`""' {
		return matrix bystats = `bystats', copy
	}

	// remove studies with insufficient data if appropriate
	local keepall = cond(`"`keeporder'"'!=`""', `"keepall"', `"`keepall'"')		// `keeporder' implies `keepall'
	if `"`keepall'"'==`""' qui replace `touse' = 0 if `_USE'==2

	// otherwise, maintain original order if requested
	else if `"`keeporder'"'!=`""' {
		tempvar olduse
		qui gen byte `olduse' = `_USE'
		qui replace `_USE' = 1 if `_USE'==2		// keep "insufficient data" studies in original study order (default is to move to end)
	}
	
	// return scalars for AD & IPD separately if "byad"
	if `"`byad'"'!=`""' {
		forvalues i=1/2 {
			local K`i'       = `bystats'[`i', `=colnumb(`bystats', "k")'] 
			local totnpts`i' = `bystats'[`i', `=colnumb(`bystats', "_NN")']
		}
		foreach x in K1 K2 totnpts1 totnpts2 eff1 eff2 se_eff1 se_eff2 {
			if `"``x''"'==`""' local `x'=.
		}

		if `"`overall'"'!=`""' {
			return scalar k1=`K1'
			return scalar k2=`K2'
			return scalar n1=`totnpts1'
			return scalar n2=`totnpts2'
			return scalar eff1=`eff1'
			return scalar eff2=`eff2'
			return scalar se_eff1=`se_eff1'
			return scalar se_eff2=`se_eff2'
		}
	}


	********************************
	* Print summary info to screen *
	********************************
	
	* Print number of studies/participants to screen
	//  (NB nos. actually analysed as opposed to the number supplied in original data)
	if `"`ad'"'!=`""' {
		if `"`byad'"'==`""' {
			tempname KIPD totnptsIPD
			qui count if `touse' & inlist(`_USE', 1, 2) & `source'==1
			scalar `KIPD' = r(N)
			if r(N) {
				if "`_NN'"!="" {
					summ `_NN' if `touse' & inlist(`_USE', 1, 2) & `source'==1, meanonly
					scalar `totnptsIPD' = cond(r(N), r(sum), .)			// if KIPD>0 but no _NN, set to missing
				}
				else scalar `totnptsIPD' = .
			}
			else scalar `totnptsIPD' = 0

			tempname KAD totnptsAD
			qui count if `touse' & inlist(`_USE', 1, 2) & `source'==2
			scalar `KAD' = r(N)
			if r(N) {
				if "`_NN'"!="" {
					summ `_NN' if `touse' & inlist(`_USE', 1, 2) & `source'==2, meanonly
					scalar `totnptsAD' = cond(r(N), r(sum), .)			// if KAD>0 but no _NN, set to missing
				}
				else scalar `totnptsAD' = .
			}
			else scalar `totnptsAD' = 0
		}
		else {
			local KIPD `K1'
			local totnptsIPD `totnpts1'
			local KAD `K2'
			local totnptsAD `totnpts2'
		}
		disp as text _n "Studies included from IPD: " as res `KIPD'
		if "`keepall'"!="" {
			qui count if `touse' & `_USE'==2 & `source'==1
			assert r(N) <= `KIPD'
			if r(N) {
				local ending = cond(r(N)==1, "y", "ies")
				disp as text "  plus " as res `r(N)' as text " stud`ending' with insufficient data"
			}
		}		
		local dispnpts = cond(missing(`totnptsIPD'), "Unknown", string(`totnptsIPD'))
		disp as text "Participants included from IPD: " as res "`dispnpts'"
		if "`keepall'"!="" & !missing(`totnptsIPD') {
			summ `_NN' if `touse' & `_USE'==2 & `source'==1, meanonly
			assert r(sum) <= `totnptsIPD'
			if r(sum) {
				if r(sum)>1 local s "s"
				disp as text "  plus " as res `r(sum)' as text " participant`s' with insufficient data"
			}
		}
		
		disp as text _n "Studies included from aggregate data: " as res `KAD'
		if "`keepall'"!="" {
			qui count if `touse' & `_USE'==2 & `source'==2
			assert r(N) <= `KAD'
			if r(N) {
				local ending = cond(r(N)==1, "y", "ies")
				disp as text "  plus " as res `r(N)' as text " stud`ending' with insufficient data"
			}
		}
		local dispnpts = cond(missing(`totnptsAD'), "Unknown", string(`totnptsAD'))
		disp as text "Participants included from aggregate data: " as res "`dispnpts'"
		if "`keepall'"!="" & !missing(`totnptsAD') {
			summ `_NN' if `touse' & `_USE'==2 & `source'==2, meanonly
			assert r(sum) <= `totnptsAD'
			if r(sum) {
				if r(sum)>1 local s "s"
				disp as text "  plus " as res `r(sum)' as text " participant`s' with insufficient data"
			}
		}
	}
	else {
		disp _n _c
		disp as text "Studies included: " as res `k'
		if "`keepall'"!="" {
			qui count if `touse' & `_USE'==2
			if r(N) {
				local ending = cond(r(N)==1, "y", "ies")
				disp as text "  plus " as res `r(N)' as text " stud`ending' with insufficient data"
			}
		}
		local dispnpts = cond(missing(`totnpts'), "Unknown", string(`totnpts'))
		disp as text "Participants included: " as res "`dispnpts'"
		if "`keepall'"!="" & !missing(`totnpts') {
			summ `_NN' if `touse' & `_USE'==2, meanonly
			if r(sum) {
				if r(sum)>1 local s "s"
				disp as text "  plus " as res `r(sum)' as text " participant`s' with insufficient data"
			}
		}
	}
	
	
	** Full descriptions of `summstat', `method' and `re_model' options, for printing to screen

	// Build up description of effect estimate type (interaction, cumulative etc.)
	local pooltext = cond(`"`cumulative'"'!=`""', "Cumulative meta-analysis of", ///
		cond(`"`influence'"'!=`""', "Influence meta-analysis of", "Meta-analysis pooling of"))
	if "`cmdstruc'"=="generic" {
		if `"`interaction'"'!=`""' local pooltext "`pooltext' interaction effect estimate"
		else if `"`exp_list'"'!=`""' local pooltext "`pooltext' user-specified effect estimate"
		else local pooltext "`pooltext' main (treatment) effect estimate"
		di _n as text "`pooltext'" as res " `estvar'"
	}
	else if `"`summstat'"'!=`""' {
		local logtext = cond(`"`log'"'!=`""', `"`log' "', `""')		// add a space if `log'
		if "`summstat'"=="rr" local efftext "`logtext'Risk Ratios"
		else if "`summstat'"=="irr" local efftext "`logtext'Incidence Rate Ratios"
		else if "`summstat'"=="rrr" local efftext "`logtext'Relative Risk Ratios"
		else if "`summstat'"=="or"  local efftext "`logtext'Odds Ratios"
		else if "`summstat'"=="rd"  local efftext " Risk Differences"
		else if "`summstat'"=="hr"  local efftext "`logtext'Hazard Ratios"
		else if "`summstat'"=="shr" local efftext "`logtext'Sub-hazard Ratios"
		else if "`summstat'"=="tr"  local efftext "`logtext'Time Ratios"
		else if "`summstat'"=="wmd" local efftext " Weighted Mean Differences"	
		else if "`summstat'"=="smd" {
			local efftext " Standardised Mean Differences"
			if "`method'"=="cohen"       local efftextf `" as text " by the method of " as res "Cohen""'
			else if "`method'"=="glass"  local efftextf `" as text " by the method of " as res "Glass""'
			else if "`method'"=="hedges" local efftextf `" as text " by the method of " as res "Hedges""'
		}
			
		// Study-level effect derivation method
		if "`logrank'"!="" local efftext "Peto (logrank) `efftext'"
		else if "`re_model'"=="fe" & "`method'"=="peto" local efftext "Peto `efftext'"
		di _n as text "`pooltext'" as res " `efftext'" `efftextf'
	}
	else {
		di _n as text "`pooltext' aggregate data"
	}		
	
	// Pooling method (Mantel-Haenszel; fixed-effect; random-effects)
	if "`re_model'"=="mh" {
		disp as text "using the " as res "Mantel-Haenszel" as text " method"
		if `"`warning'"'==`""' local fpnote `"Mantel-Haenszel model"'			// for forestplot
	}
	else {
		if "`re_model'"=="fe" | "`vce_model'"=="ivhet" local modtext "fixed-effect inverse-variance"
		else if "`vce_model'"=="qe" {
			local modtext "Doi's Quality Effects inverse-variance"
			if `"`warning'"'==`""' local fpnote `"Doi's Quality Effects model"'		// for forestplot
		}
		else if !inlist("`re_model'", "fe", "mh") {
			local modtext "random-effects inverse-variance"
			if `"`warning'"'==`""' & "`re_model'"!="sa" local fpnote `"random-effects model"'	// for forestplot
		}
		local the = cond("`vce_model'"=="qe", "", "the ")
		disp as text "using `the'" as res "`modtext'" as text " model"
	}
		
	// tausq estimation method
	if !inlist("`re_model'", "fe", "mh") {
		if "`re_model'"=="dl"        local tsqtext "DerSimonian-Laird"
		else if "`re_model'"=="dlb"  local tsqtext "Bootstrap DerSimonian-Laird"
		else if "`re_model'"=="mp"   local tsqtext "Mandel-Paule"
		else if "`re_model'"=="vc"   local tsqtext "Cochran's ANOVA-type"
		else if "`re_model'"=="sj2s" local tsqtext "Sidik-Jonkman two-step"
		else if "`re_model'"=="ml"   local tsqtext "ML"
		else if "`re_model'"=="pl"   local tsqtext "Profile ML"
		else if "`re_model'"=="reml" local tsqtext "REML"
		else if "`re_model'"=="bp"   local tsqtext "Rukhin's BP"
		else if "`re_model'"=="b0"   local tsqtext "Rukhin's B0"

		if !inlist("`vce_model'", "ivhet", "qe") {
			local continue = cond("`vce_model'"=="", "", "_c")
			if "`re_model'"!="sa" disp as text "with " as res "`tsqtext'" as text " estimate of tau{c 178} " `continue'
			else {
				disp as text "Sensitivity analysis with user-defined I{c 178} = " as res "`isqsa'%"
				if `"`warning'"'==`""' local fpnote `"Sensitivity analysis with user-defined I{c 178}"'
			}
		}
	}
	
	// variance estimator
	if "`vce_model'"!="" {
		if !inlist("`vce_model'", "ivhet", "qe") {
			if "`vce_model'"=="gamma" local vcetext "Biggerstaff-Tweedie"
			else if "`vce_model'"=="hksj" local vcetext "Hartung-Knapp-Sidik-Jonkman"
			else if "`vce_model'"=="kr" local vcetext "Kenward-Roger"
			else if "`vce_model'"=="fv" local vcetext "Sandercock's"
			disp as text "and " as res "`vcetext'" as text " variance estimator"
			if `"`warning'"'==`""' local fpnote `"`fpnote' and `vcetext' variance estimator"'
		}
	
		else {
			// IVhet model
			if "`vce_model'"=="ivhet" {
				disp as text "with " as res "Doi's IVhet" as text " variance estimator, based on " _c
				if `"`warning'"'==`""' local fpnote `"`fpnote' with Doi's IVhet variance estimator"'
			}

			// Quality effects (QE) model
			else disp as text "with quality scores " as res "`qe'" as text " and " _c

			// Sensitivity (tausq) analysis
			if "`re_model'"!="sa" disp as res `"`tsqtext'"' as text `" estimate of tau{c 178}"'
			else disp as text "user-defined I{c 178} = " as res "`isqsa'%"
		}
	}

	// user-defined weights
	if "`wgt'" != "" {
		disp as text "and with user-defined weights " as res "`wgt'"
		if `"`warning'"'==`""' local fpnote `"NOTE: Weights are user-defined"'
	}
	else if `"`fpnote'"'!=`""' local fpnote `"NOTE: Weights are from `fpnote'"'



	***************************
	* Print results to screen *
	***************************
	
	// Unless no table AND no graph AND no saving, store study value labels in new var "_LABELS"
	// N.B. `study' should always be numeric
	if !(`"`table'"'!=`""' & `"`graph'"'!=`""' & `"`saving'"'==`""') {
		tempvar _LABELS
		local labelsvar `study'
		if `"`labelsvar'"'==`""' gettoken labelsvar lcols : lcols
		if `"`labelsvar'"'==`""' local svarlab "Study"
		else {
			local svarlab : variable label `labelsvar'
			local svarlab = cond(`"`svarlab'"'!=`""', `"`svarlab'"', `"`labelsvar'"')
		}
		cap confirm numeric var `labelsvar'
		if !_rc {
			cap decode `labelsvar' if `touse', gen(`_LABELS')				// if value label
			if _rc qui gen `_LABELS' = string(`labelsvar') if `touse'		// if no value label
		}
		else qui gen `_LABELS' = `labelsvar' if `touse'						// if string
	
		// missing values of `study'
		// string() works with ".a" etc. but not "." -- contrary to documentation??
		qui replace `_LABELS' = "." if missing(`_LABELS') & !missing(`labelsvar') & `touse'
	}
	
	if `"`table'"'==`""' {

		// find maximum length of labels in LHS column
		tempvar vlablen
		qui gen long `vlablen' = length(`_LABELS')
		if `"`by'"'!=`""' {
			tempvar bylabels
			cap decode `by', gen(`bylabels')
			if _rc local bylabels `"string(`by')"'
			qui replace `vlablen' = max(`vlablen', length(`bylabels'))
			cap drop `bylabels'
		}
		summ `vlablen', meanonly
		local lablen=r(max)
		drop `vlablen'
	}
	
	if `"`by'"'!=`""' {
		local byvarlab : variable label `by'
		local byvarlab = cond(`"`byvarlab'"'==`""', `"`by'"', `"`byvarlab'"')
		local bytitle `"`byvarlab' and "'
	}
	local stitle `"`bytitle'`svarlab'"'
	if `"`influence'"'!=`""' local stitle `"`stitle' omitted"'

	
	// need to pass a marker of "`re_model'"=="sa" to DrawTable, but no need to pass `re_model' itself
	local sa = cond("`re_model'"=="sa", "sa", "")
	
	cap nois DrawTableAD `_USE' `outvlist' if `touse', ///
		sortby(`sortby' `obs') study(`study') `options_re' `sa' ///
		labels(`_LABELS') lablen(`lablen') stitle(`"`stitle'"') etitle(`"`effect'"') ///
		by(`by') bystats(`bystats') `eform' method(`method') `cumulative' `influence' ///
		chi2(`chi2') `t' dfkr(`df_kr') q(`Q') qdiff(`Qdiff') isq(`Isqlist') hsq(`Hsqlist') tausq(`tsqlist') ///
		`table' `het' `overall' `subgroup' `breslow'

	if _rc {
		nois disp as err `"Error in {bf:admetan.DrawTableAD}"'
		c_local err "noerr"		// tell admetan not to also report an "error in MainRoutine"
		exit _rc
	}		
		
	tempname coeffs
	mat `coeffs' = r(coeffs)
	return matrix coeffs = `coeffs'


	
	******************************************
	* Prepare dataset for graphics or saving *
	******************************************

	cap confirm numeric variable _rsample
	local _rsample = cond(!_rc, "_rsample", "")

	* Unless -noKEEPVars- (i.e. "`keepvars'"!=""), set up "stored" variables
	// (that is, _ES _seES _LCI _UCI _WT _NN)
	local _NNname = cond(`"`_NN'"'!=`""', "_NN", "")
	local stored `"_ES _seES _LCI _UCI _WT `_NNname'"'
	
	if "`keepvars'"=="" {
		foreach v of local stored {
			if `"``v''"'!=`""' {
				if `"``v''"'!=`"`v'"' {		// If pre-existing var has the same name (i.e. was named _ES etc.), nothing needs to be done.
					cap drop `v'			// Else, first drop any existing var named _ES (e.g. left over from previous analysis)
				
					// Directly rename tempvar if processed by -ipdmetan- (in which case will always be tempvars)
					//  or if created as a tempvar within -admetan- (`tvlist')
					if `"`ipdfile'"'!=`""' | `: list v in tvlist' {
						qui rename ``v'' `v'
					}
					
					// Otherwise, ``v'' is a pre-existing var which needs to be retained at program termination
					// so, use -clonevar-
					else qui clonevar `v' = ``v'' if `touse'
				}
				local `v' `"`v'"'			// for use with subsequent code (`_ES' now contains "_ES", etc.)
			}
		}
		qui compress `stored'
		order `_ES' `_seES' `_LCI' `_UCI' `_rfLCI' `_rfUCI' `_WT' `_NN' `_rsample', last
	}


	* If saving or graph
	if `"`saving'"'!=`""' | `"`graph'"'==`""' {

		// use these local names from now on; their contents may be modified by the next subroutine
		local _BY = cond(`"`byad'"'!=`""', `"`source'"', `"`by'"')
		local _STUDY `"`study'"'
		local _SOURCE `"`source'"'

		
		// `saving' only
		if `"`saving'"'!=`""' {

			// Parse `saving' option first, to extract `stacklabel'
			// Would like to use _prefix_saving here,
			//  but ipdmetan's 'saving' option has additional sub-options
			//  so have to parse manually
			local 0 `saving'
			cap nois syntax anything(id="file name" name=filename) [, STACKlabel REPLACE *]
			if !_rc {
				if "`replace'" == "" {
					local ss : subinstr local filename ".dta" ""
					confirm new file `"`ss'.dta"'
				}
			}
			else {
				di as err "invalid saving() option"
				exit _rc
			}
			local saving `"`"`filename'"', `replace' `options'"'
			
			// if intention is to save, we may as well preserve/keep now
			// but keep `touse' itself for now to make subsequent coding easier
			// (N.B. else, already preserved)
			if `"`rsample'"'==`""' preserve
			qui keep if `touse'
			if `"`summaryonly'"'!=`""' qui drop if inlist(`_USE', 1, 2)

			// Now we can finish off renaming tempvars to permanent varnames
			local savevars `"_USE _STUDY _LABELS"'
			local _BY = cond(`"`byad'"'!=`""', `""', `"`by'"')
			if `"`_BY'"'!=`""'     local savevars `"`savevars' _BY"'
			if `"`_SOURCE'"'!=`""' local savevars `"`savevars' _SOURCE"'
			if `"`rfdist'"'!=`""'  local savevars `"`savevars' _rfLCI _rfUCI"'
			if "`keepvars'"!=""    local savevars : list stored | savevars		// if noKEEPVars, tempvars in `stored' have not yet been renamed
			
			foreach v of local savevars {
				if `"``v''"'!=`""' {

					// Except for string-valued _LABELS,
					//   check if pre-existing var (``v'') has the "correct" value label name (`v').
					// If it does not, drop any existing value label `v', and copy current value label across to `v'.
					if `"`v'"'!=`"_LABELS"' {
						if `"`: value label ``v'''"' != `""' & `"`: value label ``v'''"' != `"`v'"' {
							cap label drop `v'
							label copy `: value label ``v''' `v'
							label values ``v'' `v'
						}
					}
				
					// Similar logic now applies to variable names:
					// Check if pre-existing var has the same name (i.e. was named _BY, _STUDY etc.)
					// If it does not, first drop any existing var named _BY, _STUDY (e.g. left over from previous analysis), then rename.
					if `"``v''"'!=`"`v'"' {
						cap drop `v'
						qui rename ``v'' `v'	// (N.B. no need to use -clonevar- here)
					}
					
					local `v' `"`v'"'			// for use with subsequent code
				}
			}
			
			// if `byad', `by' has been pointing to `source'. For saving, create a separate _BY variable. 
			if `"`byad'"'!=`""' {
				cap drop _BY
				cap label drop _BY
				qui gen byte _BY = _SOURCE
				label copy _SOURCE _BY
				label values _BY _BY
				local _BY `"_BY"'
			}			
			
			qui compress `_USE' `_BY' `_SOURCE' `_STUDY' `_LABELS'
			order `_USE' `_BY' `_SOURCE' `_STUDY' `_LABELS', first			
			
		}	// end if `"`saving'"'!=`""'
		
		quietly {
			tempvar expand

			// _BY will typically be missing for _USE==5, so need to be careful when sorting
			// Hence, generate marker of _USE==5 to sort on *before* _BY
			// (do this now before obs with _USE = 5.5, 5.75 etc. are generated)
			summ `_USE' if `touse', meanonly
			if r(max)==5 {
				tempvar use5
				qui gen byte `use5' = (`_USE'==5)
			}
			local notuse5 = cond("`use5'"=="", "", `"*(!`use5')"')
			
			// variable name (titles) for "_LABELS" or `stacklabel'
			local labtitle = cond(`"`summaryonly'"'!=`""' & `"`by'"'!=`""', `"`byvarlab'"', `"`stitle'"')
			if `"`stacklabel'"'==`""' label variable `_LABELS' `"`labtitle'"'
			else label variable `_LABELS'		// no title if `stacklabel'

			// variable name (title) and format for "_NN" (if appropriate)
			tempvar strlen
			if `"`_NN'"'!=`""' {
				if `"`: variable label `_NN''"'==`""' label variable `_NN' "No. pts"
				gen `strlen' = length(string(`_NN'))
				summ `strlen' if `touse', meanonly
				local fmtlen = max(`r(max)', 3)		// min of 3, otherwise title ("No. pts") won't fit
				format `_NN' %`fmtlen'.0f			// right-justified; fixed format (for integers)
				drop `strlen'
			}

			// Prediction intervals
			if `"`rfdist'"'!=`""' {
				local oldN = _N
				gen byte `expand' = 1 + `touse'*inlist(`_USE', 3, 5)
				expand `expand'
				drop `expand'
				replace `_USE' = 3.5 if `touse' & _n>`oldN' & `_USE'==3
				replace `_USE' = 5.5 if `touse' & _n>`oldN' & `_USE'==5
			}

			
			** `counts' or `oev' string
			if "`counts'"!="" | "`oev'"!="" {
				tokenize `invlist'
				local params : word count `invlist'

				if "`counts'"!="" {
					if `params' == 6 args n1 mean1 sd1 n0 mean0 sd0					// `invlist'
					else {
						tempvar sum_e1 sum_e0
					
						// Log-rank (Peto) HR
						// counts = "events/total in research arm; events/total in control arm"
						if `params'==2 & "`logrank'"!="" & `"`ipdfile'"'!=`""' {
							cap confirm numeric var `lrvlist'
							if _rc {
								nois disp as err `"Error in communication between {bf:ipdmetan} and {bf:admetan}"'
								exit 198
							}
							tokenize `lrvlist'
							args n1 n0 e1 e0
						}

						// Binary outcome (OR, Peto, RR, RD)
						// counts = "events/total in research arm; events/total in control arm"
						else if `params'==4 {
							args e1 f1 e0 f0		// `invlist'
							tempvar n1 n0
							qui gen long `n1' = `e1' + `f1'
							qui gen long `n0' = `e0' + `f0'
						}
						
						else {
							nois disp as err _n `"{bf:counts} is only valid with 2x2 count data or continuous data, so will be ignored"'
							local counts
						}	
					}
				}
				
				if "`oev'"!="" {
					if "`logrank'"=="" {
						disp as err `"Note: {bf:oev} is not applicable without log-rank data and will be ignored"'
						local oev
					}
					else {
						tokenize `invlist'
						args oe v

						label variable `oe' `"O-E(o)"'
						label variable `v'  `"V(o)"'
						format `oe' %6.2f
						format `v' %6.2f
						
						if "`saving'"!="" {
							rename `oe' _OE
							rename `v' _V
							
							local oe _OE
							local v _V
						}
						
						local lcols `"`oe' `v' `lcols'"'
					}
				}
			}
			
			if "`counts'"!="" | "`oev'"!="" {		// open brackets anew in case option(s) has/have been ignored (see above)
				sort `touse' `use5' `_BY' `_USE' `_SOURCE' `obs'
				tempvar _counts1 _counts0 sum_n1 sum_n0 sum_oe sum_v
				
				// overall totals
				if `"`overall'"'==`""' {
					if "`counts'"!="" {
						gen long `sum_n1' = sum(`n1') if `touse'
						gen long `sum_n0' = sum(`n0') if `touse'
						replace `n1' = `sum_n1' if `_USE'==5
						replace `n0' = `sum_n0' if `_USE'==5
						drop `sum_n1' `sum_n0'
								
						if inlist(`params', 2, 4) {
							tempvar sum_e1 sum_e0
							gen long `sum_e1' = sum(`e1') if `touse'
							gen long `sum_e0' = sum(`e0') if `touse'
							replace `e1' = `sum_e1' if `_USE'==5
							replace `e0' = `sum_e0' if `_USE'==5
							drop `sum_e1' `sum_e0'
						}
					}
					if "`oev'"!="" {
						gen double `sum_oe' = sum(`oe') if `touse'
						gen double `sum_v'  = sum(`v')  if `touse'
						replace `oe' = `sum_oe' if `_USE'==5
						replace `v'  = `sum_v'  if `_USE'==5
						drop `sum_oe' `sum_v'
					}
				}
						
				// subgroup totals
				if `"`by'"'!=`""' & `"`subgroup'"'==`""' {
					if "`counts'"!="" {
						by `touse' `use5' `_BY' : gen long `sum_n1' = sum(`n1') if `touse'
						by `touse' `use5' `_BY' : gen long `sum_n0' = sum(`n0') if `touse'
						replace `n1' = `sum_n1' if `_USE'==3
						replace `n0' = `sum_n0' if `_USE'==3
						drop `sum_n1' `sum_n0'
								
						if inlist(`params', 2, 4) {
							by `touse' `use5' `_BY' : gen long `sum_e1' = sum(`e1') if `touse'
							by `touse' `use5' `_BY' : gen long `sum_e0' = sum(`e0') if `touse'
							replace `e1' = `sum_e1' if `_USE'==3
							replace `e0' = `sum_e0' if `_USE'==3
							drop `sum_e1' `sum_e0'
						}
					}
					if "`oev'"!="" {
						by `touse' `use5' `_BY' : gen double `sum_oe' = sum(`oe') if `touse'
						by `touse' `use5' `_BY' : gen double `sum_v'  = sum(`v')  if `touse'
						replace `oe' = `sum_oe' if `_USE'==3
						replace `v'  = `sum_v'  if `_USE'==3
						drop `sum_oe' `sum_v'
					}					
				}
				
				
				** Finally, create `counts' string for forestplot
				if "`counts'"!="" {

					// Titles
					local title1 = cond(`"`group2'"'!=`""', `"`group2'"', `"Treatment"')
					local title0 = cond(`"`group1'"'!=`""', `"`group1'"', `"Control"')
					
					// Binary data & logrank HR
					if inlist(`params', 2, 4) {
						qui gen `_counts1' = string(`e1') + "/" + string(`n1') if inlist(`_USE', 1, 2, 3, 5)
						qui gen `_counts0' = string(`e0') + "/" + string(`n0') if inlist(`_USE', 1, 2, 3, 5)
						label variable `_counts1' `"`title1' n/N"'
						label variable `_counts0' `"`title0' n/N"'
						drop `n1' `n0'							// tidy up
					}
							
					// N mean SD for continuous data
					// counts = "N, mean (SD) in research arm; N, mean (SD) events/total in control arm"
					else {
						tempvar _counts1msd _counts0msd

						qui gen long `_counts1' = `n1' if inlist(`_USE', 1, 2, 3, 5)
						qui gen `_counts1msd' = string(`mean1', "%7.2f") + " (" + string(`sd1', "%7.2f") + ")" if inlist(`_USE', 1, 2)
						label variable `_counts1' "N"
						label variable `_counts1msd' `"`title1' Mean (SD)"'
								
						qui gen long `_counts0' = `n0' if inlist(`_USE', 1, 2, 3, 5)
						qui gen `_counts0msd' = string(`mean0', "%7.2f") + " (" + string(`sd0', "%7.2f") + ")" if inlist(`_USE', 1, 2)
						label variable `_counts0' "N"
						label variable `_counts0msd' `"`title0' Mean (SD)"'
								
						// Find max number of digits in `_counts1', `_counts0'
						summ `_counts1', meanonly
						if r(N) {
							local fmtlen = floor(log10(`r(max)'))
							format `_counts1' %`fmtlen'.0f
						}
						summ `_counts0', meanonly
						if r(N) {
							local fmtlen = floor(log10(`r(max)'))
							format `_counts0' %`fmtlen'.0f
						}
					}

					if "`saving'"!="" {
						rename `_counts1' _counts1
						rename `_counts0' _counts0
						local _counts1 `_counts1'
						local _counts0 `_counts0'

						if `params'==6 {
							rename `_counts1msd' _counts1msd
							rename `_counts0msd' _counts0msd
							local _counts1msd `_counts1msd'
							local _counts0msd `_counts0msd'
						}
					}
					
					local counts `"`_counts1' `_counts1msd' `_counts0' `_counts0msd'"'
					compress `counts'
					local lcols `"`counts' `lcols'"'
				}
			}
			
			// similarly for npts
			if `"`npts'"'!=`""' {
				if `"`_NN2'"'==`""' local lcols `"`_NN'  `lcols'"'		// standard study-level pt nos.
				else {
					if `"`cumulative'"'!=`""' label variable `_NN2' "Cumulative no. pts"
					else label variable `_NN2' "Remaining no. pts"
					local lcols `"`_NN2' `lcols'"'						// cumulative/influence pt nos.
				}
			}
			
			// if `counts' or `npts' requested for display on forest plot,
			//  heterogeneity stats will need to be on a new line
			local extraline = cond(`"`het'"'==`""' & `"`counts'`npts'"'!=`""', `"extraline"', `"`extraline'"')
			
						
			** Insert extra rows for headings, labels, spacings etc.
			//  Note: in the following routines, "half" values of _USE are used temporarily to get correct order
			//        and are then replaced with whole numbers at the end			

			isid `touse' `use5' `_BY' `_USE' `_SOURCE' `obs', missok				
			
			* Subgroup headings
			// N.B. we would like to expand for "all values of _BY except where it is missing"...
			// ...but in practice this wouldn't work as "missing" can be a legitimate value for _BY!!
			// So, instead, we use `notuse5', where we have previously generated `use5' to mark those observations
			//   where we don't want _BY groups to be expanded.
			if `"`by'"'!=`""' {
				if `"`summaryonly'"'==`""' {
					bysort `touse' `_BY' (`obs') : gen byte `expand' = 1 + 2*`touse'*(_n==1)`notuse5'
					expand `expand'
					replace `expand' = !(`expand' - 1)							// `expand' is now 0 if expanded and 1 otherwise (for sorting)
					sort `touse' `_BY' `expand' `_USE' `_SOURCE' `obs'
					by `touse' `_BY' : replace `_USE' = 0 if `touse' & !`expand' & _n==2	// row for headings (before)
					by `touse' `_BY' : replace `_USE' = 4 if `touse' & !`expand' & _n==3	// row for blank line (after)
				}
				else {
					summ `_BY' if `touse', meanonly
					bysort `touse' `_BY' (`obs') : gen byte `expand' = 1 + `touse'*(`_BY'==`r(max)')*(_n==_N)`notuse5'
					expand `expand'
					replace `expand' = !(`expand' - 1)							// `expand' is now 0 if expanded and 1 otherwise (for sorting)
					sort `touse' `_BY' `expand' `_USE' `_SOURCE' `obs'
					by `touse' `_BY' : replace `_USE' = 4 if `touse' & !`expand' & _n==2	// row for blank line (only after last subgroup)
				}
				drop `expand'
							
				// Subgroup spacings & heterogeneity
				if "`subgroup'"=="" & `"`extraline'"'!=`""' {
					bysort `touse' `_BY' (`obs') : gen byte `expand' = 1 + `touse'*(_n==_N)`notuse5'
					expand `expand'
					replace `expand' = !(`expand' - 1)						// `expand' is now 0 if expanded and 1 otherwise (for sorting)
					sort `touse' `_BY' `expand' `_USE' `_SOURCE' `obs'
					by `touse' `_BY' : replace `_USE' = 3.75 if `touse' & !`expand' & _n==2		// extra row for het if lcols
					
					// An extra complexity if `cumulative':
					//  there are no overall diamonds; instead the final _USE==1 observation is marked with `use3'
					// But we *don't* want to mark expanded obs with `use3'.
					if "`use3'"!="" {
						by `touse' `_BY' : replace `use3' = 0 if `touse' & !`expand' & _n==2
					}

					drop `expand'
				}
			}

			// Blank out effect sizes etc. in `expand'-ed rows
			foreach x of varlist `_LABELS' `_ES' `_seES' `_LCI' `_UCI' `_WT' `_NN' `lcols' `rcols' {
				cap confirm numeric var `x'
				if !_rc replace `x' = .  if `touse' & !inlist(`_USE', 1, 2, 3, 5)
				else    replace `x' = "" if `touse' & !inlist(`_USE', 1, 2, 3, 5)
			}
			
			if `"`summaryonly'"'==`""' {
				if `"`_STUDY'"'!=`""' {
					replace `_STUDY' = . if `touse' & !inlist(`_USE', 1, 2)
				}
				
				// don't blank out `_SOURCE' if `byad' and not `saving'
				//  since in that case `_SOURCE' is doing the job of `_BY'
				if `"`_SOURCE'"'!=`""' & !(`"`byad'"'!=`""' & `"`saving'"'==`""') {
					replace `_SOURCE'=. if `touse' & !inlist(`_USE', 1, 2)
				}
			}
			
			// extra row to contain what would otherwise be the leftmost column heading if `stacklabel' specified
			// (i.e. so that heading can be used for forestplot stacking)
			if `"`stacklabel'"' != `""' {
				local newN = _N + 1
				set obs `newN'
				replace `touse' = 1 in `newN'
				replace `_USE' = -1 in `newN'
				if "`use5'"=="" {
					tempvar use5						// we need `use5' here, regardless of whether it's needed elsewhere 
					gen byte `use5' = 0 if `touse'
				}
				replace `use5' = -1 in `newN'
				replace `_LABELS' = `"`labtitle'"' in `newN'
			}

			
			** Now insert label info into new rows
			
			// "ovstat" is a synonym for "hetstat"
			local hetstat = cond(`"`hetstat'"'==`""', `"`ovstat'"', `"`hetstat'"')
			
			// "overall" labels
			if `"`overall'"'==`""' {
				local ovlabel
				if `"`het'"'==`""' {
					local Qdf = `k' - 1
					
					// tausq-related stuff (incl. Qr) is meaningless for M-H, and also for Peto or Breslow unless RE
					// (N.B. although this *does* include sensitivity analysis)
					if "`hetstat'"=="q" | "`re_model'"=="mh" ///
						| ("`re_model'"=="fe" & ("`method'"=="peto" | "`breslow'"!="")) {
							local ovlabel "(Q = " + string(`Q', "%5.2f") + " on `Qdf' df)"
					}
					else {
						local ovlabel "(I-squared = " + string(100*`Isq', "%5.1f")+ "%)"
					}
					
					// Overall heterogeneity - extra row if lcols
					if `"`extraline'"'!=`""' {
						local newN = _N + 1
						set obs `newN'
						replace `touse' = 1    in `newN'
						replace `_USE'  = 5.75 in `newN'
						if "`use5'"!="" {
							replace `use5' = 1 in `newN'
						}
						replace `_LABELS' = "`ovlabel'" if `_USE'==5.75
						local ovlabel				// ovlabel on line below so no conflict with lcols; then clear macro
					}
				}
				replace `_LABELS' = "Overall `ovlabel'" if `_USE'==5
			}

			// subgroup ("by") headings & labels
			if `"`_BY'"'!=`""' {

				// tausq-related stuff (incl. Qr) is meaningless for M-H, and also for Peto or Breslow unless RE
				// (N.B. although this *does* include sensitivity analysis)
				if "`hetstat'"!="q" & "`re_model'"!="mh" ///
					& !("`re_model'"=="fe" & ("`method'"=="peto" | "`breslow'"!="")) {

					tempname Isqmat
					local nr = rowsof(`bystats')
					mat `Isqmat' = J(`nr', 1, .)
					
					local sigmasqcol = colnumb(`bystats', "sigmasq")
					local tausqcol   = colnumb(`bystats', "tausq")
						
					forvalues r = 1/`nr' {
						mat `Isqmat'[`r', 1] = `bystats'[`r', `tausqcol'] / (`bystats'[`r', `tausqcol'] + `bystats'[`r', `sigmasqcol'])
					}
				}
			
				forvalues i=1/`nby' {
					local byi : word `i' of `bylist'
					
					// headings
					local bylabi : label (`_BY') `byi'
					if `"`summaryonly'"'==`""' {
						replace `_LABELS' = "`bylabi'" if `_USE'==0 & `_BY'==`byi'
					}
					
					// labels + heterogeneity
					if `"`subgroup'"'==`""' {
						
						local sglabel = cond(`"`summaryonly'"'!=`""', `"`bylabi'"', `"Subgroup"')
						local sghetlab
					
						if `"`het'"'==`""' {
						
							// tausq-related stuff (incl. Qr) is meaningless for M-H, and also for Peto or Breslow unless RE
							// (N.B. although this *does* include sensitivity analysis)
							if "`hetstat'"=="q" | "`re_model'"=="mh" ///
								| ("`re_model'"=="fe" & ("`method'"=="peto" | "`breslow'"!="")) {
									
								local Qi  = `bystats'[`i', `=colnumb(`bystats', "Q")']
								local dfi = `bystats'[`i', `=colnumb(`bystats', "k")'] - 1
								local sghetlab = "(Q = " + string(`Qi', "%5.2f") + " on `dfi' df)"
							}
							else {
								local Isqi = `Isqmat'[`i', 1]
								local sghetlab = "(I-squared = " + string(100*`Isqi', "%5.1f")+ "%)"
							}
							if `"`extraline'"'!=`""' {
								replace `_LABELS' = "`sghetlab'" if `_USE'==3.75 & `_BY'==`byi'
								local sghetlab			// sghetlab on line below so no conflict with lcols; then clear macro
							}
						}
						replace `_LABELS' = `"`sglabel' `sghetlab'"' if `_USE'==3 & `_BY'==`byi'
					}
				}
				
				// add between-group heterogeneity info if appropriate (fixed-effects only)
				// (N.B. `overall' as o/w `Qdiff' not calculated; `subgroup' as o/w `Qsum' not calculated)
				if inlist("`re_model'", "fe", "mh") & `"`overall'`subgroup'`het'"'==`""' {
					local newN = _N + 1
					set obs `newN'
					replace `touse' = 1   in `newN'
					replace `_USE'  = 4.75 in `newN'
					if "`use5'"!="" {
						replace `use5' = 0 in `newN'
					}
					local Qdiffp = chi2tail(`nby'-1, `Qdiff')
					replace `_LABELS' = "Heterogeneity between groups: p = " + string(`Qdiffp', "%5.3f") in `newN'
				}
			}		// end if `"`_BY'"'!=`""'
			
			// Prediction intervals
			if `"`rfdist'"'!=`""' {
				replace `_LABELS' = "with estimated prediction interval" if inlist(`_USE', 3.5, 5.5)
				replace `_LCI' = `_rfLCI' if inlist(`_USE', 3.5, 5.5)
				replace `_UCI' = `_rfUCI' if inlist(`_USE', 3.5, 5.5)
				drop if missing(`_LCI', `_UCI') & inlist(`_USE', 3.5, 5.5)		// if prediction interval was undefined
			}
			
			// Vaccine efficacy
			if `"`efficacy'"'!=`""' {
				if "`saving'"!="" local _VE "_VE"
				else tempvar _VE
			
				gen `_VE' = string(100*(1 - exp(`_ES')), "%4.0f") + " (" ///
					+ string(100*(1 - exp(`_LCI')), "%4.0f") + ", " ///
					+ string(100*(1 - exp(`_UCI')), "%4.0f") + ")" if inlist(`_USE', 1, 3, 5)
				
				label variable `_VE' "Vaccine efficacy (%)"
				local rcols `"`_VE' `rcols'"'
				
				gen `strlen' = length(`_VE')
				summ `strlen', meanonly
				format %`r(max)'s `_VE'
				compress `_VE'
				drop `strlen'
			}
			
 			** Sort, and tidy up
			sort `touse' `use5' `_BY' `_USE' `_SOURCE' `obs'
			cap drop `use5'
			
			// Tidy up `_USE'
			replace `_USE' = 0 if `_USE' == -1
			replace `_USE' = 6 if `_USE' == 4
			replace `_USE' = 3 if `_USE' == 3.5
			replace `_USE' = 5 if `_USE' == 5.5
			replace `_USE' = 4 if inlist(`_USE', -0.5, 2.5, 3.75, 4.75, 5.75)
			if `"`keepall'"'!=`""' & `"`keeporder'"'!=`""' {
				replace `_USE' = 2 if `_USE'==1 & `olduse'==2
				drop `olduse'
			}
			
			// Having added "overall", het. info etc., re-format _LABELS using study names only
			// (otherwise the "adjust" routine in forestplot.ProcessColumns can't have any effect)
			gen `strlen' = length(`_LABELS')
			if `"`summaryonly'"'==`""' {
				summ `strlen' if `touse' & inlist(`_USE', 1, 2), meanonly
			}
			else summ `strlen' if `touse', meanonly			// alternative if no study estimates (`summaryonly' should be the only reason for this)
			format `_LABELS' %-`r(max)'s					// left-justified; length equal to longest study name
			drop `strlen'

		}	// end quietly
		
		// sort out plotid if byad, then add to forestplot options
		if `"`plotid'"'!=`""' {
			local 0 `plotid'
			syntax [name] [, *]
			if `"`namelist'"'==`"_BYAD"' {
				local plotid `"`_SOURCE', `options'"'
			}
			local forestplot `"`macval(forestplot)' plotid(`plotid')"'
		}

		
		** Pass to forestplot
		if `"`graph'"'==`""' {
			if "`cumulative'"!="" {						// cumulative only; not influence
				qui replace `_USE' = 3 if `use3'==1		// ==1 in case new obs added, with `use3' missing
				drop `use3'
			}
			if "`summaryonly'"!="" {
				qui replace `touse'= 0 if inlist(`_USE', 1, 2)
			}
		
			// cumulative/influence notes for forestplot
			if `"`warning'"'==`""' & `"`fpnote'"'!=`""' & !inlist("`re_model'", "fe", "mh") & `"`altwt'"'!=`""' {
				if `"`cumulative'"'!=`""' {
					local fpnote `""`fpnote';" "changes in heterogeneity may mean that cumulative weights are not monotone increasing""'
				}
				else if `"`influence'"'!=`""' {
					local fpnote `""`fpnote'," "expressed relative to the total weight in the overall model""'
				}
			}
			// June 2016: in future, could maybe add other warnings here, e.g. continuity correction??

			cap nois forestplot `_ES' `_LCI' `_UCI' if `touse', wgt(`_WT') use(`_USE') labels(`_LABELS') by(`_BY') ///
				admetan `cumulative' `interaction' `eform' `keepall' effect(`effect') ///
				lcols(`lcols') rcols(`rcols') rfdist(`rfdlist') note(`fpnote') `forestplot'

			if _rc {
				if `"`err'"'==`""' {
					if _rc==1 nois disp as err `"User break in {bf:forestplot}"'
					else nois disp as err `"Error in {bf:forestplot}"'
				}
				c_local err "noerr"		// tell admetan not to also report an "error in MainRoutine"
				exit _rc
			}
			
			return add
			/*
			// we are under -preserve- here, but forestplot.ado may have added some observations;
			// remove these before saving or returning control to ipdmetan.ado
			qui drop if missing(`touse')
			cap assert inrange(`_USE', 0, 6)
			*/
		}
		

		** Finally, save dataset
		if `"`saving'"'!=`""' {
			keep `_USE' `_BY' `_SOURCE' `_STUDY' `_LABELS' `_ES' `_seES' `_LCI' `_UCI' `_WT' `_NN' `_rfLCI' `_rfUCI' `lcols' `rcols'
			qui save `saving'
		}
	
	}	// end if `"`saving'"'!=`""' | `"`graph'"'==`""'

end	




***************************************************************
	
* PerformMetaAnalysis
// (subroutine of MainRoutine)

// Carries out meta-analysis based on a particular input varlist (which could differ for AD and IPD)
//   - processes input varlist to create "pooling" varlist (ProcessPoolingVarlist)
//   - carry out pooling itself (in MetaAnalysisLoop subroutine, separately overall and by groups);
//       first looping over subgroups, then overall

// Nov 2015: N.B. `summstat' is optional; if generic I-V, no need for it.

program define PerformMetaAnalysis, rclass sortpreserve

	syntax varlist(min=3 max=7 numeric) [if] [in], METHOD(string) ///
		[SORTBY(varlist) SUMMSTAT(string) REMODEL(string) BY(string) BYLIST(string) BYSTATS(name) ///
		LEVEL(real 95) CC(real .5) CHI2opt noOVerall noSUbgroup OVWT SGWT WGT(varname numeric) ///
		BREslow LOGRank OUTVLIST(namelist min=5 max=8) RFDLIST(namelist min=2 max=2) RFLEVEL(passthru) DF(varname numeric) ///
		TOPROCESS(varname) INV2list(varlist numeric) XOUTVLIST(varlist numeric) CUmulative INFluence * ]
		
	marksample touse, novarlist	// -novarlist- option prevents -marksample- from setting `touse' to zero if any missing values in `varlist'
								// we want to control this behaviour ourselves, e.g. by using KEEPALL option

	local re_model `remodel'		// for clarity/consistency
	
	tokenize `outvlist'
	args _ES _seES _LCI _UCI _WT _NN
	gettoken _USE invlist : varlist


	* Create list of "pooling" tempvars to pass to ProcessPoolingVarlist
	// and thereby create final generic list of "pooling" vars to use within MetaAnalysisLoop
	// (i.e. tempvars that are only needed within this subroutine)
	
	// Logic:
	// If M-H pooling, then M-H heterogeneity
	// If Peto pooling, then Peto heterogeneity
	// If generic I-V with 2x2 count data, then either Cochran or M-H heterogeneity (or Breslow-Day, but only if OR)
	
	// So:
	// M-H heterogeneity if (a) M-H pooling or (b) generic I-V (fe, re) with 2x2 count data and cochran/breslow not specified (M-H is default in this situation)
	// Peto heterogeneity if (a) Peto pooling or (b) generic I-V (fe, re) with 2x2 count data and cochran/breslow not specified AND OR/HR ONLY
	// Breslow-Day heterogeneity only if OR and user-specified
	// Cochran heterogeneity only if generic I-V (and user-specified if necessary)
	
	// So:
	// If OR + M-H then het can be only be M-H
	// If OR + Peto then het can only be Peto
	// If OR + RE I-V then het can be M-H (default), Peto, Breslow or Cochran -- the only situation where "peto" option can be combined
	// If OR + FE I-V then het can be Cochran (default) or Breslow

	// If HR + Peto then het can only be Peto
	// If HR + RE I-V then het can be Peto (default) or Cochran
	
	// If RR/RD + M-H then het can only be M-H
	// If RR/RD + RE I-V then het can be M-H (default) or Cochran
	
	// If anything else + FE I-V then het can only be Cochran
	
	local inv2list = cond(`"`inv2list'"'!=`""', `"`inv2list'"', `"`invlist'"')
	local params : word count `inv2list'
	
	if `params' > 3 | "`logrank'"!="" {			// all except generic inverse-variance input

		if `params' == 4 {		// Binary outcome (OR, Peto, RR, RD)
			tempvar r1 r0
			local binvlist `"`r1' `r0'"'	// r1 = total in research arm ( = a + b); r0 = total in control arm ( = c + d)
											// `binvlist' = tempvars needed for all binary outcomes
			if "`summstat'"=="or" {
				tempvar ea va c1 c0			// c1 = total events ( = a + c); c0 = total non-events ( = b + d)
				local orvlist `"`c1' `c0' `ea' `va'"'			// extra OR-specific tempvars (e.g. for Peto method or chi2 test)

				if "`method'"=="mh" {							// extra tempvars for Mantel-Haenszel OR and/or het
					tempvar r s pr ps qr qs v
					local mhvlist `"`r' `s' `pr' `ps' `qr' `qs' `v'"'
				}
				if "`method'"=="peto" {							// extra tempvars for Peto OR and/or het
					tempvar oe p
					local petovlist `"`oe' `p'"'
				}
			}
			
			else if inlist("`summstat'", "rr", "irr", "rrr") {	// RR/IRR/RRR
				tempvar r s v p
				local mhvlist `"`r' `s' `v' `p'"'				// note: `p' only needed if MH; others needed regardless
			}
			
			else if "`summstat'" == "rd" {						// RD
				tempvar v rdwt rdnum vnum
				local mhvlist `"`v' `rdwt' `rdnum' `vnum'"'		// note: `rdwt', `rdnum', `vnum' only needed if MH
			}
		}
		
		else if "`logrank'"!="" {		// logrank HR (O-E & V -- already supplied in `invlist')
			assert `params'==2
			tempvar p
			local petovlist `"`p'"'
		}

		//  Generate study-level effect size variables `_ES' and `_seES',
		//  plus variables used to generate overall/subgroup statistics
		local toprocess = cond(`"`toprocess'"'==`""', `""', `" & `toprocess'"')
		cap nois ProcessPoolingVarlist `_USE' `inv2list' if `touse' `toprocess', ///
			outvlist(`outvlist') summstat(`summstat') method(`method') remodel(`re_model') cc(`cc') ///
			binvlist(`binvlist') orvlist(`orvlist') mhvlist(`mhvlist') petovlist(`petovlist') `breslow' `logrank'
		
		if _rc {
			nois disp as err `"Error in {bf:admetan.ProcessPoolingVarlist}"'
			c_local err "noerr"		// tell admetan not to also report an "error in PerformMetaAnalysis"
			exit _rc
		}
		
		local qvlist   `"`r(qvlist)'"'		// "heterogeneity" varlist (not needed for I-V)
		local chi2vars `"`r(chi2vars)'"'	// varlist for chi2 test (if applicable)
		local aervars  `"`r(aervars)'"'		// varlist for average event rate (if applicable)
	
	}	// end if `params' > 3 | "`logrank'"!=""
	
	local pvlist = cond(`"`r(pvlist)'"'!=`""', `"`r(pvlist)'"', `"`_ES' `_seES'"')		// "pooling" varlist


	// Generate `_seES' in the special case where `_ES', `_LCI' and `_UCI' are provided; assume normal distribution
	qui replace `_seES' = (`_UCI' - `_LCI') / (2*invnormal(.5 + `level'/200)) if `touse' & `_USE'==1 ///
		& missing(`_seES') & !missing(`_UCI', `_LCI')
	
	// We should now have _ES and _seES defined throughout.
	// Quick double-check that studies with insufficient data are identified ("`_USE'==2")
	// (should already have been done by either -ipdmetan- or -ProcessInputVarlist-)
	// (but in special cases, e.g. if `nocc', may still be some missings)
	qui replace `_USE'=2 if `touse' & `_USE'==1 & missing(`_ES', `_seES')
	qui count if `_USE'==1
	if !r(N) exit 2000	
		
	// if B0 estimator, must have _NN for all studies with an effect size (i.e. `_USE'==1)
	if "`re_model'"=="b0" {
		cap {
			confirm numeric var `_NN'
			assert `_NN'>=0 & !missing(`_NN') if `_USE'==1
		}
		if _rc {
			nois disp as err `"Participant numbers not available for all studies; cannot calculate tau{c 178} estimator B0"'
			exit 198
		}
		local npts `_NN'	// to send to PerformPooling (within MetaAnalysisLoop)
	}						// N.B. `npts' is otherwise undefined here

	// setup for subgroups and/or cumulative MA
	tempname Q Qsum k n
	scalar `Q'    = 0
	scalar `Qsum' = 0
	
	
	** Overall analysis
	// (but NOT if cumulative and `by' specified.  In that case, only need to run `by' loop.)
	// how to differentiate between cumulative and influence? (could always parse their options, of course)
	local nrfd = 0		// initialize
	
	if (`"`overall'"'==`""' | `"`ovwt'"'!=`""') {

		cap nois MetaAnalysisLoop `_USE' `pvlist' if `touse' & inlist(`_USE', 1, 5), outvlist(`outvlist') ///
			sortby(`sortby') remodel(`re_model') method(`method') rfdlist(`rfdlist') xoutvlist(`xoutvlist') ///
			chi2vars(`chi2vars') aervars(`aervars') qvlist(`qvlist') npts(`npts') wgt(`wgt') `breslow' ///
			summstat(`summstat') level(`level') `rflevel' df(`df') `ovwt' `cumulative' `influence' `options'
			
		if _rc {
			if `"`err'"'==`""' {
				if _rc==1 nois disp as err `"User break in {bf:admetan.MetaAnalysisLoop}"'
				else nois disp as err `"Error in {bf:admetan.MetaAnalysisLoop}"'
			}
			c_local err "noerr"		// tell admetan not to also report an "error in PerformMetaAnalysis"
			exit _rc
		}
		
		if `"`re_model'"'!=`"`r(re_model)'"' {
			if !inlist("`re_model'", "fe", "mh") {
				nois disp as err "Note: Only one estimate found; random-effects model not used"
			}
			local subgroup "nosubgroup"		// certainly can't do subgroups if you can't do overall
			return local re_model  `r(re_model)'
			return local vce_model `r(vce_model)'
		}

		scalar `k' = r(k)			// overall number of studies
		scalar `n' = r(n)			// overall number of participants
		return add					// add anything else returned by PerformPooling (within MetaAnalysisLoop) to return list of PerformMetaAnalysis
									// e.g. r(OR), r(RR); tsq-related stuff; chi2
	}	// end if "`overall'"==""

	
	** Analysis within study subgroups (`by')
	local nmiss = 0		// initialize
	local nrc = 0		// initialize
	local nsg = 0		// initialize
	tempname kOV nOV
	scalar `kOV' = 0	// initialize
	scalar `nOV' = .	// initialize
	
	if (`"`by'"'!=`""' & `"`subgroup'"'==`""') | `"`sgwt'"'!=`""' {

		qui levelsof `by' if `touse' & `_USE'!=5, missing local(bylist)		// "missing" since `touse' should already be appropriate for missing yes/no
																			// but `_USE'!=5 since that will be missing anyway
		local i = 0
		foreach byi of local bylist {
		
			cap nois MetaAnalysisLoop `_USE' `pvlist' if `touse' & `by'==`byi' & inlist(`_USE', 1, 3), outvlist(`outvlist') ///
				sortby(`sortby') remodel(`re_model') method(`method') rfdlist(`rfdlist') xoutvlist(`xoutvlist') ///
				chi2vars(`chi2vars') aervars(`aervars') qvlist(`qvlist') npts(`npts') wgt(`wgt') `breslow' ///
				summstat(`summstat') level(`level') `rflevel' df(`df') `sgwt' `cumulative' `influence' `options' 

			if _rc {
				if _rc==1 {
					nois disp as err "User break in {bf:admetan.MetaAnalysisLoop}"
					c_local err "noerr"		// tell admetan not to also report an "error in PerformMetaAnalysis"
					exit _rc
				}
				else if !`nrc' {			// only display the error once!
					if _rc==2000 nois disp as err "Note: insufficient data in one or more subgroups" 
					else nois disp as err "Note: pooling failed in one or more subgroups" 
					local nrc = 1
				}
			}
			else if `"`r(re_model)'"'!=`"`re_model'"' {
				if !`nsg' {					// only display the error once!
					nois disp as err "Note: one or more subgroups contain only a single valid estimate" 
					local nsg = 1
				}
			}

			// update `bystats' matrix and return subgroup stats (if PerformPooling within MetaAnalysisLoop ran successfully)
			local ++i
			
			if !_rc {
			
				// update running sums
				scalar `Qsum' = `Qsum' + r(Q)
				scalar `kOV'  = `kOV'  + r(k)

				// update matrices
				mat `bystats'[`i', `=colnumb(`bystats', "_BY")'] = `byi'
				mat `bystats'[`i', `=colnumb(`bystats', "Q")'] = r(Q)
				mat `bystats'[`i', `=colnumb(`bystats', "k")'] = r(k)

				// chi2 statistic (OR only)
				if "`chi2opt'"!="" {
					mat `bystats'[`i', `=colnumb(`bystats', "chi2")'] = r(chi2)
				}
					
				// tausq-related stuff (incl. Qr) is meaningless for M-H, and also for Peto or Breslow unless RE
				// (N.B. although this *does* include sensitivity analysis)
				if "`r(re_model)'"!="mh" & !("`r(re_model)'"=="fe" & ("`method'"=="peto" | "`breslow'"!="")) {
					
					// If we are doing this for AD separately, and if IPD used M-H, tausq will not be valid
					cap assert !missing(colnumb(`bystats', "tausq"))
					if !_rc {
						mat `bystats'[`i', `=colnumb(`bystats', "sigmasq")'] = r(sigmasq)
						mat `bystats'[`i', `=colnumb(`bystats', "tausq")']   = r(tausq)

						if inlist("`r(re_model)'", "dlb", "mp", "ml", "pl", "reml") | inlist("`r(vce_model)'", "gamma", "kr") {
							mat `bystats'[`i', `=colnumb(`bystats', "tsq_lci")'] = r(tsq_lci)
							mat `bystats'[`i', `=colnumb(`bystats', "tsq_uci")'] = r(tsq_uci)
						}
						if `"`r(vce_model)'"'==`"kr"' { 
							mat `bystats'[`i', `=colnumb(`bystats', "df_kr")'] = r(df_kr)
						}
					}
				}
			
				// if byad, store eff1,2 and se_eff1,2 as scalars to be returned
				if `"`byad'"'!=`""' {
					return scalar eff`i'    = r(eff)
					return scalar se_eff`i' = r(se_eff)
				}

				// subgroup numbers of participants
				if `"`_NN'"'!=`""' {
					mat `bystats'[`i', `=colnumb(`bystats', "_NN")'] = r(n)
					scalar `nOV' = cond(missing(`nOV'), 0, `nOV') + r(n)
				}
			}
			
		}	// end foreach byi of local bylist

		if (`"`overall'"'==`""' | `"`ovwt'"'!=`""') {
			assert `kOV' == `k'		// check that sum of subgroup `k's = previously-calculated overall `k'
			assert `nOV' == `n'		// check that sum of subgroup `n's = previously-calculated overall `n'
		}
		else {
			scalar `k' = `kOV'		// if no previously-calculated overall `k', *define* it to be sum of subgroup `k's
			scalar `n' = `nOV'		// if no previously-calculated overall `n', *define* it to be sum of subgroup `n's
		}
		return scalar Qsum  = `Qsum'
		
	}		// end if `"`by'"'!=`""'

	// Error message re prediction intervals with < 3 studies
	if `nrfd' {
		disp as err "Note: Prediction intervals are undefined if less than three studies"
	}

		
	* Finalise numbers of participants
	if `"`_NN'"'!=`""' {
		summ `_NN' if `touse' & `_USE'==1, meanonly
		cap assert `r(N)' == `k'
		if _rc {
			if `"`by'"'!=`""' & `"`subgroup'"'==`""' cap assert !`nmiss'
			if !_rc disp as err "Note: Patient numbers are missing in one or more trials"
			if `"`xoutvlist'"'!=`""' {
				disp as err "      " + upper(`cumulative'`influence') + " patient numbers cannot be returned"
				c_local _NN				// clear macro _NN, so that by-trial patient numbers are no longer available
			}
		}
		else return scalar totnpts = `n'
	}
	return scalar k = `k'
	
end




**************************************************************

* ProcessPoolingVarlist
// subroutine of PerformMetaAnalysis

// subroutine to processes (non-IV) input varlist to create appropriate varlist for the specified pooling method
// That is, generate study-level effect size variables,
// plus variables used to generate overall/subgroup statistics

program define ProcessPoolingVarlist, rclass

	syntax varlist(min=3 max=7 default=none) [if] [in], ///
		OUTVLIST(namelist min=5 max=8) SUMMSTAT(string) METHOD(string) REMODEL(string) ///
		[BREslow LOGRank noINTeger CC(real .5) ///
		BINVLIST(namelist min=2 max=2) ORVLIST(namelist min=4 max=4) ///
		MHVLIST(namelist min=4 max=7) PETOVLIST(namelist max=2) ]
	
	local re_model `remodel'
	marksample touse, novarlist
	
	// unpack varlists
	tokenize `outvlist'
	args _ES _seES _LCI _UCI _WT _NN
	gettoken _USE invlist : varlist
	tokenize `invlist'
	local params : word count `invlist'
	
	// all except logrank HR
	if `params' > 3 {
	
		// generate effect size vars
		// (N.B. gen as tempvars for now, to accommodate inverse-variance;
		//       but will be renamed to permanent variables later if appropriate)
		
		// Binary outcome (OR, RR, RD)
		if `params' == 4 {
			
			assert inlist("`summstat'", "or", "rr", "irr", "rrr", "rd")
			args e1 f1 e0 f0		// events & non-events in trt; events & non-events in control (aka a b c d)

			tokenize `binvlist'
			args r1 r0
			local type = cond("`integer'"=="", "long", "double")
			qui gen `type' `r1' = `e1' + `f1' if `touse'		// total in trt arm (aka a + b)
			qui gen `type' `r0' = `e0' + `f0' if `touse'		// total in control arm (aka c + d)
			qui replace   `_NN' = `r1' + `r0' if `touse'		// overall total
			
			return local aervars `"`e1' `r1' `e0' `r0'"'

			// zero-cell adjustments
			tempvar zeros
			qui gen byte `zeros' = (`_USE'==1) & (`e1'*`f1'*`e0'*`f0'==0) * (`cc' > 0)
			summ `zeros' if `touse', meanonly
			if r(N) {
				tempvar e1_cont f1_cont e0_cont f0_cont t_cont
				qui gen double `e1_cont' = cond(`zeros', `e1' + `cc', `e1') if `touse'
				qui gen double `f1_cont' = cond(`zeros', `f1' + `cc', `f1') if `touse'
				qui gen double `e0_cont' = cond(`zeros', `e0' + `cc', `e0') if `touse'
				qui gen double `f0_cont' = cond(`zeros', `f0' + `cc', `f0') if `touse'
					
				tempvar r1_cont r0_cont t_cont
				qui gen double `r1_cont' = `e1_cont' + `f1_cont'
				qui gen double `r0_cont' = `e0_cont' + `f0_cont'
				qui gen double  `t_cont' = `r1_cont' + `r0_cont'
			}
			else {
				local e1_cont `e1'
				local f1_cont `f1'
				local e0_cont `e0'
				local f0_cont `f0'
				local r1_cont `r1'
				local r0_cont `r0'
				local t_cont `_NN'
			}
			
			 // now branch by outcome measure
			if "`summstat'"=="or" {
			
				// extra OR-specific vars
				tokenize `orvlist'
				args c1 c0 ea va
				local a `e1'									// synonym; makes it easier to read code involving Peto and chi2
				qui gen `type' `c1' = `e1' + `e0'				// total events (aka a + c)
				qui gen `type' `c0' = `f1' + `f0'				// total non-events (aka b + d)
				qui gen double `ea' = (`r1'*`c1')/ `_NN'		// expected events in trt arm, i.e. E(a) where a = e1
				qui gen double `va' = `r1'*`r0'*`c1'*`c0'/( `_NN'*`_NN'*(`_NN' - 1))		// V(a) where a = e1

				// setup for chi-squared test
				return local chi2vars `"`a' `ea' `va'"'

				// Peto method
				if "`method'"=="peto" {
					tokenize `petovlist'
					args oe p
					qui gen double `oe' = `a' - `ea'
					
					qui replace `_ES'   = `oe'/`va'    if `touse' & `_USE'==1		// logOR or logHR
					qui replace `_seES' = 1/sqrt(`va') if `touse' & `_USE'==1		// selogOR or selogHR
		
					qui gen double `p' = (`oe'^2)/`va'
					local qvlist `"`oe' `va' `p'"'		// Peto het -- N.B. Peto pooling is equivalent to I-V (that is, as a method, for a given _ES and _seES);
				}										// but *heterogeneity* uses a different calculation.

				// M-H or I-V method
				else {

					// calculate individual ORs and variances using cc-adjusted counts
					// (on the linear scale, i.e. logOR)
					qui replace `_ES'   = ln(`e1_cont'*`f0_cont') - ln(`f1_cont'*`e0_cont')           if `touse' & `_USE'==1
					qui replace `_seES' = sqrt(1/`e1_cont' + 1/`f1_cont' + 1/`e0_cont' + 1/`f0_cont') if `touse' & `_USE'==1
			
					// setup for Mantel-Haenszel method
					if "`method'"=="mh" {
						tokenize `mhvlist'
						args r s pr ps qr qs v
						qui gen double `r' = `e1_cont'*`f0_cont'/`t_cont'								// so r/s = ad/bc = standard OR
						qui gen double `s' = `f1_cont'*`e0_cont'/`t_cont'
						qui gen double `v' = 1/`e1_cont' + 1/`f1_cont' + 1/`e0_cont' + 1/`f0_cont'		// = standard Var(OR)
						
						tempvar p q
						qui gen double `p'  = (`e1_cont' + `f0_cont')/`t_cont'
						qui gen double `q'  = (`f1_cont' + `e0_cont')/`t_cont'
						qui gen double `pr' = `p'*`r'
						qui gen double `ps' = `p'*`s'
						qui gen double `qr' = `q'*`r'
						qui gen double `qs' = `q'*`s'

						local pvlist `"`r' `s' `pr' `ps' `qr' `qs'"'							// M-H pooling
					}

					local qvlist = cond("`breslow'"!="", `"`r1' `r0' `c1' `c0' `a'"', ///		// Breslow-Day het
						cond("`method'"=="mh", `"`v' `_ES' `r' `s'"', `""'))					// M-H het; else het same as I-V
					
				}	/* end non-Peto OR*/
			} 		/* end OR */
			
			// setup for RR/IRR/RRR 
			else if inlist("`summstat'", "rr", "irr", "rrr") {
				tokenize `mhvlist'
				args r s v p
				qui gen double `r' = `e1_cont'*`r0_cont' / `t_cont'
				qui gen double `s' = `e0_cont'*`r1_cont' / `t_cont'
				qui gen double `v' = 1/`e1_cont' + 1/`e0_cont' - 1/`r1_cont' - 1/`r0_cont'
				qui replace `_ES'   = ln(`r'/`s') if `touse' & `_USE'==1		// logRR 
				qui replace `_seES' = sqrt(`v')   if `touse' & `_USE'==1		// selogRR
				
				// setup for Mantel-Haenszel method
				if "`method'"=="mh" {
					qui gen double `p' = `r1_cont'*`r0_cont'*(`e1_cont' + `e0_cont')/(`t_cont'*`t_cont') - `e1_cont'*`e0_cont'/`t_cont'
					local pvlist `"`p' `r' `s'"'								// M-H pooling
					local qvlist `"`v' `_ES' `r' `s'"'							// M-H het
				}
			}
			
			// setup for RD
			else if "`summstat'" == "rd" {
				tokenize `mhvlist'
				args v rdwt rdnum vnum
				qui gen double `v'  = `e1_cont'*`f1_cont'/(`r1_cont'^3) + `e0_cont'*`f0_cont'/(`r0_cont'^3)
				qui replace `_ES'   = `e1'/`r1' - `e0'/`r0' if `touse' & `_USE'==1
				qui replace `_seES' = sqrt(`v')             if `touse' & `_USE'==1

				// setup for Mantel-Haenszel method
				// N.B. `rdwt' and `rdnum' are calculated *without* cc adjustment, to ensure 0/n1 v 0/n2 really *is* RD=0
				if "`method'"=="mh" {
					qui gen double `rdwt'  = `r1'*`r0'/ `_NN'
					qui gen double `rdnum' = (`e1'*`r0' - `e0'*`r1')/ `_NN'
					qui gen double `vnum'  = (`e1_cont'*`f1_cont'*(`r0_cont'^3) + `e0_cont'*`f0_cont'*(`r1_cont'^3)) /(`r1_cont'*`r0_cont'*`t_cont'*`t_cont')

					local pvlist `"`rdwt' `rdnum' `vnum'"'					// M-H pooling
					local qvlist `"`v' `_ES' `rdwt' `rdnum'"'				// M-H het
				}
			}	// end "rd"

		}	/* end if `params' == 4 */
		
		else {
		
			assert `params' == 6
		
			// N mean SD for continuous data
			assert inlist("`summstat'", "wmd", "smd")
			args n1 mean1 sd1 n0 mean0 sd0

			qui replace `_NN' = `n1' + `n0' if `touse'
				
			if "`summstat'" == "wmd" {
				qui replace `_ES'   = `mean1' - `mean0'                     if `touse' & `_USE'==1
				qui replace `_seES' = sqrt((`sd1'^2)/`n1' + (`sd0'^2)/`n0') if `touse' & `_USE'==1
			}
			else {				// summstat = SMD
				tempvar s
				qui gen double `s' = sqrt( ((`n1'-1)*(`sd1'^2) + (`n0'-1)*(`sd0'^2) )/( `_NN' - 2) )

				if "`method'" == "cohen" {
					qui replace `_ES'   = (`mean1' - `mean0')/`s'                                      if `touse' & `_USE'==1
					qui replace `_seES' = sqrt((`_NN' /(`n1'*`n0')) + (`_ES'*`_ES'/ (2*(`_NN' - 2)) )) if `touse' & `_USE'==1
				}
				else if "`method'" == "glass" {
					qui replace `_ES'   = (`mean1' - `mean0')/`sd0'                                    if `touse' & `_USE'==1
					qui replace `_seES' = sqrt(( `_NN' /(`n1'*`n0')) + (`_ES'*`_ES'/ (2*(`n0' - 1)) )) if `touse' & `_USE'==1
				}
				else if "`method'" == "hedges" {
					qui replace `_ES'   = (`mean1' - `mean0')*(1 - 3/(4*`_NN' - 9))/`s'                    if `touse' & `_USE'==1
					qui replace `_seES' = sqrt(( `_NN' /(`n1'*`n0')) + (`_ES'*`_ES'/ (2*(`_NN' - 3.94)) )) if `touse' & `_USE'==1
				}
			}
		}	/* end else (i.e. if `params' == 6) */
	}		/* end if `params' > 3 */
	
	// setup for logrank HR (O-E & V)
	else if "`logrank'"!="" {
		assert `params' == 2
		args oe v
		local p : copy local petovlist
		
		qui replace `_ES'   = `oe'/`v'    if `touse' & `_USE'==1		// logHR
		qui replace `_seES' = 1/sqrt(`v') if `touse' & `_USE'==1		// selogHR
		
		qui gen double `p' = (`oe'^2)/`v'
		local qvlist `"`oe' `v' `p'"'				// Peto het
	}												// N.B. FE pooling could use either of these, but Peto het can only be done qvlist.		

	// assemble varlist to send to PerformPooling
	return local pvlist `"`pvlist'"'
	return local qvlist `"`qvlist'"'
	
end
	
	


***********************************************************

* Program to generate confidence intervals for individual studies (NOT pooled estimates)
// subroutine of PerformMetaAnalysis

program define GenConfInts

	syntax varlist(min=2 max=6 default=none) [if] [in], OUTVLIST(namelist min=5 max=8) CItype(string) ///
		[DF(varname numeric) LEVEL(real 95) ZTOL(real 1e-6)]

	marksample touse, novarlist
	
	// unpack varlists
	tokenize `outvlist'
	args _ES _seES _LCI _UCI _WT _NN
	assert !missing(`_ES', `_seES') if `touse'
	local params : word count `varlist'		// `varlist' == `invlist'
	
	
	* Calculate confidence limits for original study estimates using specified `citype'
	// (unless limits supplied by user)
	if "`citype'"=="normal" {						// normal distribution - default
		tempname critval
		scalar `critval' = invnormal(.5 + `level'/200)
		qui replace `_LCI' = `_ES' - `critval'*`_seES' if `touse'
		qui replace `_UCI' = `_ES' + `critval'*`_seES' if `touse'
	}
		
	else if inlist("`citype'", "t", "logit") {		// t distribution
		cap confirm numeric variable `df'
		if !_rc {
			summ `df' if `touse', meanonly			// use supplied df if available
			cap assert r(max) < .
			if _rc {
				nois disp as err `"Degrees-of-freedom variable {bf:`df'} contains missing values;"'
				nois disp as err `"  cannot use {bf:`citype'}-based confidence intervals for study estimates"'
				exit 198
			}
		}
		else {
			cap confirm numeric variable `_NN'
			if !_rc {
				summ `_NN' if `touse', meanonly			// use supplied df if available
				cap assert r(max) < .
				if _rc {
					nois disp as err `"Participant numbers not available for all studies;"'
					nois disp as err `"  cannot use {bf:`citype'}-based confidence intervals for study estimates"'
					exit 198
				}
				tempvar df
				qui gen `: type `_NN'' `df' = `_NN' - 2			// use npts-2 as df for t distribution of df not explicitly given
				nois disp as err `"Note: Degrees of freedom for {bf:`citype'}-based confidence intervals not supplied; using {it:n-2} as default"'
			}
			else {
				nois disp as err `"Neither degrees-of-freedom nor participant numbers available;"'
				nois disp as err `"  cannot use {bf:`citype'}-based confidence intervals for study estimates"'
				exit 198
			}
		}
		tempvar critval
		qui gen double `critval' = invttail(`df', .5-`level'/200)
			
		if "`citype'"=="t" {
			qui replace `_LCI' = `_ES' - `critval'*`_seES' if `touse'
			qui replace `_UCI' = `_ES' + `critval'*`_seES' if `touse'
		}
		else {								// logit, proportions only (for formula, see Stata manual for -proportion-)
			summ `_ES' if `touse', meanonly
				if r(min)<0 | r(max)>1 {
				nois disp as err "{bf:citype(logit)} may only be used with proportions"
				exit 198
			}
			qui replace `_LCI' = invlogit(logit(`_ES') - `critval'*`_seES'/(`_ES'*(1 - `_ES'))) if `touse'
			qui replace `_UCI' = invlogit(logit(`_ES') + `critval'*`_seES'/(`_ES'*(1 - `_ES'))) if `touse'
		}
		drop `critval'
	}
		
	else if inlist("`citype'", "cornfield", "exact", "woolf") {		// options to pass to -cci-; summstat==OR only
		tokenize `varlist'
		args a b c d		// events & non-events in trt; events & non-events in control (c.f. -metan- help file)

		// sort appropriately, then find observation number of first relevant obs
		tempvar obs
		qui bysort `touse' : gen long `obs' = _n if `touse'			// N.B. MetaAnalysisLoop uses -sortpreserve-
		sort `obs'													// so this sorting should not affect the original data
		summ `obs' if `touse', meanonly
		forvalues j = 1/`r(max)' {
			nois cci `=`a'[`j']' `=`b'[`j']' `=`c'[`j']' `=`d'[`j']', `citype'
			qui replace `_LCI' = log(`r(lb_or)' in `j'
			qui replace `_UCI' = log(`r(ub_or)' in `j'
		}
	}

end




***************************************************************

* MetaAnalysisLoop
// subroutine of PerformMetaAnalysis; do meta-analysis overall and/or by subgroups

// If cumulative, loop over observations one by one
// If influence, exclude observations one by one
// In any case, write pooled estimates to dataset (typically in observations marked _USE==3 or _USE==5)
//   and return pooling summary statistics (Isq, tausq, etc.)

program define MetaAnalysisLoop, rclass

	syntax varlist(min=3 max=7 numeric) [if] [in], ///
		SORTBY(varlist) METHOD(string) REMODEL(string) OUTVLIST(namelist min=5 max=8) ///
		[SUMMSTAT(string) LEVEL(real 95) ISQSA(real 80) RFDLIST(varlist numeric) RFLEVEL(real 95) OVWt SGWt ALTWt ///
		CUMULATIVE INFLUENCE XOUTVLIST(varlist numeric) USE3(varname numeric) ///
		CHI2vars(varlist numeric) AERVARS(varlist numeric) BREslow QVLIST(varlist numeric) NPTS(varname numeric) WGT(varname numeric) ///
		VCEMODEL(string) DF(varname numeric) * ]
	
	marksample touse, novarlist
	gettoken _USE pvlist : varlist
	
	qui count if `touse' & `_USE'==1
	if !r(N) exit 2000	
	
	local re_model `remodel'
	local vce_model `vcemodel'
	
	tokenize `outvlist'
	args _ES _seES _LCI _UCI _WT _NN

	// unpack rfdlist (if exists)
	tokenize `rfdlist'
	args _rfLCI _rfUCI	

	
	** Cumulative and Influence analysis
	
	// The plan:
	// (1) Iterate `j' from 1 to `jmax'
	// (2) Pool obs from 1 to `j' (cumulative) or all except `j' (influence)
	// (3) Store pooled results in `j'
	
	// Complication:
	// influence might use nooverall/nosubgroup
	// in which case *pooling* needs doing but not *storing* (except for total weight)
	
	// Solution: increment `jmax'
	// then, last run will pool "all except `jmax'" (i.e. all the actual observations, since `jmax' doesn't exist)
	// and pooled results will not be stored (`touse2' will be zero throughout)
	
	// Note: if *not* cumulative or influence analysis,
	// we set `jmin' equal to `jmax', so there is only one iteration, involving *all* studies.	
	
	tempname critval
	tempvar obsj touse2
	qui bysort `touse' (`_USE' `sortby') : gen long `obsj' = _n if `touse'
	qui count if `touse'
	local jmax = r(N)
	
	// unless cumulative, if no "pooled" obs specified (i.e. "nooverall" or "nosubgroup" specified)
	// increment `jmax' to an obs value that doesn't actually exist ==> pooled estimates are not stored
	if `"`cumulative'"'==`""' {
		qui count if `touse' & `_USE'!=1
		if !r(N) local ++jmax
	}
	else assert `_USE'==1 if `touse'		// else, should be no "pooled" obs; double check
	
	// initialise `svlist' = list of vars in which to store estimates returned by PerformPooling
	// this is typically = `outvlist', UNLESS cumulative/influence analysis, in which case = `xoutvlist'
	local svlist = cond(`"`xoutvlist'"'!=`""', `"`xoutvlist'"', `"`outvlist'"')
	tokenize `svlist'
	args _ES_ _seES_ _LCI_ _UCI_ _WT_
	
	local jmin = cond(`"`xoutvlist'"'==`""', `jmax', 1)
	
	forvalues j = `jmin'/`jmax' {

		gen byte `touse2' = `touse' * (`_USE'==1)
	
		// Define `touse' for *input* (i.e. which obs to meta-analyse)
		if `"`xoutvlist'"'!=`""' {
			qui replace `touse2' = `touse' * cond(`"`cumulative'"'!=`""', ///
				inrange(`obsj', 1, `j'), ///								// cumulative: obs from 1 to `j' (==> last run is all obs)
				cond(`j'<`jmax', (`obsj' != `j'), 1))						// influence: all obs except `j'; then all obs
		}																	// (N.B. for influence, `j'<`jmax' ==> `_USE'==1)

		// If only one study, revert from RE to FE/M-H if necessary.
		// Also return the "reverted" values of `re_model' and `vce_model' so a "Note" can be printed to screen.
		// BUT don't do this if it's the first iteration of a cumulative analysis,
		// since this will *always* contain just a single study.
		local re_model2  `re_model'
		local vce_model2 `vce_model'
		local pvlist2    `pvlist'
		qui count if `touse2'
		if r(N)==1 {
			local re_model2 = cond("`method'"=="mh", "mh", "fe")
			local vce_model2
		}
		else if "`method'"=="mh" & "`re_model'"!="mh" {
			local pvlist2 `"`_ES' `_seES'"'						// if M-H but random-effects, switch to IV
		}
		
		if `"`cumulative'"'!=`""' & `j'==1 {
			return local re_model `re_model'					// if first iteration of cumulative, *don't* return "reverted" values
			return local vce_model `vce_model'
		}
		else {
			return local re_model `re_model2'					// this is "re_model_SG"
			return local vce_model `vce_model2'
		}
		
		// if ovwt/sgwt, pass `_WT' to PerformPooling to be filled in
		// otherwise, PerformPooling will generate a tempvar, and `_WT' will remain empty
		local wtvar = cond(`"`ovwt'`sgwt'"'!=`""', `"`_WT'"', `""')

		cap nois PerformPooling `pvlist2' if `touse2', method(`method') remodel(`re_model2') wtvar(`wtvar') wgt(`wgt') ///
			chi2vars(`chi2vars') aervars(`aervars') qvlist(`qvlist') npts(`npts') `breslow' ///
			summstat(`summstat') level(`level') isqsa(`isqsa') vcemodel(`vce_model2') df(`df') `options'

		if _rc {
			if _rc==1 nois disp as err `"User break in {bf:admetan.PerformPooling}"'
			else nois disp as err `"Error in {bf:admetan.PerformPooling}"'
			c_local err "noerr"		// tell admetan not to also report an "error in MetaAnalysisLoop"
			exit _rc
		}
		
		// Now re-define `touse2' for *output* (i.e. where to store the results of the meta-analysis)
		qui replace `touse2' = `touse' * (`obsj'==`j')
			
		// store effect size, SE & totwt in the dataset
		qui replace `_ES_'   = r(eff)    if `touse2'
		qui replace `_seES_' = r(se_eff) if `touse2'
		qui replace `_WT_'   = r(totwt)  if `touse2'
						
		// store CIs
		if "`re_model2'"=="pl" {
			qui replace `_LCI_' = r(eff_lci) if `touse2'
			qui replace `_UCI_' = r(eff_uci) if `touse2'
		}
		else {
			scalar `critval' = ///
				cond("`vce_model2'"=="hksj", invttail(r(k)-1,   .5 - `level'/200), ///		// crit. val. for HKSJ (uses k-1 d.f.)
				cond("`vce_model2'"=="kr",   invttail(r(df_kr), .5 - `level'/200), ///		// crit. val. for Kenward-Roger
				invnormal(.5 + `level'/200) ))
			
			if `critval' == . {
				if      "`vce_model2'"=="hksj" & !missing(r(k))     scalar `critval' = maxdouble()
				else if "`vce_model2'"=="kr"   & !missing(r(df_kr)) scalar `critval' = maxdouble()
			}

			qui replace `_LCI_' = r(eff) - `critval' * r(se_eff) if `touse2'
			qui replace `_UCI_' = r(eff) + `critval' * r(se_eff) if `touse2'
		}
		
		// prediction intervals (use k-2 d.f.)
		if "`rfdlist'"!="" {
			if r(k)<3 c_local nrfd = 1		// tell PerformMetaAnalysis to display error
			else {
				tempname rfcritval
				scalar `rfcritval' = invttail(r(k)-2, .5 - `rflevel'/200)
				qui replace `_rfLCI' = r(eff) - `rfcritval' * sqrt(r(tausq) + r(se_eff)^2) if `touse2'
				qui replace `_rfUCI' = r(eff) + `rfcritval' * sqrt(r(tausq) + r(se_eff)^2) if `touse2'
			}
		}

		// Q, tausq, sigmasq for cumulative/influence
		if `"`xoutvlist'"'!=`""' {
			local tausigma = cond("`re_model'"!="mh", "_tausq _sigmasq", "")		// note `re_model' here, *not* `re_model2'
			tokenize `xoutvlist'
			args _ES2 _seES2 _LCI2 _UCI2 _WT2 _Q `tausigma' _NN2

			qui replace `_Q' = r(Q) if `touse2'
			if "`re_model2'"!="mh" {
				qui replace `_tausq'   = r(tausq)   if `touse2'
				qui replace `_sigmasq' = r(sigmasq) if `touse2'
			}
			if      "`vce_model2'"=="hksj" qui replace `df' = r(k)-1   if `touse2'
			else if "`vce_model2'"=="kr"   qui replace `df' = r(df_kr) if `touse2'
		}
		
		drop `touse2'	// tidying up
		
	}					// end forvalues j=`jmin'/`jmax'

	// Return stats from final run of PerformPooling
	tempname totwt k
	scalar `totwt' = r(totwt)
	scalar `k' = r(k)
	return add
	
	// Find and return number of participants
	if `"`_NN'"'!=`""' {
		summ `_NN' if `touse' & `_USE'==1, meanonly
		return scalar n = r(sum)
		
		// Store subgroup/overall numbers of participants in dataset (unless cumulative/influence)
		if `"`xoutvlist'"'==`""' {
			qui replace `_NN' = r(sum) if `touse' & `_USE'!=1
		}
	}
	
	// Normalise weights if ovwt/sgwt specified
	if `"`ovwt'`sgwt'"'!=`""' {

		if `"`altwt'"'!=`""' {
			qui replace `_WT_' = `_WT' / `totwt' if `touse'		// use *original* weights (_WT) rather than cumul/infl weights (_WT_)
			qui replace `_WT_' = 1 if `touse' & `_USE'!=1
		}
		else {
			qui replace `_WT_' = `_WT_' / `totwt' if `touse'

			// Numbers of participants if cumulative/influence
			if `"`_NN2'"'!=`""' {
			
				// Cumulative
				if `"`cumulative'"'!=`""' qui replace `_NN2' = sum(`_NN') if `touse' & `_USE'==1
				
				// Influence
				else if `"`influence'"'!=`""' {
					summ `_NN' if `touse' & `_USE'==1, meanonly
					qui replace `_NN2' = r(sum) - `_NN' if `touse' & `_USE'==1
				}
			}
		}
	}

	// Else, find sum of *existing* (previously-normalised) weights and store in _USE==3/5 (i.e. _USE!=1)
	else {
		summ `_WT' if `touse' & `_USE'==1, meanonly
		scalar `totwt' = cond(r(N), r(sum), .)
		qui replace `_WT_' = `totwt' if `touse' & `_USE'!=1
	}

	// cumulative: identifier of last estimate, for placement of dotted line in forestplot
	if `"`cumulative'"'!=`""' {
		qui replace `use3' = 1 if `touse' & `obsj'==`jmax'
	}

	// Check consistency of numbers of *studies*
	qui count if `touse' & `_USE'==1
	assert r(N) == `k'
	
end





*******************************************************************
	
* PerformPooling
// subroutine of MetaAnalysisLoop

// This routine actually performs the pooling itself.
// non-IV calculations are done in Stata (partly using code taken from metan.ado by Ross Harris et al);
//   iterative IV analyses are done in Mata (within GetEstimates routine).

// N.B. study-level results _ES, _seES, _LCI, _UCI are assumed *always* to be on the linear scale (i.e. logOR etc.)
// as this makes building the forestplot easier, and keeps things simple in general.
// For non-IV 2x2 count data, however, the exponentiated effect size may also be returned, e.g. r(OR), r(RR).

program define PerformPooling, rclass
	
	syntax varlist(min=2 max=8 numeric) [if] [in], ///
		METHOD(string) REMODEL(string) ///
		[SUMMSTAT(string) LEVEL(real 95) WTVAR(varname numeric) NPTS(varname numeric) WGT(varname numeric) ///
		CHI2vars(varlist numeric) AERVARS(varlist numeric) BREslow noINTeger QVLIST(varlist numeric) ///
		VCEMODEL(string) ISQSA(real 80) QE(varname numeric) ///
		ITOL(real 1e-8) MAXTausq(real -9) REPS(real 1000) MAXITer(real 1000) QUADPTS(real 40) noTRUNCate EIM OIM DF(varname numeric) ]
	
	marksample touse
	local re_model `remodel'
	local vce_model `vcemodel'
	
	tempname k
	qui count if `touse'
	scalar `k' = r(N)
	
	tempvar qhet
	tempname Q

	// if no wtvar, gen as tempvar
	if `"`wtvar'"'==`""' {
		local wtvar
		tempvar wtvar
		qui gen `wtvar' = .
	}
	
	
	** Binary outcomes (OR, RR, RD)

	// Get average event rate for each group (before any 0.5 adjustments or excluding 0-0 studies)
	if "`aervars'"!="" {
		assert `: word count `aervars'' == 4
		tokenize `aervars'
		args a r1 c r0
	
		tempname ernum erden tger cger
		sum `a' if `touse', meanonly
		scalar `ernum' = cond(r(N), r(sum), .)
		sum `r1' if `touse', meanonly
		scalar `erden' = cond(r(N), r(sum), .)
		scalar `tger' = `ernum'/`erden'
		return scalar tger = `tger'
		
		sum `c' if `touse', meanonly
		scalar `ernum' = cond(r(N), r(sum), .)
		sum `r0' if `touse', meanonly
		scalar `erden' = cond(r(N), r(sum), .)
		scalar `cger' = `ernum'/`erden'
		return scalar cger = `cger'
	}
		
	// Chi-squared test (OR only)
	if "`chi2vars'"!="" {
		assert `: word count `chi2vars'' == 3
		tokenize `chi2vars'
		args a ea va
	
		tempname A EA VA chi2
		summ `a' if `touse', meanonly
		scalar `A' = cond(r(N), r(sum), .)
		summ `ea' if `touse', meanonly
		scalar `EA' = cond(r(N), r(sum), .)
		summ `va' if `touse', meanonly
		scalar `VA' = cond(r(N), r(sum), .)
		scalar `chi2' = ((`A'-`EA')^2 )/`VA'
		return scalar chi2 = `chi2'
	}

	// N.B. `varlist' is what was previously `pvlist'
	// so can contain 2 elements (I-V), 3 (Peto OR or HR), 3 (M-H RR or RD) or 6 (M-H OR)

	
	** Mantel-Haenszel methods
	if "`method'"=="mh" {

		// Mantel-Haenszel OR
		if "`summstat'"=="or" {
		
			if "`re_model'"=="mh" {
				assert `: word count `varlist'' == 6
				tokenize `varlist'
				args r s pr ps qr qs
			}
			if "`breslow'"=="" {
				assert `: word count `qvlist'' == 4		// if re_model=="mh" then r, s already defined
				tokenize `qvlist'						// (else, re_model must be RE I-V)
				args v _ES r s
			}

			tempname R S OR
			sum `r' if `touse', meanonly
			scalar `R' = cond(r(N), r(sum), .)
			sum `s' if `touse', meanonly
			scalar `S' = cond(r(N), r(sum), .)
			scalar `OR' = `R'/`S'
			
			if "`re_model'"=="mh" {
				tempname PR PS QR QS selogOR
				summ `pr' if `touse', meanonly
				scalar `PR' = cond(r(N), r(sum), .)
				summ `ps' if `touse', meanonly
				scalar `PS' = cond(r(N), r(sum), .)
				summ `qr' if `touse', meanonly
				scalar `QR' = cond(r(N), r(sum), .)
				summ `qs' if `touse', meanonly
				scalar `QS' = cond(r(N), r(sum), .)
				scalar `selogOR' = sqrt( (`PR'/(`R'*`R') + (`PS'+`QR')/(`R'*`S') + `QS'/(`S'*`S')) /2 )

				// return scalars
				return scalar OR = `OR'
				return scalar eff = ln(`OR')
				return scalar se_eff = `selogOR'
				
				// weight
				qui replace `wtvar' = `s' if `touse'
			}
				
			// Standard M-H heterogeneity
			if "`breslow'"=="" {
				qui gen double `qhet' = ( (`_ES' - ln(`OR'))^2 ) /`v'
				sum `qhet' if `touse', meanonly
				scalar `Q' = cond(r(N), r(sum), .)
				drop `qhet'
			}

			// Breslow-Day heterogeneity
			// (Breslow NE, Day NE. Statistical Methods in Cancer Research: Vol. I - The Analysis of Case-Control Studies.
			//  Lyon: International Agency for Research on Cancer 1980)
			else {
				assert `: word count `qvlist'' == 5
				tokenize `qvlist'
				args r1 r0 c1 c0 a

				tempvar afit bfit cfit dfit
				if abs(`OR' - 1) < 0.0001 {										// sep 2015: For future: allow user-defined tolerance?
					local type = cond("`integer'"=="", "long", "double")
					qui gen `type' `_NN' = `r1' + `r0'
					qui gen double afit = `r1'*`c1'/ `_NN'
					qui gen double bfit = `r1'*`c0'/ `_NN'
					qui gen double cfit = `r0'*`c1'/ `_NN'
					qui gen double dfit = `r0'*`c0'/ `_NN'
					drop `_NN'
				}
				else {
					tempvar sterm cterm root1 root2
					tempname qterm
					scalar `qterm' = 1 - `OR'
					qui gen double `sterm' = `r0' - `c1' + `OR'*(`r1' + `c1')
					qui gen double `cterm' = -`OR'*`c1'*`r1'
					qui gen double `root1' = (-`sterm' + sqrt(`sterm'*`sterm' - 4*`qterm'*`cterm'))/(2*`qterm')
					qui gen double `root2' = (-`sterm' - sqrt(`sterm'*`sterm' - 4*`qterm'*`cterm'))/(2*`qterm')
					qui gen double `afit' = `root1' if `root2'<0
					qui replace `afit' = `root2' if `root1'<0
					qui replace `afit' = `root1' if (`root2'>`c1') | (`root2'>`r1')
					qui replace `afit' = `root2' if (`root1'>`c1') | (`root1'>`r1')
					qui gen double `bfit' = `r1' - `afit'
					qui gen double `cfit' = `c1' - `afit'
					qui gen double `dfit' = `r0' - `cfit'
					drop `sterm' `cterm' `root1' `root2'
				}
				qui gen `qhet' = ((`a'-`afit')^2) * ((1/`afit') + (1/`bfit') + (1/`cfit') + (1/`dfit'))
				summ `qhet' if `touse', meanonly
				scalar `Q' = cond(r(N), r(sum), .)
				drop `qhet' `afit' `bfit' `cfit' `dfit'
			}
		}		// end M-H OR

		// Mantel-Haenszel RR/IRR/RRR
		else if inlist("`summstat'", "rr", "irr", "rrr") {
		
			if "`re_model'"=="mh" {
				assert `: word count `varlist'' == 3
				tokenize `varlist'
				args p r s
			}

			// M-H heterogeneity
			assert `: word count `qvlist'' == 4			// if re_model=="mh" then r, s already defined
			tokenize `qvlist'							// (else, re_model must be RE I-V)
			args v _ES r s
		
			tempname R S RR
			sum `r' if `touse', meanonly
			scalar `R' = cond(r(N), r(sum), .)
			sum `s' if `touse', meanonly
			scalar `S' = cond(r(N), r(sum), .)
			scalar `RR' = `R'/`S'

			if "`re_model'"=="mh" {
				tempname P selogRR
				sum `p' if `touse', meanonly
				scalar `P' = cond(r(N), r(sum), .)
				scalar `selogRR' = sqrt(`P'/(`R'*`S'))
			
				// return scalars
				return scalar RR = `RR'
				return scalar eff = ln(`RR')
				return scalar se_eff = `selogRR'
				
				// weight
				qui replace `wtvar' = `s' if `touse'
			}

			// M-H heterogeneity
			// tempvar qhet
			qui gen double `qhet' = ((`_ES' - ln(`RR') )^2 ) /`v'
			sum `qhet' if `touse', meanonly
			scalar `Q' = cond(r(N), r(sum), .)
			drop `qhet'
		}

		// Mantel-Haenszel RD
		else if "`summstat'"=="rd" {
		
			if "`re_model'"=="mh" {
				assert `: word count `varlist''==3
				tokenize `varlist'
				args rdwt rdnum vnum
			}

			// M-H heterogeneity 
			assert `: word count `qvlist'' == 4				// if re_model=="mh" then rdwt, rdnum already defined
			tokenize `qvlist'								// (else, re_model must be RE I-V)
			args v _ES rdwt rdnum

			tempname W RD
			sum `rdwt' if `touse', meanonly
			scalar `W' = cond(r(N), r(sum), .)
			sum `rdnum' if `touse', meanonly
			scalar `RD' = r(sum)/`W'						// pooled rd

			if "`re_model'"=="mh" {
				tempname seRD
				sum `vnum' if `touse', meanonly
				scalar `seRD' = sqrt( r(sum) /(`W'*`W') )		// SE of pooled rd
				
				// return scalars
				return scalar eff = `RD'
				return scalar se_eff = `seRD'
				
				// weight
				qui replace `wtvar' = `rdwt' if `touse'
			}

			// M-H heterogeneity
			// tempvar qhet
			qui gen double `qhet' = ((`_ES' - `RD')^2 )/`v'
			sum `qhet' if `touse', meanonly
			scalar `Q' = cond(r(N), r(sum), .)
			drop `qhet'
		}
	}	// end of M-H methods
	

	** Peto heterogeneity (OR/HR is done as if fixed-effects inverse-variance, as it comes to the same thing)
	else if "`method'"=="peto" {
		assert `: word count `qvlist''==3
		tokenize `qvlist'
		args oe v p

		tempname OE V OR selogOR
		summ `oe' if `touse', meanonly
		scalar `OE' = cond(r(N), r(sum), .)
		summ `v' if `touse', meanonly
		scalar `V' = cond(r(N), r(sum), .)
		return scalar OE = `OE'
		return scalar V = `V'
		
		// Peto heterogeneity
		tempname P chi2
		summ `p' if `touse', meanonly
		scalar `P' = cond(r(N), r(sum), .)
		scalar `chi2' = (`OE'^2)/`V'		// chi-squared statistic
		scalar `Q' = `P' - `chi2'
		return scalar chi2 = `chi2'
	}


	** Generic inverse-variance methods and/or heterogeneity
	// N.B. if qmethod==cochran then method==I-V (but not necess. v.v.; could be RE I-V with M-H or Peto, or OR + Breslow)
	if "`re_model'"!="mh" {

		assert `: word count `varlist''==2
		tokenize `varlist'
		args _ES _seES

		tempname eff se_eff
		qui replace `wtvar' = 1/`_seES'^2 if `touse'
		
		summ `_ES' [aw=`wtvar'] if `touse', meanonly
		scalar `eff' = r(mean)
		scalar `se_eff' = 1/sqrt(r(sum_w))		// fixed-effects SE

		// Need to derive Cochran's Q; will be returned as Qc, separately from "generic" r(Q) (which may contain a different stat e.g. Breslow-Day)
		tempname Qc
		qui gen double `qhet' = `wtvar'*((`_ES' - `eff')^2)
		summ `qhet' if `touse', meanonly
		scalar `Qc' = cond(r(N), r(sum), .)
		return scalar Qc = `Qc'
		if "`method'"=="iv" | inlist("`summstat'", "smd", "wmd") scalar `Q' = `Qc'
	
		tempname c sigmasq tausq
		summ `wtvar' [aw=`wtvar'] if `touse', meanonly
		scalar `c' = r(sum_w) - r(mean)
		scalar `sigmasq' = (`k' - 1)/`c'							// [general note: can this be generalised to other (non-IV) methods?]
		scalar `tausq' = max(0, (`Qc' - (`k' - 1))/`c')				// default: D+L estimate
		
		// User-defined weights
		if `"`wgt'"'!=`""' {
			qui replace `wtvar' = `wgt' if `touse'
			summ `_ES' [aw=`wtvar'] if `touse', meanonly
			scalar `eff' = r(mean)
			scalar `se_eff' = 1/sqrt(r(sum_w))						// re-weighted ES & SE			
		}
		
		** Non-iterative estimates of tausq
		else if inlist("`re_model'", "dl", "sa", "vc", "sj2s", "b0", "bp") {
		
			if "`re_model'"=="sa" {			// Sensitivity analysis: use given Isq and sigmasq to generate tausq
				scalar `tausq' = `isqsa'*`sigmasq'/(100 - `isqsa')
			}
			else if inlist("`re_model'", "vc", "sj2s", "b0", "bp") {
				tempvar v
				tempname var_eff meanv
				qui summ `_ES' if `touse'
				scalar `var_eff' = r(Var)
				qui gen double `v' = `_seES'^2
				summ `v' if `touse', meanonly
				scalar `meanv' = r(mean)
				
				if inlist("`re_model'", "vc", "sj2s") {				// "variance component" aka Cochran ANOVA-type estimator
					scalar `tausq' = `var_eff' - `meanv'
				}
				else if inlist("`re_model'", "b0", "bp") {			// Rukhin Bayes estimators
					scalar `tausq' = `var_eff'*(`k' - 1)/(`k' + 1)
					if "`re_model'"=="b0" {
						summ `npts' if `touse', meanonly	
						scalar `tausq' = `tausq' - ( (`r(sum)' - `k')*(`k' - 1)*`meanv'/((`k' + 1)*(`r(sum)' - `k' + 2)) )
					}
				}
				drop `v'
				scalar `tausq' = max(0, `tausq')			// truncate at zero
			}
		
			// generate random-effects weights, eff, SE (unless "IVhet" or "QE" models, which don't use tausq in this context)
			if !inlist("`vce_model'", "ivhet", "qe") {
				qui replace `wtvar' = 1/((`_seES'^2) + `tausq') if `touse'
				summ `_ES' [aw=`wtvar'] if `touse', meanonly
				scalar `eff' = r(mean)
				scalar `se_eff' = 1/sqrt(r(sum_w))
			}
			
			// "QE" model: more work needed to obtain weights for point estimate
			// (and then more work again for the variance; see later)
			else if "`vce_model'"=="qe" {
				tempvar newqe tauqe
				
				// re-scale scores relative to highest value
				summ `qe' if `touse', meanonly
				qui gen double `newqe' = `qe'/r(max)

				// taui and tauhati
				qui gen double `tauqe' = (1 - `newqe')/(`_seES'*`_seES'*(`k'-1))
				summ `tauqe' if `touse', meanonly
				local sumtauqe = r(sum)

				summ `newqe' if `touse', meanonly
				if r(min) < 1 {
					tempvar newqe_adj
					qui gen double `newqe_adj' = `newqe' + r(sum)*`tauqe'/(`sumtauqe'*(`k'-1))
					summ `newqe_adj' if `touse', meanonly
					qui replace `tauqe' = (`sumtauqe'*`k'*`newqe_adj'/r(sum)) - `tauqe'
					cap drop `newqe_adj'
				}
				else qui replace `tauqe' = (`sumtauqe'*`k'*`newqe'/r(sum)) - `tauqe'
				
				// Point estimate uses weights = qi/vi + tauhati
				qui replace `wtvar' = (`newqe'/(`_seES'^2)) + `tauqe' if `touse'
				drop `newqe' `tauqe'

				summ `_ES' [aw=`wtvar'] if `touse', meanonly
				scalar `eff' = r(mean)
				scalar `se_eff' = 1/sqrt(r(sum_w))
			}
		}

		
		** Iterative models, using Mata
		// (plus Biggerstaff-Tweedie approximate Gamma overdispersion method, which also requires Mata)
		// (N.B. I think Biggerstaff-Tweedie can only use DL tausq, which simplifies things...
		//    ...if a choice of tausq was needed for B-T, this code would need to be rearranged)
		if inlist("`re_model'", "dlb", "mp", "ml", "pl", "reml") | "`vce_model'"=="gamma" {

			// Check validity of iteropts
			cap assert (`maxtausq'>=0 & !missing(`maxtausq')) | `maxtausq'==-9
			if _rc {
				disp as err "maxtausq() cannot be negative"
				exit 198
			}			
			cap assert `itol'>=0 & !missing(`itol')
			if _rc {
				disp as err "itol() cannot be negative"
				exit 198
			}
			cap {
				assert (`maxiter'>0 & !missing(`maxiter'))
				assert round(`maxiter')==`maxiter'
			}
			if _rc {
				disp as err "maxiter() must be an integer greater than zero"
				exit 198
			}

			// maxtausq: use 10*`tausq' if not specified
			// (and 10 times that for uci -- done in Mata)
			local maxtausq = cond(`maxtausq'==-9, max(10*`tausq', 100), `maxtausq')
		
			if "`re_model'"=="dlb" {
				cap {
					assert (`reps'>0 & !missing(`reps'))
					assert round(`reps')==`reps'
				}
				if _rc {
					disp as err "reps() must be an integer greater than zero"
					exit 198
				}
				cap nois mata: DLb("`_ES' `_seES'", "`touse'", "`wtvar'", `level', `reps')
			}
			else if "`re_model'"=="mp" {
				cap nois mata: MandelPaule("`_ES' `_seES'", "`touse'", "`wtvar'", `level', (`maxtausq', `itol', `maxiter'))
			}
			else if "`vce_model'"=="gamma" {
				cap nois mata: Gamma("`_ES' `_seES'", "`touse'", "`wtvar'", `level', (`maxtausq', `itol', `maxiter'), `quadpts')
			}
			else if inlist("`re_model'", "ml", "pl") {
				cap nois mata: MLPL("`_ES' `_seES'", "`touse'", "`wtvar'", `level', (`maxtausq', `itol', `maxiter'), "`re_model'")
			}
			else if "`re_model'"=="reml" {
				cap nois mata: REML("`_ES' `_seES'", "`touse'", "`wtvar'", `level', (`maxtausq', `itol', `maxiter'))
			}
			if _rc {
				if _rc==1 exit _rc
				else if _rc>=3000 {
					nois disp as err "Mata compile-time or run-time error"
					exit _rc
				}
				else if _rc nois disp as err "Error(s) detected during running of Mata code; please check output"
			}

			// check tausq limits and set to missing if necessary
			tempname tsq_lci tsq_uci
			scalar `tsq_lci' = r(tsq_lci)
			scalar `tsq_uci' = r(tsq_uci)
			if "`re_model'"!="dlb" {
				scalar `tsq_lci' = cond(r(rc_tsq_lci)>1 & `tsq_lci'!=0, ., `tsq_lci')
				scalar `tsq_uci' = cond(r(rc_tsq_uci)>1, ., `tsq_uci')
			}
			
			// return extra scalars
			return scalar maxtausq = `maxtausq'
			return scalar tsq_lci  = `tsq_lci'
			return scalar tsq_uci  = `tsq_uci'
			return scalar rc_tausq = r(rc_tausq)
			return scalar rc_tsq_lci = r(rc_tsq_lci)
			return scalar rc_tsq_uci = r(rc_tsq_uci)
				
			if "`re_model'"=="pl" {
				return scalar eff_lci = r(eff_lci)
				return scalar eff_uci = r(eff_uci)
				return scalar rc_eff_lci = r(rc_eff_lci)
				return scalar rc_eff_uci = r(rc_eff_uci)
			}
			
			if "`vce_model'"=="gamma" {
				return scalar tsq_var = r(tsq_var)
				scalar `se_eff' = r(se_eff)
			}
			else scalar `tausq' = r(tausq)

			// calculate "basic" scalars but don't return them yet (they may be modified)
			summ `_ES' [aw=`wtvar'] if `touse', meanonly
			scalar `eff' = r(mean)
			if "`vce_model'"!="gamma" scalar `se_eff' = 1/sqrt(r(sum_w))			
		}
		
		// "Generalised" (random-effects) version of Cochran's Q
		if !inlist("`vce_model'", "ivh", "qe") {
			local Qr `Qc'
			if "`re_model'"!="fe" | "`wgt'"!="" {		// if fe, Qr = Qc; if Doi's models then Qr is meaningless
				tempname Qr
				qui replace `qhet' = `wtvar'*((`_ES' - `eff')^2)
				summ `qhet' if `touse', meanonly
				scalar `Qr' = cond(r(N), r(sum), .)	
			}
		}
		
		
		** "Variance inflation" or "overdispersion" methods
		// (also encompasses Biggerstaff-Tweedie approximate Gamma method, although this is done within Mata; see above)
		if inlist("`vce_model'", "hksj", "ivhet", "qe", "fv") {
			tempname overdisp
			
			// "Full variance" estimator suggested by Sandercock
			// (https://metasurv.wordpress.com/2013/04/26/
			//    fixed-or-random-effects-how-about-the-full-variance-model-resolving-a-decades-old-bunfight)
			// This assumes that **fixed-effects** estimator and weights are used;
			//  only the **variance** of the estimator is different
			if "`vce_model'"=="fv" scalar `overdisp' = `Qc'/(`k' - 1)		// = H2(M) + 1 = 1/(1 - I2)
			
			// "IVHet" estimator (Doi et al, Contemporary Clinical Trials 2015; 45: 130-8)
			// and Quality effects (QE) model (extension of IVHet to incorporate quality scores)
			// (Doi et al, Contemporary Clinical Trials 2015; 45: 123-9)
			// both again use a fixed-effect based estimator and weights for the **point** estimate;
			//   but the variance is calculated using an estimate of tausq (D+L by default)
			else if inlist("`vce_model'", "ivhet", "qe") {
				tempvar psi
				qui gen double `psi' = `wtvar' * ((`_seES'^2) + `tausq')	// If tausq=0 & IVHet, psi = 1 ==> IVhet = FE
				summ `psi' [aw=`wtvar'] if `touse', meanonly
				scalar `overdisp' = r(mean)
			}

			// Hartung-Knapp-Sidik-Jonkman variance inflation method
			// (Roever C et al, BMC Medical Research Methodology 2015; 15: 99)
			else if "`vce_model'"=="hksj" scalar `overdisp' = `Qr'/(`k' - 1)
			
			// Truncate at 1, i.e. don't use if *under* dispersion present (unless `notruncate' option)
			// (this is the recommended "modified" version of the HKSJ method -- see Roever 2015)
			if "`truncate'"=="" scalar `overdisp' = max(1, `overdisp')
			scalar `se_eff' = `se_eff' * sqrt(`overdisp')
		}

		// Kenward-Roger variance inflation method
		// (see Morris TP, Fisher DJ, Kenward MG, Carpenter JR. Statistics in Medicine 2017, submitted
		//  "Meta-analysis of Gaussian individual patient data: two stage or not two stage?")
		else if "`vce_model'"=="kr" {
			tempname wi1 wi2 wi3 nwi2 nwi3
			summ `wtvar' if `touse', meanonly
			scalar `wi1' = r(sum)				// sum of weights
			summ `wtvar' [aw=`wtvar'] if `touse', meanonly
			scalar `wi2' = r(sum)				// sum of squared weights
			summ `wtvar' [aw=`wtvar'^2] if `touse', meanonly
			scalar `wi3' = r(sum)				// sum of cubed weights
			scalar `nwi2' = `wi2'/`wi1'			// "normalised" sum of squared weights [i.e. sum(wi:^2)/sum(wi)]
			scalar `nwi3' = `wi3'/`wi1'			// "normalised" sum of cubed weights [i.e. sum(wi:^3)/sum(wi)]		
				
			// expected information
			tempname I
			scalar `I' = `wi2'/2 - `nwi3' + (`nwi2'^2)/2
			
			// observed information
			if "`oim'"!="" {
				tempvar resid resid2
				tempname q2 q3
				
				qui gen double `resid' = `_ES' - `eff'
				summ `resid' [aw=`wtvar'^2] if `touse', meanonly
				scalar `q2' = r(sum)			// quadratic involving squared weights and residual
				
				qui gen double `resid2' = `resid'^2
				summ `resid2' [aw=`wtvar'^3] if `touse', meanonly
				scalar `q3' = r(sum)			// quadratic involving cubed weights and squared residual
				qui drop `resid' `resid2'
				
				scalar `I' = (`q2'^2)/`wi1' + `q3' - `I'
			}
			// var_tausq = 1/I											// var(tausq)
			
			// corrected se_eff [sqrt(Phi_A) in Kenward-Roger papers]
			scalar `se_eff' = sqrt( (1/`wi1') + 2*(`wi3' - (`wi2'^2)/`wi1')/((`wi1'^2) * `I') )
			
			// denominator degrees of freedom
			tempname df_kr
			scalar `df_kr' = 2 * `I' / (((`se_eff'^2) * `wi2')^2)
			return scalar df_kr = `df_kr'	
		}
					
		// Sidik & Jonkman, with Cochran tausq as initial estimate
		// (not strictly a variance inflation method, but do this here so that Qr is already calculated)
		else if "`re_model'"=="sj2s" {
			scalar `tausq' = `tausq' * `Qr'/(`k' - 1)
				
			// reset random weight
			qui replace `wtvar' = 1/((`_seES'^2) + `tausq') if `touse'
			summ `_ES' [aw=`wtvar'] if `touse', meanonly
			scalar `eff' = r(mean)
			scalar `se_eff' = 1/sqrt(r(sum_w))

			// reset Qr
			qui replace `qhet' = `wtvar'*((`_ES' - `eff')^2)
			summ `qhet' if `touse', meanonly
			scalar `Qr' = cond(r(N), r(sum), .)
		}
		
		// return Qr (following sj2s reset)
		if "`re_model'"!="fe" & !inlist("`vce_model'", "ivh", "qe") {
			return scalar Qr = `Qr'
		}
		
		// return scalars
		return scalar eff = `eff'
		return scalar se_eff = `se_eff'
		return scalar sigmasq = `sigmasq'
		return scalar tausq = `tausq'

	}	// end inverse-variance
	
	// return scalars:
	return scalar k = `k'	// k = number of studies
	return scalar Q = `Q'	// generic heterogeneity statistic (incl. Peto, M-H, Breslow-Day)

	summ `wtvar' if `touse', meanonly
	return scalar totwt = cond(r(N), r(sum), .)		// sum of (non-normalised) weights
	
end	




*******************************************************

* Process ad() option and compare with data already in memory
// (e.g. check study() and by() exist in both, string/numeric, etc.)

program define ProcessAD, rclass

	syntax [if] [in], AD(string asis) ADTOUSE(name) ///
		[IPDFILE(string asis) SORTBY(varname) WGT(varname numeric) SUMMSTAT(string) METHOD(string) MH ///
		EFORM LOG LOGRank BREslow CC(passthru) CORnfield EXact WOolf noINTeger CHI2opt LRCOLS(namelist) ZTOL(passthru) ///
		BY(string asis) BYAD Study(string asis) INVLIST(varlist numeric) USELIST(varlist numeric) NPTS(varname numeric) TVLIST(namelist) ]

	// obtain current variable & value labels from `_STUDY' and (optionally) `_BY'
	tokenize `uselist'
	args _USE _STUDY _BY

	// if `ipdfile', check if _NN exists
	if `"`ipdfile'"'!=`""' {
		cap confirm numeric var _NN
		local _NN = cond(!_rc, "_NN", "")
	}
	
	// tempvars
	tokenize `tvlist'
	args newstudy newby _SOURCE
	
	// First, create ipd_bylist and ipd_slist using `touse' as defined in IPD
	marksample touse
	if `"`_BY'"'!=`""' {	// if `by' exists in current (IPD) data
		qui levelsof `_BY' if `touse' & inlist(`_USE', 1, 2), local(ipd_bylist) missing		// assume "missing" within previously-defined `touse'
		local bylab : value label `_BY'
		local byvarlab : variable label `_BY'
		local by_in_IPD `_BY'						// clarify name, to compare with by_in_AD later
	}
	qui levelsof `_STUDY' if `touse' & inlist(`_USE', 1, 2), local(ipd_slist) missing		// assume "missing" within previously-defined `touse'
	local studylab : value label `_STUDY'
	local svarlab : variable label `_STUDY'

	// temporarily rename IPD locals <--- see note above r.e. parsefplotopts
	local ipdbyad    `byad'
	local ipdnpts    `npts'
	local ipdlogrank `logrank'
	local params : word count `invlist'
	local ipd_iv = cond(inlist(`params', 2, 3)  & "`logrank'"=="",  "ipd_iv", "")
	
	* Now, test to see if `ADfile' has been supplied
	// (alternative is that the "AD" forms a part of the data already in memory)
	local rc = 0
	_parse comma lhs rhs : ad
	if `"`lhs'"'!=`""' {
		gettoken ADfile lhs : lhs					// obtain `ADfile' as first word of `lhs'
		if `"`ADfile'"'!=`""' {						// check that `ADfile' is valid
			cap confirm file `"`ADfile'"'
			local rc = _rc
			if `rc' local lhs `"`ADfile' `lhs'"'		// if it isn't, put `lhs' back together again to apply -syntax- later
		}												// assume AD option (and -syntax-) is to be applied to data currently in memory
	}
	
	* If `ADfile' exists, prepare data and load file
	if `"`ADfile'"'!=`""' & !`rc' {
	
		// create new (tempname-d) labels `adstudylab' and `adbylab', and save them in `labfile'
		tempfile labfile
		tempname adstudylab adbylab

		if "`studylab'"!="" {
			label copy `studylab' `adstudylab'		// in case labelname `studylab' is already in use in AD dataset,
			local adstudylabopt `adstudylab'		//   we take a copy and call it `adstudylab'
		}
		if "`_BY'"!="" & "`bylab'"!="" {
			label copy `bylab' `adbylab'		// in case labelname `bylab' is already in use in AD dataset,
			local adbylabopt `adbylab'			//   we take a copy and call it `adbylab'
		}
		qui label save `adstudylabopt' `adbylabopt' using `labfile'		// save these labels
		
		// Now save data to `ipdfile' so that AD file can be loaded
		local replace
		if `"`ipdfile'"'==`""' tempfile ipdfile
		else local replace replace
		qui save `ipdfile', `replace'		// recycle `ipdfile' as created by ipdmetan.ado if possible
		
		// load AD file, and re-load (temp) value labels (but don't apply them yet)
		qui use `"`ADfile'"', clear
		qui do `labfile'
	}
		
	else {
		local adstudylab `studylab'
		local adbylab `bylab'
	}
	
	// Now apply syntax
	local 0 `"`lhs' `rhs'"'
	cap syntax [if] [in] [, BYAD VARS(varlist numeric min=2 max=6) NPTS(varname numeric) LOGRank RELabel ///
		ADCOLVARS(namelist) ADPLOTVAR(name) ADSORTBY(name) IPDSTR ]
			
	if _rc {
		if `rc' & !inlist(`"`ADfile'"', "in", "if") & substr(`"`ADfile'"', 1, 1)!="[" {
			use `"`ADfile'"', clear				// this will (purposefully) result in error 601 "file not found" or "invalid file specification"
		}
		else syntax [if] [in] [, BYAD VARS(varlist numeric min=2 max=6) NPTS(varname numeric) LOGRank RELabel ///
		ADCOLVARS(namelist) ADPLOTVAR(name) ADSORTBY(name) IPDSTR ]		// if `ADfile' not detected, run -syntax- again to (purposefully) exit with error
	}
	else if `rc' local ADfile					// clear `ADfile' macro for later existence testing	
	
	marksample touse, novarlist		// include missing values
		
	qui count if `touse'
	if !r(N) exit 2000
	local ni=r(N)	
		
	// rename locals to clarify which are associated with AD and which IPD
	local adinvlist `vars'
	local adparams : word count `adinvlist'
			
	local adnpts = cond(`"`npts'"'!=`""', `"`npts'"', `"`ipdnpts'"')
	local byad   = cond(`"`byad'"'!=`""', `"`byad'"', `"`ipdbyad'"')
	local adlogrank `logrank'

	// having sorted out `adnpts', bring in `_NN' if relevant
	local ipdnpts = cond(`"`ipdnpts'"'!=`""', `"`ipdnpts'"', `"`_NN'"')

	// First, parse `by' (as specified in main option, i.e. with potential `missing') within ADfile
	if trim(`"`by'"')==`","' local by
	if `"`by'"'!=`""' {
		if `"`byad'"'!=`""' {
			nois disp as err `"Note: Cannot specify both {bf:byad} and {bf:by()}; {bf:byad} will be ignored"' 
			local byad
		}
			
		local 0 `"`by'"'
		syntax name(name=by) [, Missing]		// only a single (var)name is allowed
		cap confirm var `by'

		// if doesn't exist in AD dataset; check it *does* exist in IPD dataset
		if _rc {
			if `"`by_in_IPD'"'==`""' {
				nois disp as err `"variable {bf:`by'} not found in either IPD or AD dataset"'
				exit 111
			}
		}
		else {
			local byopt = cond(`"`by_in_IPD'"'==`""', `"`newby'"', `"`_BY'"')
			
			if `"`missing'"'==`""' markout `touse' `by', strok
			local by_in_AD `by'			// marker of `by' variable being present in AD (N.B. `by_in_IPD' is marker of presence in *IPD*)
			local byvarlab = cond(`"`byvarlab'"'!=`""', `"`byvarlab'"', ///
				cond(`"`: variable label `by_in_AD''"'!=`""', `"`: variable label `by_in_AD''"', `"`by_in_AD'"'))
		}
	}

	// Try parsing `study' (as in main option) within ADfile
	if `"`study'"'!=`""' {
		local 0 `"`study'"'
		syntax name(name=study) [, Missing]
		cap confirm var `study'
		if !_rc {
			if `"`missing'"'==`""' markout `touse' `study', strok
			local svarlab = cond(`"`svarlab'"'!=`""', `"`svarlab'"', ///
				cond(`"`: variable label `study''"'!=`""', `"`: variable label `study''"', `"`study'"'))
		}
		else {
			disp as err `"Note: variable {bf:`study'} (in option {bf:study()}) not found in aggregate dataset;"'
			disp as err `"      all valid observations in the aggregate dataset will be included"' 
			local study
		}	
	}	
	
	// If `study' not supplied or not found, assume entire dataset is to be used
	// remove any observations with no (i.e. missing) data in `invlist'.
	// (code fragment taken from _grownonmiss.ado)
	if `"`study'"'==`""' {
		tokenize `adinvlist'
		tempvar g
		qui gen byte `g' = (`1'<.) if `touse'
		mac shift
		while "`1'" != "" {
			qui replace `g' = `g' + (`1'<.) if `touse'
			mac shift
		}
		qui replace `g' = . if `g' == 0		// set to missing for benefit of markout
		markout `touse' `g'
		drop `g'
	}
	
	// `study' might be string in ADfile (as indeed it might have originally been in the IPD);
	//   but if *numeric*, compare value labels and detect clashes
	cap confirm numeric var `study'
	if !_rc {
		qui levelsof `study' if `touse', local(ad_slist) missing
		local clash = cond(`"`: list ipd_slist & ad_slist'"'==`""', `""', "clash")		// clash in original IPD and AD study values; new label needed
				
		if "`clash'"!=`""' & `"`relabel'"'==`""' {
			if `"`ipdstr'"'==`""' {
				disp as err `"Study value label conflict between AD and IPD"'
				disp as err `"If appropriate, use the {bf:relabel} suboption of {bf:ad()} to force relabelling of both AD and IPD"'
			}
			else {
				disp as err `"Study value label conflict between AD and IPD, due to {bf:study()} being converted from string in IPD."'
				disp as err `"To avoid this conflict, supply a numeric (within IPD) variable to the {bf:study()} option;"'
				disp as err `"  or to over-ride it, use the {bf:relabel} suboption of {bf:ad()} to force relabelling of both AD and IPD."'
			}
			exit 180
		}
	}

	* Now, create common labels for `study' and `by' (converted from string to numeric if need be) across IPD and AD datasets

	// N.B. `adstudylab' contains IPD study labels so far, but ultimately will contain both.
	local smax : word `: word count `ipd_slist'' of `ipd_slist'				// max IPD study value
	local nby : word count `ipd_bylist'										// number of IPD subgroups
	
	cap nois ProcessLabels if `touse', smax(`smax') nby(`nby') `relabel' ///
		study(`study') newstudy(`newstudy') newstudylab(`adstudylab') ///
		by(`by_in_AD') newby(`byopt')       newbylab(`adbylab')
	if _rc {
		if _rc==1 nois disp as err `"User break in {bf:admetan.ProcessLabels} when applied to AD"'
		else if _rc!=2000 nois disp as err `"Error in {bf:admetan.ProcessLabels} when applied to AD"'
		c_local err "noerr"			// tell admetan not to also report an "error in ProcessAD"
		exit _rc
	}
	
	// update `study'; don't apply label just yet though
	if `"`r(newstudy)'"'==`""' {				// if r(newstudy) not returned, just use the original variable
		if `"`study'"'!=`"`_STUDY'"' qui rename `study' `_STUDY'	// (we can rename it since we are under -preserve-)
	}
	else if `"`r(newstudy)'"'!=`"`_STUDY'"' {	// if r(newstudy) *was* returned, use it
		cap drop `_STUDY'						// "capture" since `_STUDY' might not exist
		qui rename `r(newstudy)' `_STUDY'		// (N.B. can safely drop, since `_STUDY' can't be in lcols/rcols)
	}
	local adstudylab = cond(`"`r(newstudylab)'"'!=`""', `"`r(newstudylab)'"', `"`adstudylab'"')
		
	// `by' is largely left alone except for converting from string if necessary
	if "`by_in_AD'"!=`""' {
		local adbylab  = cond(`"`r(newbylab)'"'!=`""', `"`r(newbylab)'"', `"`adbylab'"')
		local by_in_AD = cond(`"`r(newby)'"'!=`""',    `"`r(newby)'"',    `"`by_in_AD'"')
		qui levelsof `by_in_AD', local(ad_bylist) missing		// for comparing with IPD
		if `"`by_in_AD'"'!=`"`_BY'"' & `"`_BY'"'!=`""' {
			cap drop `_BY'
			qui rename `by_in_AD' `_BY'
			local by_in_AD `_BY'
		}
		else if `"`_BY'"'==`""' local _BY `by_in_AD'
	}
	
		
	*** stuff specific to separate `ADfile'
		
	if `"`ADfile'"'!=`""' {

		// check for existence of npts and wgt
		if `"`adnpts'"'!=`""' {
			cap confirm numeric var `adnpts'
			if _rc {
				if _rc==111 disp as err `"variable {bf:`adnpts'} in option {bf:)} not found in aggregate dataset"'
				exit _rc
			}
		}
		if `"`wgt'"'!=`""' {
			cap confirm numeric var `wgt'
			if _rc {
				disp as err `"Note: user-defined weights {bf:`wgt'} not found in aggregate dataset"'
				local wgt
			}
		}

		// same with sortby and plotvar (but with slightly different error message)
		foreach v in sortby plotvar {
			if "`ad`v''"!="" {
				cap confirm var `ad`v''
				if _rc {
					nois disp as err `"Variable {bf:``v''} in option {bf:`v'()} not found in either IPD or AD dataset"'
					exit 111
				}
			}
		}

		// lcols/rcols: if don't exist in IPD dataset, check they exist in AD dataset
		if `"`adcolvars'"'!=`""' {
			foreach v of local adcolvars {
				cap confirm var `v'
				if _rc {
					nois disp as err `"Variable {bf:`v'}, in {bf:lcols()} or {bf:rcols()}, not found in either IPD or AD dataset"'
					exit 111
				}
			}
		}
		
		// discard unwanted observations and variables from `ADfile', to save memory
		if `"`lrcols'"'!=`""' {
			qui ds
			local dslist = r(varlist)
			local lrcols : list lrcols & dslist		// identify vars in `lrcols' present in `ADfile'
		}
		qui keep if `touse'
		cap sort `sortby'
		qui keep `touse' `_STUDY' `by_in_AD' `adinvlist' `adnpts' `wgt' `adplotvar' `adcolvars' `lrcols'
		qui gen byte `_USE' = 1
		
	}	// end if `"`ADfile'"'!=`""'
	
	else qui replace `_USE' = 1 if `touse'

	
	// Think about this.
	// We have an IPD dataset with "`_STUDY'" plus "_ES _seES" or "`invlist'"; and optionally `_BY', `_NN', `_USE'
	// We wish to append our AD dataset to this.  So:
	// 1. Get rid of extraneous vars
	// 2. Rename to tempvars (to avoid rename clashes, e.g. `study' might be named "_BY")
	// 3. Re-rename to the desired vars (_STUDY etc.)
		
	* Sort out `npts' in AD dataset;
	// only permitted with 2- or 3-element varlist; that is, "ES, seES", "ES, LCI, UCI", or "OE, V"
	if "`adnpts'"!="" {
		if `adparams'<=3 & "`integer'"=="" {
			cap assert int(`adnpts')==`adnpts' if `touse'
			if _rc {
				nois disp as err `"Non-integer counts found in {bf:npts()} option"'
				exit _rc
			}
		}
		else if `adparams'>3 {
			nois disp as err `"Option {bf:npts()} only valid with generic inverse-variance model or with logrank (O-E & V) HR"'
			exit 198
		}
		if `"`ipdnpts'"'!=`""' & `"`adnpts'"'!=`"`ipdnpts'"' {
			local badnames `"`_STUDY' `by_in_AD' `adinvlist' `wgt' `adplotvar' `adcolvars' `lrcols'"'
			if `: list adnpts in badnames' {
				disp as err `"varname conflict in {bf:npts()} suboption to {bf:ad()}"'
				exit 198
			}
			qui rename `adnpts' `ipdnpts'	// guaranteed to have this name if exists in IPD file
		}
		else return local npts `adnpts'		// else, tell admetan that npts now exists
	}
	
	// For AD, if count data (`adparams'==4) or logrank HR (`adlogrank') and no further info
	// then default to *log* (rather than to *eform* as for IPD)
	if `adparams'==4 {
		local eform = cond(`"`eform'"'==`""', `""', `"`eform'"')
		local log = cond(`"`eform'"'==`""', `"log"', `"`log'"')
		if `"`summstat'"'==`""' {
			local summstat "rr"
			local effect "Risk Ratio"
			local logstr = cond(`"`log'"'!=`""', `"log "', `""')
			disp as err _n `"Note: Effects assumed to represent `logstr'Risk Ratios, due to 2x2 count data in {bf:ad()}"'
		}
	}
	if `"`adlogrank'"'!=`""' {
		local eform = cond(`"`eform'"'==`""', `""', `"`eform'"')
		local log = cond(`"`eform'"'==`""', `"log"', `"`log'"')
		local summstat "hr"
		local effect "Haz. Ratio"
		local logstr = cond(`"`log'"'!=`""', `"log "', `""')
		disp as err _n `"Note: Effects assumed to represent `logstr'Hazard Ratios, due to {bf:logrank} suboption in {bf:ad()}"' 
	}
		
		
	** Compare AD & IPD data structures
	// Compatible structures:
	// any `ipdparams'==`adparams'; AD method/summstat/etc. is same as for IPD
	// assuming no obvious incompatibility (e.g. can't have IPD I-V, summstat="wmd" and `adparams'==4):
	//   IPD I-V (i.e. `params'==2 & !logrank);  AD method then also analysed as I-V
	//   AD  I-V (i.e. `params'==2 & !logrank); IPD method then also analysed as I-V -- ERROR IF NON-IV OPTIONS GIVEN
			
	// Incompatible structures:
	// IPD is M-H, `adparams'!=4
	// As above e.g. IPD is I-V, summstat="wmd" and `adparams'==4

	// N.B. If IPD is logrank, then if AD is O-E & V it *must* also specify logrank, o/w will be assumed to be _ES & _seES and I-V					
	local ad_iv = cond(inlist(`adparams', 2, 3) & "`adlogrank'"=="", "ad_iv", "")
	
	cap nois ProcessInputVarlist `_USE' `adinvlist' if `touse', ad `mh' summstat(`summstat') method(`method') ///
		`breslow' `cc' `chi2opt' `cornfield' `exact' `woolf' `adlogrank' `level' `ztol'

	// N.B. Here, some validity checks result in an error 184 (options X and Y may not be combined; i.e. IPD and AD incompatibility)
	//  which can be -capture-d and dealt with below (if `rc').
	local rc = _rc
	if _rc {
		if _rc==2000 nois disp as err "No studies found with sufficient data to be analysed"
		else if _rc==1 nois disp as err `"User break in {bf:admetan.ProcessInputVarlist}"'
		else nois disp as err `"Error in {bf:admetan.ProcessInputVarlist}"'
		c_local err "noerr"			// tell admetan not to also report an "error in ProcessAD"
		exit _rc
	}
	
	* If params are different *and neither* is I-V, analysis cannot (currently) be done; exit with error
	else if `"`ad_iv'`ipd_iv'"'==`""' ///
			& !(`adparams'==`params' & "`adlogrank'"=="`ipdlogrank'") {
		nois disp as err "IPD and AD data files are incompatible."
		nois disp as err "Need to either analyse within each dataset separately,"
		nois disp as err " or first manipulate the data so that they are compatible."
		exit 198
	}	

	* IPD and AD have same structure
	else if ("`ad_iv'"!="" & "`ipd_iv'"!="") | (`adparams'==`params' & "`adlogrank'"=="`ipdlogrank'") {

		assert `"`r(switchoff)'"'=="`switchoff'"
		assert `"`r(method)'"'=="`method'"
		assert `"`r(summstat)'"'=="`summstat'"

		// If data structures match, rename advarlist to match with IPD
		if `adparams'==`params' & "`adlogrank'"=="`ipdlogrank'" {
			local rc = 0	// reset
			local i = 1
			foreach adv of varlist `adinvlist' {
				local ipdv : word `i' of `invlist'
				if `"`adv'"'!=`"`ipdv'"' qui rename `adv' `ipdv'
				local rc = `rc' + _rc
				local ++i
			}
			if `rc' {
				nois disp as err `"{it:varlist} name conflict between IPD and aggregate data; please check"'
				exit _rc
			}
			local adinvlist `"`invlist'"'
			
			if inlist(`"`summstat'"', "hr", "shr") & `"`adlogrank'"'==`""' & `adparams'==2 {
				disp as err `"Note: Aggregate data variables assumed to represent {it:logHR} and {it:selogHR}"'
				disp as err `"      If in fact they should represent {it:O-E} and {it:V}, please supply the {bf:logrank} suboption to {bf:ad()}"' 
			}
		}

		// Else if structures *nearly* match; i.e. both I-V...
		// ...but one uses _ES, _seES and the other _ES, _LCI, _UCI
		else if (`adparams'==2 & `params'==3) | (`params'==2 & `adparams'==3) {
					
			gettoken adword1 adrest : adinvlist
			gettoken   word1   rest :   invlist
					
			cap assert `"`: list rest & adrest'"'==`""'
			if _rc {
				nois disp as err `"{it:varlist} name conflict between IPD and aggregate data; please check"'
				exit _rc
			}
					
			if `"`adword1'"'!=`"`word1'"' {
				cap nois rename `adword1' `word1'
				if _rc {
					nois disp as err `"{it:varlist} name conflict between IPD and aggregate data; please check"'
					exit _rc
				}
				local adinvlist `"`word1' `adrest'"'
			}
		}
	}	// end else if !`rc'
						
	// If one uses _ES, _seES (logHR, selogHR) but the other uses OE & V,
	//  display appropriate warning message r.e. confusion between whether AD input is really _ES, _seES or OE & V
	// (N.B. this may occur even if both are nominally I-V)
	else if `"`ipdlogrank'"'==`""' & `"`adlogrank'"'!=`""' & `params'==2 {
		disp as err `"Note: Aggregate data variables assumed to represent {it:O-E} and {it:V} due to {bf:logrank} suboption in {bf:ad()}"'
		local method "iv"
	}
	else if `"`ipdlogrank'"'!=`""' & `"`adlogrank'"'==`""' & `adparams'==2 {
		disp as err `"Note: Aggregate data variables assumed to represent {it:logHR} and {it:selogHR}"'
		disp as err `"      If in fact they should represent {it:O-E} and {it:V}, please supply the {bf:logrank} suboption to {bf:ad()}"' 
		disp as err `"     (that is, in addition to the {bf:logrank} main option to {bf:ipdmetan})"' 
		local method "iv"
	}	
	
	* Else one is I-V and the other is not (and structures are different)
	// then `invlist' and `adinvlist' should be disjoint: check this
	else {
		cap assert `"`: list invlist & adinvlist'"'==`""'
		if _rc {
			nois disp as err `"{it:varlist} name conflict between IPD and aggregate data; please check"'
			exit _rc
		}
		
		assert inlist(`"`r(method)'"', "`method'", "iv")
		assert `"`r(summstat)'"'=="`summstat'"
		local method "iv"
		
		local ivdata = cond("`ad_iv'"!="", "AD", "IPD")
		local nonivdata = cond("`ad_iv'"=="", "AD", "IPD")
		nois disp as err `"Note: `ivdata' has different variable structure to `nonivdata', but is assumed to be compatible"'
		nois disp as err `"      please check stated outcome, method and results carefully"'
		
		return local switchoff `"`r(switchoff)'"'
		
	}		// end else if `rc'

	

	*** APPEND IPD TO AD ***
	qui gen byte `_SOURCE' = 2 if `touse'
	if `"`ADfile'"'!=`""' qui append using `ipdfile'
	qui replace `_SOURCE' = 1 if missing(`_SOURCE') & `_USE'!=5
	label variable `_SOURCE' "Data source"			
		
	
	** Sort out various permutations of _BY
	
	// If byad, replace _USE==5 with _USE==3 in IPD dataset
	if `"`byad'"'!=`""' {
		qui replace `_USE' = 3    if `_USE'==5 & missing(`_SOURCE')
		qui replace `_SOURCE' = 1 if `_USE'==3 & missing(`_SOURCE')
	}
			
	// If `by' only exists in one dataset or the other, but NOT both:
	//  - if `by' in IPD but not AD, set AD value to r(max) + 1
	if `"`by_in_IPD'"'!=`""' & `"`by_in_AD'"'==`""' {
		summ `_BY' if `_SOURCE'==1, meanonly
		qui replace `_BY' = r(max) + 1 if `_SOURCE'==2
		label define `adbylab' `=r(max) + 1' "Aggregate data", add				
	}			
			
	//  - if `by' in AD but not IPD, set IPD value to r(min) - 1
	else if `"`by_in_AD'"'!=`""' & `"`by_in_IPD'"'==`""' {
		summ `_BY' if `_SOURCE'==2, meanonly
		qui replace `_BY' = r(min) - 1 if `_SOURCE'==1
		label define `adbylab' `=r(min) - 1' "IPD", add
	}
	
	// Finalise study and by labels
	label variable `_STUDY' `"`svarlab'"'
	if `"`studylab'"'!=`""' & `"`studylab'"'!=`"`adstudylab'"' {
		cap label drop `studylab'
		label copy `adstudylab' `studylab'
		label values `_STUDY' `studylab'
	}
	
	if `"`_BY'"'!=`""' {
		label variable `_BY' `"`byvarlab'"'
		
		local newbylab = cond(`"`by_in_IPD'"'==`""', `"`_BY'"', `"`bylab'"')
		if `"`newbylab'"'!=`""' & `"`newbylab'"'!=`"`adbylab'"' {
			cap label drop `newbylab'
			label copy `adbylab' `newbylab'
			label values `_BY' `newbylab'
		}
	}
	
	qui gen byte `adtouse' = `touse'	// this will have an effect in main routine, as `adtouse' tempvar was defined there
	
	// Return values
	return local adfile   `"`ADfile'"'
	return local ad_iv    `ad_iv'	
	return local by       `_BY'
	return local byad     `byad'
	return local eform    `eform'
	return local effect   `"`effect'"'
	return local invlist  `"`adinvlist'"'
	return local log      `log'
	return local logrank  `adlogrank'
	return local method   `method'
	return local overall  `overall'
	return local summstat `summstat'
	
end
	



**********************************************

* MyGetEFormOpts
// Basically _get_eformopts plus a bit extra!
// This program is used by both -ipdmetan- and -admetan-
//   and not all aspects are relevant to both.
// Easier to maintain just a single program, though.

program define MyGetEFormOpts, rclass
	
	// First, parse RR, since we want to stop it being interpreted as RRR by _get_eformopts
	syntax [name(name=cmdname)] , [ RR * ]

	** Estimation command syntax: use standard _check_eformopt
	if `"`cmdname'"'!=`""' {
		_check_eformopt `cmdname', eformopts(`options') soptions
		local eform = cond(`"`s(eform)'"'!=`""', "eform", "")
		local effect  `"`s(str)'"' 
		local summstat = cond(`"`s(opt)'"'==`"eform"', `""', `"`s(opt)'"')
	}
	
	** Non-estimation command syntax:
	// First, try _get_eformopts
	else {
		_get_eformopts, soptions eformopts(`options') allowed(__all__)
		local eform = cond(`"`s(eform)'"'!=`""', "eform", "")
		local effect  `"`s(str)'"' 
		local summstat = cond(`"`s(opt)'"'==`"eform"', `""', `"`s(opt)'"')
	}
	
	// Next, parse `anything' to extract anything that wouldn't usually be interpreted by _get_eformopts
	//  that is: mean differences (`md', `smd', `wmd'); `rd';
	//  `rr' (since this would usually be interpreted as `rrr' by _get_eformopts)
	//  `coef'/`log', and `nohr' & `noshr' (which imply `log')
	// (N.B. do this even if a valid option was found by _get_eformopts, since we still need to check for multiple options)
	local 0 `", `s(options)' `rr'"'
	syntax , [ COEF LOG MD SMD WMD RR RD NOHR NOSHR * ]

	// identify multiple options; exit with error if found
	if `"`summstat'"'!=`""' & `"`md'`smd'`wmd'`rr'`rd'`nohr'`noshr'"'!=`""' {
		opts_exclusive "`summstat' `md' `smd' `wmd' `rr' `rd' `nohr' `noshr'"
	}
	
	if `"`md'`wmd'"'!=`""' {		// MD and WMD are synonyms
		local effect `"WMD"'
		local summstat "wmd"
	}
	else if "`rr'"!="" {
		local effect `"Risk Ratio"'
		local summstat "rr"
		local eform `"eform"'
	}
	else {
		local effect = cond("`smd'"!="", `"SMD"', ///
			cond("`rd'"!="", `"Risk Diff."', ///
			cond("`rr'"!="", `"Risk Ratio"', `"`effect'"')))
		local summstat = cond(`"`summstat'"'==`""', `"`smd'`rd'`rr'"', `"`summstat'"')
	}
	else local summstat = cond(`"`nohr'"'!=`""', "hr", cond(`"`noshr'"'!=`""', "shr", `"`summstat'"'))

	// log always takes priority over eform
	// ==> cancel eform if appropriate
	local log = cond(`"`coef'"'!=`""', `"log"', `"`log'"')				// `coef' is a synonym for `log'
	if `"`log'"'!=`""' & inlist("`summstat'", "rd", "smd", "wmd") {
		nois disp as err "Log option only appropriate with ratio statistics"
		exit 198
	}
	if `"`log'`nohr'`noshr'"'!=`""' {
		local eform
		local log "log"
	}
	
	return local eform    `"`eform'"'
	return local log      `"`log'"'
	return local summstat `"`summstat'"'
	return local effect   `"`effect'"'
	return local options  `"`options'"'

end



* Routine to parse main options and forestplot options, and check for conflicts
// This program is used by both -ipdmetan- and -admetan-

// Certain options may be supplied EITHER to ipdmetan/admetan directly, OR as sub-options to forestplot()
//  with "forestplot options" prioritised over "main options" in the event of a clash.
// These options are:
// -eform- options (plus extra stuff parsed by MyGetEformOpts e.g. `rr', `rd', `md', `smd', `wmd', `log')
// nograph, nohet, nooverall, nosubgroup, nowarning, nowt
// effect, hetstat (ovstat), lcols, rcols, plotid, ovwt, sgwt, sgweight
// cumulative, efficacy, influence, interaction
// counts, group1, group2 (for compatibility with metan.ado)
// rfdist, rflevel (for compatibility with metan.ado)

program define ParseFPlotOpts, rclass

	// Obtain summary info and lists from main routine
	syntax [, CMDNAME(string) EFORM LOG MAINPROG(string) SUMMSTAT(string) SEFFECT(string) ///
		MAINOPTS(string asis) FPLOTOPTS(string asis)]

	// Parse "main options" (i.e. options supplied directly to -ipdmetan- or -admetan-)
	local 0 `", `mainopts'"'
	syntax [, noGRaph noHET noOVerall noSUbgroup noWARNing noWT ///
		EFFect(passthru) HETStat(passthru) OVStat(passthru) PLOTID(passthru) LCols(passthru) RCols(passthru) OVWt SGWt SGWEIGHT ///
		CUmulative EFFIcacy INFluence INTERaction COunts GROUP1(passthru) GROUP2(passthru) RFDist RFLevel(passthru) * ]

	return local mainopts `"`options'"'							// return anything else

	// Temporarily rename options which may be supplied as either "main options" or "forestplot options"
	local sgwt = cond("`sgweight'"!="", "sgwt", "`sgwt'")		// sgweight is a synonym (for compatibility with metan.ado)
	local sgweight
	
	local optionlist1 `"graph het overall subgroup warning wt ovwt sgwt"'
	local optionlist1 `"`optionlist1' cumulative efficacy influence interaction counts rfdist"'		// "stand-alone" options
	local optionlist2 `"effect hetstat ovstat plotid group1 group2 rflevel"'						// options requiring content within brackets
	local optionlist = trim(`"`optionlist1' `optionlist2' lcols rcols"')
	
	foreach opt of local optionlist {
		local `opt'_main : copy local `opt'
	}
		
	// Now parse forestplot options in the same way
	local 0 `", `fplotopts'"'
	syntax [, noGRaph noHET noOVerall noSUbgroup noWARNing noWT ///
		EFFect(passthru) HETStat(passthru) OVStat(passthru) PLOTID(passthru) LCols(passthru) RCols(passthru) OVWt SGWt SGWEIGHT ///
		CUmulative EFFIcacy INFluence INTERaction COunts GROUP1(passthru) GROUP2(passthru) RFDist RFLevel(passthru) * ]

	local sgwt = cond("`sgweight'"!="", "sgwt", "`sgwt'")		// sgweight is a synonym (for compatibility with metan.ado)
	local sgweight
	
	// Process -eform- for forestplot, and check for clashes/prioritisation
	cap nois MyGetEFormOpts `cmdname', `log' `options'
	if _rc exit _rc
	return local fplotopts `"`r(options)'"'						// return anything else
	
	if `"`summstat'"'!=`""' & `"`r(summstat)'"'!=`""' & `"`summstat'"'!=`"`r(summstat)'"' {
		nois disp as err `"Conflicting summary statistics supplied to {bf:`mainprog'} and to {bf:forestplot()}"'
		exit 198
	}	
	
	// Forestplot options take priority
	return local eform = cond(`"`log'"'!=`""', `""', cond(`"`r(eform)'"'!=`""', `"eform"', `"`eform'"'))
	return local log = cond(`"`r(log)'"'!=`""', `"`r(log)'"', `"`log'"')
	return local summstat = cond(`"`r(summstat)'"'!=`""', `"`r(summstat)'"', `"`summstat'"')
	return local seffect = cond(`"`r(effect)'"'!=`""', `"`r(effect)'"', `"`seffect'"')
	
	// lcols, rcols: these *cannot* conflict
	foreach opt in lcols rcols {
		if `"``opt''"'!=`""' & `"``opt'_main'"'!=`""' & `"``opt''"'!=`"``opt'_main'"' {
			nois disp as err `"Conflicting option {bf:`opt'} supplied to {bf:`mainprog'} and to {bf:forestplot()}"'
			exit 198
		}
		if `"``opt''"'==`""' & `"``opt'_main'"'!=`""' local `opt' : copy local `opt'_main
		local parsedopts `"`parsedopts' ``opt''"'
	}
	
	// Remaining options are allowed to conflict, but forestplot will take priority
	// However, display warning for options requiring content within brackets (`optionlist2')
	foreach opt of local optionlist1 {
		if `"``opt''"'==`""' & `"``opt'_main'"'!=`""' local `opt' : copy local `opt'_main
		local parsedopts `"`parsedopts' ``opt''"'
	}
	foreach opt of local optionlist2 {
		if `"``opt''"'!=`""' & `"``opt'_main'"'!=`""' & `"``opt''"'!=`"``opt'_main'"' {
			nois disp as err `"Note: Conflicting option {bf:`opt'()}; {bf:forestplot()} suboption will take priority"' 
		}
		if `"``opt''"'==`""' & `"``opt'_main'"'!=`""' local `opt' : copy local `opt'_main
		local parsedopts `"`parsedopts' ``opt''"'
	}

	return local parsedopts = trim(itrim(`"`parsedopts'"'))
	
end



**************************************************************************

* Program to process `study' and `by' labels
// based on ProcessAD.ado but altered quite a bit
// (called directly by admetan.ado early on)

program define ProcessLabels, rclass sortpreserve

	syntax [if] [in], NEWSTUDY(name) [NEWSTUDYLAB(name) STUDY(name) SMAX(integer 0) ///
		NEWBY(name) NEWBYLAB(name) BY(name) NBY(integer 0) BYAD RELabel]
			 
	// First, test for *existence* of `study' and `by' in current data
	cap confirm variable `study'
	if _rc local study
	cap confirm variable `by'
	if _rc local by
	
	// Next, mark sample and check that it is populated
	marksample touse
	qui count if `touse'
	if !r(N) {
		if `"`study'"'!=`""' {
			local errtext `"in {bf:study()} variable"'
			if `"`by'"'!=`""' local errtext `"`errtext' or "'
		}
		if `"`by'"'!=`""' local errtext `"`errtext'in {bf:by()} variable"'
		nois disp as err `"no valid observations `errtext'"'
		exit 2000
	}	
	local nsad = r(N)
	
	tempvar obs
	qui gen long `obs' = _n

	
	** Subgroup (`by') labelling (if applicable)
	// N.B. do this first, in case `by' is string and contains missings. Stata sorts string missings to be *first* rather than last.
	// If IPD alone, ProcessLabels will never be run.
	// If AD alone, no need for a new variable (`newby') unless `by' is string, but tempvar is set just in case
	// If IPD+AD, `by' contains the AD by-var and `newby' contains "_BY" (i.e. the name of the var used in IPD, with label `newbylab')
	if `"`by'"'!=`""' {

		cap confirm numeric variable `by'

		// If AD alone, or IPD+AD but `by' doesn't appear in IPD, no need to do anything (this is !`nby')
		// else, map AD values onto IPD label and check for conflicts
		if !_rc & `nby' {
			tempvar bygroup
			qui bysort `touse' `by' : gen long `bygroup' = (_n==1) if `touse'
			qui bysort `touse' : replace `bygroup' = sum(`bygroup') if `touse'
			local nby = `bygroup'[_N]
						
			sort `obs'
			forvalues i=1/`nby' {
				summ `obs' if `touse' & `bygroup'==`i', meanonly
				local val = `by'[`r(min)']
						
				local bylabi    : label (`by') `val'					// AD label value (not "strict")
				local newbylabi : label `newbylab' `val', strict		// IPD label value ("strict")
				if `"`newbylabi'"'==`""' & `val'!=. {
					label define `newbylab' `val' "`bylabi'", add
				}					
				 else {
					local bylabi : label (`by') `val', strict			// "strict" AD label value
					if `"`newbylabi'"'!=`"`bylabi'"' & `"`bylabi'"'!=`""' {
						nois disp as err `"Subgroup value label conflict at value `val'"'
						exit 180
					}
				}
			}
			local newby `by'
			return local newby    "`by'"			// use existing variable...
			return local newbylab "`newbylab'"		// ...but new (extended from IPD) varlab
		}

		// string
		else if _rc {
			cap confirm var `newby'
			if _rc qui gen `newby' = .
			tempvar newby_temp
			qui encode `by' if `touse', gen(`newby_temp') label(`newbylab')	// order automatically if label not yet defined
			qui replace `newby' = `newby_temp' if `touse'
			label values `newby' `newbylab'
			return local newby    "`newby'"
			return local newbylab "`newbylab'"
		}
		
		// else, still need `newby' for subequent code
		else local newby `by'		
		
	}	// end if `"`by'"'!=`""'
	else local newby

	
	** Study label
	// If AD numeric, check for clash with IPD.
	//   If clash and `relabel' not specified, exit with error; create new AD var starting from [max IPD value] + 1
	//       i.e. take oldlabel value from oldAD[i] and map it to `i' + `smax' newlabel
	//   If no clash, loop over AD values and add to existing IPD label
	//       i.e. take oldlabel value from oldAD[i] and map it to oldAD[i] newlabel
	// If AD string, create numeric var starting starting from [max IPD value] + 1
	//       i.e. take oldstring and map it to `i' + `smax' newlabel
	// If AD doesn't have `study', create dummy var starting from [max IPD value] + 1
	//       (no labelling to be done; empty labels)

	// if `study' is numeric, labelled, and *not* IPD+AD (i.e. !`smax'), no need to do anything
	cap confirm numeric var `study'
	local rc = _rc
	local noloop = !`rc' & !`smax'
	if `"`study'"'!=`""' {
		local noloop = `noloop' * (`"`: value label `study''"'!=`""')
	}
	
	// else, need to loop over `study' values and define a new label
	if !`noloop' {

		// If AD is string/missing, or if IPD+AD and clash ==> AD relabelling, use/gen new AD variable `newstudy'
		if `rc' | `"`relabel'"'!=`""' {
			cap confirm variable `newstudy'
			if _rc qui gen long `newstudy' = .
			qui bysort `touse' (`newby' `obs') : replace `newstudy' = _n + `smax' if `touse'
			sort `newstudy'				// studies of interest should now be the first `nsad' observations
			return local newstudy "`newstudy'"
		}
		else local smax = 0				// if not generating new variable, don't offset
		
		// Before continuing, find the first obs (under current sort) where `touse'==1
		qui replace `obs' = _n
		summ `obs' if `touse', meanonly
		local offset = r(min)
		
		// Now either generate new AD label, or add AD values to existing IPD label (`newstudylab')
		forvalues i=1/`nsad' {
			
			local si_new = `i' + `smax'		// if string or missing
		
			// if `study' not present, create "dummy" label consisting of `si_new' values
			if `"`study'"'==`""' {
				label define `newstudylab' `si_new' `"`si_new'"', add
			}
			
			else {
				local si_old = `study'[`=`i' + `offset' - 1']
				if !`rc' {
					local si_new = cond(`smax', `i' + `smax', `si_old')		// numeric
				}
			
				// if `study' is numeric and labelled, copy `study' value labels across to `newstudylab'
				// (offset by `smax' if `relabel', o/w not)
				if !`rc' {
					cap assert `"`: label `newstudylab' `si_new''"'==`"`: label (`study') `si_old''"'	// if label is already defined correctly, don't attempt to re-label
					if _rc label define `newstudylab' `si_new' `"`: label (`study') `si_old''"', add
				}
				
				// if `study' is string, put `study' strings into `newstudylab' values (offset by `smax')
				else {
					cap assert `"`: label `newstudylab' `si_new''"'==`"`si_old'"'	// if label is already defined correctly, don't attempt to re-label
					if _rc label define `newstudylab' `si_new' `"`si_old'"', add
				}
			}
		}

		return local newstudylab "`newstudylab'"
	}
	
end




*********************************************************************

* Program to parse inputted varlist structure and
// - identify studies with insufficient data (`_USE'==2)
// - check for validity

// (N.B. called by admetan.ado early on)

/*
Syntax:
a) binary data (4 vars):
		admetan #events_research #nonevents_research #events_control #nonevents_control , ...
b) cts data (6 vars):     
		admetan #N_research mean_research sd_research  #N_control mean_control sd_control , ...
c) logrank survival (OE & V) (2 vars): 
		admetan theta oe v, [NPTS(varname numeric] ...
d) generic inverse-variance (2 vars): 
		admetan theta se_theta , [NPTS(varname numeric] ...
e) generic inverse-variance with CI instead of SE (3 vars): 
		admetan theta lowerlimit upperlimit , [NPTS(varname numeric] ...
*/

program define ProcessInputVarlist, rclass
	
	syntax varlist(min=2 max=8 default=none numeric) [if] [in], ///
		[SUMMSTAT(string) METHOD(string) BREslow ///
		AD MH CC(string) CORnfield EXact WOolf noINTeger CHI2opt LOG LOGRank ZTOL(real 1e-6)]

	marksample touse
	
	local chi2 `chi2opt'		// just within this subroutine, for error display; o/w `chi2opt' is the on/off macro
	
	gettoken _USE varlist : varlist
	tokenize `varlist'
	
	cap assert "`7'" == ""
    if _rc {
		nois disp as err "Too many variables specified"
		exit _rc
	}

	local aggregate = cond("`ad'"=="", "", "aggregate ")
	
	if "`6'"=="" {

		// input is generic inverse-variance (2 or 3 vars) or HR logrank (2 vars)
		if "`4'"=="" {
			
			// input is HR logrank (2 vars: OE & V)
			if "`logrank'" != "" {
				assert "`3'"=="" & "`2'"!=""
				
				// Default method is Peto; can also be I-V (Cochran heterogeneity)
				if "`method'"=="mh" {
					if "`ad'"=="" nois disp as err "Mantel-Haenszel methods are incompatible with log-rank hazard ratios"
					else nois disp as err "Aggregate data identified as log-rank; Mantel-Haenszel methods are incompatible"
					exit 184
				}
				else if !inlist("`method'", "", "peto", "iv") {
					nois disp as err "Specified method is incompatible with the `aggregate'data"
					exit 184
				}
				
				local summstat "hr"
				local effect `"Haz. Ratio"'
				local method = cond("`method'"!="", "`method'", "peto")
			}

			// input is _ES, _seES or _ES, _LCI, _UCI
			else {
				// Method can only be I-V (which may include WMD/SMD methods if AD)
				if "`ad'"=="" & !inlist("`method'", "iv", "") {
					nois disp as err `"Specified method is incompatible with the data"'
					exit 184
				}
				if "`ad'"!="" & inlist("`method'", "mh", "peto") {
					if "`mh'"!="" nois disp as err `"Note: specified method {bf:`method'} is incompatible with the aggregate data and will be ignored"'
					local method "iv"
				}
				local method = cond("`method'"!="", "`method'", "iv")
			}
			
			// switch off incompatible options
			foreach opt in breslow cc chi2opt cornfield exact woolf {
				cap assert `"``opt''"' == `""'
				if _rc {
					nois disp as err `"Note: Option {bf:`opt'} is not appropriate without 2x2 count data and will be ignored"' 
					local switchoff `"`switchoff' `opt'"'
				}
			}			
			
			// Identify studies with insufficient data (`_USE'==2)
			if "`3'"=="" { 	// input is ES + SE
				args _ES _seES
				qui replace `_USE' = 2 if `touse' & `_USE'==1 & missing(`_ES', `_seES')
				qui replace `_USE' = 2 if `touse' & `_USE'==1 & `_seES'==0
				
				// if logrank, `_seES' actually contains (hypergeometric) `v', so 1/se becomes sqrt(v)
				if "`logrank'"=="" qui replace `_USE' = 2 if `touse' & `_USE'==1 & 1/`_seES' < `ztol'
				else qui replace `_USE' = 2 if `touse' & `_USE'==1 & sqrt(`_seES') < `ztol'
			}

			else { 	// input is ES + CI
				args _ES _LCI _UCI
				qui replace `_USE' = 2 if `touse' & `_USE'==1 & missing(`_LCI', `_UCI')
				qui replace `_USE' = 2 if `touse' & `_USE'==1 & float(`_LCI')==float(`_UCI')
				cap assert `_UCI'>=`_ES' & `_ES'>=`_LCI' if `touse' & `_USE'==1
				if _rc {
					nois disp as err "Effect size and/or confidence interval limits invalid;"
					nois disp as err `"order should be {it:effect_size} {it:lower_limit} {it:upper_limit}"'
					exit _rc
				}
				qui replace `_USE' = 2 if `touse' & `_USE'==1 & 2*invnormal(.975)/(`_UCI' - `_LCI') < `ztol'
			}
			qui count if `touse' & `_USE'==1
			if !r(N) exit 2000			
			
		}       // end of inverse-variance setup

		// input is 2x2 tables
		else {
			cap assert "`5'"==""
			if _rc {
				nois disp as err "Invalid number of variables specified" 
				exit _rc
			}
			args e1 f1 e0 f0	// events, non-events in trt group; events, non-events in ctrl group (a.k.a. a b c d)
			
			if "`integer'"=="" {
				cap {
					assert int(`e1')==`e1' if `touse'
					assert int(`f1')==`f1' if `touse'
					assert int(`e0')==`e0' if `touse'
					assert int(`f0')==`f0' if `touse'
				}
				if _rc {
					di as err "Non integer cell counts found" 
					exit _rc
				}
			}
			cap assert `e1'>=0 & `f1'>=0 & `e0'>=0 & `f0'>=0 if `touse'
			if _rc {
				di as err "Non-positive cell counts found" 
				exit _rc
			}

			if `"`cc'"'!=`""' {		// if exists, `cc' will be numeric; already tested for this
			
				// ensure continuity correction is valid
				if "`method'"=="peto" & !`cc' {
					nois disp as err "Note: continuity correction is incompatible with Peto method and will be ignored"
					local switchoff `"`switchoff' cc"'
				}
				else {
					cap assert `cc'>=0 & `cc'<1
					if _rc {
						nois disp as err "Invalid continuity correction: must be in range [0,1)"
						exit _rc
					}
				}
			}
			
			if "`chi2'"!="" {
				if !inlist("`summstat'", "or", "") {
					nois disp as err `"Note: {bf:chi2} is only compatible with odds ratios; option will be ignored"' 
					local switchoff `"`switchoff' chi2opt"'
				}
				else if "`summstat'"=="" {
					nois disp as err `"Note: Chi-squared option specified; odds ratios assumed"' 
					local summstat "or"
				}
			}
			
			opts_exclusive `"`cornfield' `exact' `woolf'"' `""' 184
			local opt `cornfield'`exact'`woolf'
			if `"`opt'"'!=`""' {
				if !inlist("`summstat'", "or", "") {
					nois disp as err "Note: {bf:`opt'} is only compatible with odds ratios; option will be ignored"' 
					local switchoff `"`switchoff' `opt'"'
				}
				else if "`summstat'"=="" {
					if "`opt'"=="cornfield" {
						nois disp as err `"Note: Cornfield-type confidence intervals specified; odds ratios assumed"'
					}
					else if "`opt'"=="exact" {
						nois disp as err `"Note: Exact confidence intervals specified; odds ratios assumed"'
					}
					else {
						nois disp as err `"Note: Woolf-type confidence intervals specified; odds ratios assumed"'
					}
					local summstat "or"
				}
			}
			
			// Breslow-Day homogeneity test is only valid for OR M-H (c.f. SAS PROC FREQ documentation)
			if "`breslow'"!="" {
				if !inlist("`summstat'", "or", "") | !inlist("`method'", "mh", "") {
					nois disp as err `"{bf:breslow} is only compatible with M-H odds ratios; option will be ignored"' 
					local switchoff `"`switchoff' breslow"'
				}
				else if "`summstat'"=="" | "`method'"=="" {
					local warntxt = cond("`summstat'"!="", "Mantel-Haenszel method",
						cond("`method'"=="", "Mantel-Haenszel odds ratios", "odds ratios"))
					nois disp as err `"Breslow-Day homogeneity test specified; `warntxt' assumed"' 
					
					if "`summstat'"=="" {
						local summstat or
						local effect `"Odds Ratio"'
					}
					local method  = cond("`method'"!="",  "`method'",  "mh")
				}
			}
			
			if inlist("`method'", "cohen", "glass", "hedges", "nostandard") {
				nois disp as err `"Specified method {bf:`method'} is incompatible with the `aggregate'data"'
				exit 184
			}
			if inlist("`summstat'", "hr", "shr", "tr") {
				if "`ad'"=="" nois disp as err "Time-to-event outcome types are incompatible with count data"
				else nois disp as err `"Aggregate data identified as count data; {bf:`=upper(`summstat')'} outcome is incompatible"'
				exit 184
			}
			if inlist("`summstat'", "wmd", "smd") {
				if "`ad'"=="" nois disp as err "Continuous outcome types are incompatible with count data"
				else nois disp as err `"Aggregate data identified as count data; {bf:`=upper(`summstat')'} outcome is incompatible"'
				exit 184
			}
			if "`method'"=="peto" {
				if !inlist("`summstat'", "or", "") {
					nois disp as err "Peto method option can only be used with odds ratios"
					exit 184
				}
				else if "`summstat'"=="" {
					nois disp as err `"Note: Peto method specified; odds ratios assumed"' 
					local summstat "or"
				}
			}
			
			if "`summstat'"=="" {
				local summstat rr
				local effect `"Risk Ratio"'
			}
			local method = cond("`method'"=="", "mh", "`method'")		// default pooling method is Mantel-Haenszel

			// Find studies with insufficient data (`_USE'==2)			
			qui replace `_USE' = 2 if `touse' & `_USE'==1 & missing(`e1', `f1', `e0', `f0')
			if "`summstat'"=="or" qui replace `_USE' = 2 if `touse' & `_USE'==1 & (`e1' + `e0')*(`f1' + `f0')==0
			if inlist("`summstat'", "rr", "irr", "rrr") | "`method'"=="peto" {
				qui replace `_USE' = 2 if `touse' & `_USE'==1 & ((`e1'==0 & `e0'==0 ) | (`f1'==0 & `f0'==0))
			}
			qui replace `_USE' = 2 if `touse' & `_USE'==1 & (`e1' + `f1')*(`e0' + `f0')==0		// applies to all cases
			qui count if `touse' & `_USE'==1
			if !r(N) exit 2000			
			
		} // end of binary variable setup

		// log only allowed if OR, RR, IRR, RRR, HR, SHR, TR
		if "`log'"!="" & !inlist("`summstat'", "or", "rr", "irr", "rrr", "hr", "shr", "tr") {
			nois disp as err `"{bf:log} may only be specified with 2x2 count data or log-rank HR; option will be ignored"'
			local switchoff `"`switchoff' log"'
		}			
		
	} // end of all non-6 variable setup

	if "`6'"!="" {
		
		// log not allowed
		if "`log'"!="" {
			nois disp as err `"{bf:log} may only be specified with 2x2 count data or log-rank HR; option will be ignored"'
			local switchoff `"`switchoff' log"'
		}			

		args n1 mean1 sd1 n0 mean0 sd0

        // input is form N mean SD for continuous data
		if "`integer'"=="" {
			cap assert int(`n1')==`n1' & int(`n0')==`n0' if `touse'
			if _rc {
				nois disp as err "Non integer sample sizes found"
				exit _rc
			}
		}
        cap assert `n1'>0 & `n0'>0 if `touse'
		if _rc {
			nois disp as err "Non positive sample sizes found" 
			exit _rc
		}
		
		foreach opt in breslow cc chi2 cornfield exact woolf {
			cap assert `"``opt''"' == `""'
			if _rc {
				nois disp as err `"Option {bf:`opt'} is not appropriate without 2x2 count data and will be ignored"' 
				local switchoff `"`switchoff' `opt'"'
			}
		}

		if "`method'"=="nostandard" & "`summstat'"=="smd" {
			nois disp as err `"Cannot specify both SMD and the {bf:nostandard} option"'
			exit 184
		}
		if inlist("`method'", "cohen", "glass", "hedges") & "`summstat'"=="wmd" {
			nois disp as err `"Cannot specify both WMD and the {bf:`mdmethod'} option"'
			exit 184
		}
		if inlist("`method'", "mh", "peto") | "`logrank'"!="" {
			nois disp as err `"Specified method {bf:`method'} is incompatible with the `aggregate'data"'
			exit 184
		}
		cap assert inlist("`summstat'", "", "wmd", "smd")
		if _rc {
			if "`ad'"=="" nois disp as err "Invalid specifications for combining trials"
			else nois disp as err `"Summary statistic {bf:`summstat'} is incompatible with the `aggregate'data"'
			exit 184
		}

		if "`summstat'"=="" {
			if "`method'"=="nostandard" {		// "nostandard" is a synonym for "wmd"
				local summstat "wmd"
				local effect `"WMD"'
			}
			else {
				local summstat "smd"			// default is standardized mean differences...
				local effect `"SMD"'
			}
		}
		local method  = cond(inlist("`method'", "", "iv"), "cohen", "`method'")		//   ...by the method of Cohen

		// Find studies with insufficient data (`_USE'==2)
		qui replace `_USE' = 2 if `touse' & `_USE'==1 & missing(`n1', `mean1', `sd1', `n0', `mean0', `sd0')
		qui replace `_USE' = 2 if `touse' & `_USE'==1 & `n1' < 2  | `n0' < 2
		qui replace `_USE' = 2 if `touse' & `_USE'==1 & `sd1'<=0  | `sd0'<=0
		qui count if `touse' & `_USE'==1
		if !r(N) exit 2000

	} // end of 6-var set-up
	
	return local summstat  `"`summstat'"'
	return local effect    `"`effect'"'
	return local method    `"`method'"'
	return local switchoff `"`switchoff'"'		// need to switch off in the main routine, not here
	
end




*********************

* Routine to draw output table (admetan.ado version)
// Could be done using "tabdisp", but doing it myself means it can be tailored to the situation
// therefore looks better (I hope!)

// subroutine of MainRoutine

program define DrawTableAD, rclass sortpreserve

	syntax varlist(min=6 max=7 numeric) [if] [in], SORTBY(varlist) ///
		[LABELS(varname string) LABLEN(integer 0) STITLE(string asis) ETITLE(string asis) ///
		BY(varname) BYSTATS(name) METHOD(string) CUmulative INFluence Q(name) QDIFF(name) DFKR(name) CHI2(name) T ///
		ISQ(numlist min=1 max=3 miss) HSQ(numlist min=1 max=3 miss) TAUSQ(numlist min=1 max=3 miss) ///
		EFORM noTABle noHET noOVerall noSUbgroup BREslow SA * ]
		
	marksample touse, novarlist		// -novarlist- option prevents -marksample- from setting `touse' to zero if any missing values in `varlist'

	// local re_model `remodel'		// for clarity
	local df_kr `dfkr'
	
	// unpack varlist
	tokenize `varlist'
	args _USE _ES _seES _LCI _UCI _WT _NN
	
	// create `study' if missing
	tempvar obs
	if `"`study'"'==`""' {
		tempvar touse1 study
		qui gen long `obs' = _n
		qui gen byte `touse1' = `touse' * inlist(`_USE', 1, 2)	
		qui bysort `touse1' (`obs'): gen long `study' = _n if `touse1'
		drop `obs' `touse1'
	}
	
	// now re-create `obs', sorting by `sortby', and create matrix of coefficients
	// (N.B. done within DrawTableAD so as to avoid having to sort within the main routine)
	sort `touse' `by' `_USE' `sortby'
	qui gen long `obs' = _n
	tempname coeffs
	mkmat `by' `study' `_ES' `_seES' `_NN' `_WT' if `touse' & inlist(`_USE', 1, 2), matrix(`coeffs')

	local _BYname = cond( `"`by'"'!=`""', "_BY", "")
	local _NNname = cond(`"`_NN'"'!=`""', "_NN", "")
	local _WTname = cond(`"`_WT'"'!=`""', "_WT", "")
	matrix colnames `coeffs' = `_BYname' _STUDY _ES _seES `_NNname' `_WTname'
	return matrix coeffs = `coeffs'	

	// do this beforehand in case of `"`table'"'==`""'
	if `"`by'"'!=`""' {
		qui levelsof `by' if `touse' & `_USE'!=5, missing local(bylist)		// "missing" since `touse' should already be appropriate for missing yes/no
		local bylab : value label `by'										// but `_USE'!=5 since that will be missing anyway
	}
	local nby = max(1, `: word count `bylist'')
	
	// table of results
	local swidth = 21				// define `swidth' in case noTAB
	if `"`table'"'==`""' {
	
		* Find maximum length of study title and effect title
		// Allow them to spread over several lines, but only up to a maximum number of chars
		// If a single line must be more than 32 chars, truncate and stop
		local uselen = 20										// default (minimum); max is 32
		if `lablen'>20 local uselen = min(`lablen', 31)
		SpreadTitle `stitle', target(`uselen') maxwidth(31)		// study (+ subgroup) title
		local swidth = 1 + max(`uselen', `r(maxwidth)')
		local slines = r(nlines)
		forvalues i=1/`slines' {
			local stitle`i' `"`r(title`i')'"'
		}
		SpreadTitle `etitle', target(10) maxwidth(15)		// effect title (i.e. "Odds ratio" etc.)
		local ewidth = 1 + max(10, `r(maxwidth)')
		local elines = r(nlines)
		local diff = `elines' - `slines'
		if `diff'<=0 {
			forvalues i=1/`slines' {
				local etitle`i' `"`r(title`=`i'+`diff'')'"'		// stitle uses most lines (or equal): line up etitle with stitle
			}
		}
		else {
			forvalues i=`elines'(-1)1 {					// run backwards, otherwise macros are deleted by the time they're needed
				local etitle`i' `"`r(title`i')'"'
				local stitle`i' = cond(`i'>=`diff', `"`stitle`=`i'-`diff'''"', `""')	// etitle uses most lines: line up stitle with etitle
			}
		}
		
		* Now display the title lines, starting with the "extra" lines and ending with the row including CI & weight
		di as text _n "{hline `swidth'}{c TT}{hline `=`ewidth'+35'}"
		local nl = max(`elines', `slines')
		if `nl' > 1 {
			forvalues i=1/`=`nl'-1' {
				di as text "`stitle`i''{col `=`swidth'+1'}{c |} " %~`ewidth's `"`etitle`i''"'
			}
		}
		di as text "`stitle`nl''{col `=`swidth'+1'}{c |} " %~10s `"`etitle`nl''"' "{col `=`swidth'+`ewidth'+4'}[`c(level)'% Conf. Interval]{col `=`swidth'+`ewidth'+27'}% Weight""
		local final


		*** Loop over studies, and subgroups if appropriate
	
		tempvar touse2
		gen byte `touse2' = `touse'
		
		tempname _ES_ _LCI_ _UCI_
		local xexp = cond("`eform'"!=`""', `"exp"', `""')

		forvalues i=1/`nby' {				// this will be 1/1 if no subgroups

			di as text "{hline `swidth'}{c +}{hline `=`ewidth'+35'}"

			if `"`by'"'!=`""' {
				local byi : word `i' of `bylist'
				qui replace `touse2' = `touse' * (`by'==`byi')
				summ `_ES' if `touse2' & `_USE'==1, meanonly
				if !r(N) local nodata "{col `=`swidth'+4'} (No subgroup data)"
				else local K`i' = r(N)
				
				if `"`bylab'"'!=`""' {
					local bylabi : label `bylab' `byi'
				}
				else local bylabi `"`byi'"'
				di as text substr(`"`bylabi'"', 1, `swidth'-1) + "{col `=`swidth'+1'}{c |}`nodata'"
				local nodata	// clear macro
			}

			summ `obs' if `touse2' & inlist(`_USE', 1, 2), meanonly
			if r(N) {	
				forvalues k = `r(min)' / `r(max)' {
					if missing(`_ES'[`k']) {
						di as text substr(`labels'[`k'], 1, 32) "{col `=`swidth'+1'}{c |}{col `=`swidth'+4'} (Insufficient data)"
					}
					else {
						scalar `_ES_'  = `_ES'[`k']
						scalar `_LCI_' = `_LCI'[`k']
						scalar `_UCI_' = `_UCI'[`k']
						local _labels_ = `labels'[`k']

						di as text substr(`"`_labels_'"', 1, 32) `"{col `=`swidth'+1'}{c |}{col `=`swidth'+`ewidth'-6'}"' ///
							as res %7.3f `xexp'(`_ES_') `"{col `=`swidth'+`ewidth'+5'}"' ///
							as res %7.3f `xexp'(`_LCI_') `"{col `=`swidth'+`ewidth'+15'}"' ///
							as res %7.3f `xexp'(`_UCI_') `"{col `=`swidth'+`ewidth'+26'}"' %7.2f 100*`_WT'[`k']
					}
				}
			}

			* Subgroup effects
			if `"`by'"'!=`""' & `"`subgroup'"'==`""' & `"`cumulative'"'==`""' {
				di as text "{col `=`swidth'+1'}{c |}"
				
				local byi: word `i' of `bylist'
				summ `obs' if `touse' & `by'==`byi' & `_USE'==3, meanonly
				if !r(N) {
					di as text `"Subgroup effect{col `=`swidth'+1'}{c |}{col `=`swidth'+4'} (Insufficient data)"'
				}
				else {		
					scalar `_ES_' = `_ES'[`r(min)']
					if missing(`_ES_') {
						di as text `"Subgroup effect{col `=`swidth'+1'}{c |}{col `=`swidth'+4'} (Insufficient data)"'
					}
					else {
						scalar `_LCI_' = `_LCI'[`r(min)']
						scalar `_UCI_' = `_UCI'[`r(min)']

						di as text `"Subgroup effect{col `=`swidth'+1'}{c |}{col `=`swidth'+`ewidth'-6'}"' ///
							as res %7.3f `xexp'(`_ES_') `"{col `=`swidth'+`ewidth'+5'}"' ///
							as res %7.3f `xexp'(`_LCI_') `"{col `=`swidth'+`ewidth'+15'}"' ///
							as res %7.3f `xexp'(`_UCI_') `"{col `=`swidth'+`ewidth'+26'}"' %7.2f 100*`_WT'[`r(min)']
					}
				}
			}
		}		// end forvalues i=1/`nby'
		
		drop `touse2'	// tidy up
			

		*** Overall effect
		if `"`overall'"'==`""' & `"`cumulative'"'==`""' {
			di as text "{hline `swidth'}{c +}{hline `=`ewidth'+35'}"
		
			summ `obs' if `touse' & `_USE'==5, meanonly
			if !r(N) {
				di as text `"Overall effect{col `=`swidth'+1'}{c |}{col `=`swidth'+4'} (Insufficient data)"'
			}			
			else {
				scalar `_ES_' = `_ES'[`r(min)']
				if missing(`_ES_') {
					di as text `"Overall effect{col `=`swidth'+1'}{c |}{col `=`swidth'+4'} (Insufficient data)"'
				}
				else {
					scalar `_LCI_' = `_LCI'[`r(min)']
					scalar `_UCI_' = `_UCI'[`r(min)']
		
					di as text %-20s `"Overall effect{col `=`swidth'+1'}{c |}{col `=`swidth'+`ewidth'-6'}"' ///
						as res %7.3f `xexp'(`_ES_') `"{col `=`swidth'+`ewidth'+5'}"' ///
						as res %7.3f `xexp'(`_LCI_') `"{col `=`swidth'+`ewidth'+15'}"' ///
						as res %7.3f `xexp'(`_UCI_') `"{col `=`swidth'+`ewidth'+26'}"' %7.2f 100*`_WT'[`r(min)']
				}
			}
		}
		di as text "{hline `swidth'}{c BT}{hline `=`ewidth'+35'}"
	
	}	// end if `"`table'"'==`""'

	if `"`overall'"'==`""' {
		summ `obs' if `touse' & `_USE'==1, meanonly
		local k = r(N)
		local df_ov = `k' - 1
	}
	
	* Tests, heterogeneity etc.
	local xtext = cond(`"`cumulative'"'!=`""', `"cumulative "', `""')		// n/a for influence
		
	* Test of pooled effect equal to zero
	local null = (`"`eform'"'!=`""')

	// display by subgroup
	if `"`by'"'!=`""' & `"`subgroup'"'==`""' {
		di as text _n "Tests of `xtext'effect size = " as res `null' as text ":"

		forvalues i=1/`nby' {
			local byi: word `i' of `bylist'
			if `"`bylab'"'!=`""' {
				local bylabi : label `bylab' `byi'
			}
			else local bylabi `"`byi'"'

			local testStat = .
			summ `obs' if `touse' & `by'==`byi', meanonly		// will be last _USE==1 obs if cumulative; o/w will be _USE==3
			if r(N) {
				local testStat = `_ES'[`r(max)'] / `_seES'[`r(max)']	// default
			}
			local tdf = cond(!missing(`=colnumb(`bystats', "df_kr")'), `bystats'[`i', `=colnumb(`bystats', "df_kr")'], ///
				`bystats'[`i', `=colnumb(`bystats', "k")'] - 1)

			* Test statistic and distribution
			// chi2 distribution
			if "`chi2'"!="" {
				local testDist "chi{c 178}"
				local testStat = `bystats'[`i', `=colnumb(`bystats', "chi2")']		// replaces default
				local pvalue = chi2tail(1, `testStat')
				local testStat_text `"%6.2f `testStat'"'
				local df_text `"" on " as res 1 as text " df,""'
			}

			// t distribution
			else if "`t'"!="" & `tdf'>0 & !missing(`tdf') {
				local testDist "t"
				local pvalue = 2*ttail(`tdf', abs(`testStat'))
				local testStat_text `"%7.3f `testStat'"'
				local df_fmt = cond(!missing(`=colnumb(`bystats', "df_kr")'), "%6.2f", "%3.0f")
				local df_text `"" on " as res `df_fmt' `tdf' as text " df,""'
			}

			// normal (z) distribution
			else {
				local testDist "z"
				local pvalue = 2*normal(-abs(`testStat'))
				local testStat_text `"%7.3f `testStat'"'
				if "`t'"!="" {		// if other subgroups use t, leave gap so as to line up
					local df_fmt = cond(!missing(`=colnumb(`bystats', "df_kr")'), "%6.2f", "%3.0f")
					local df_text `"`"`: disp _dup(`=8 + cond(!missing(`=colnumb(`bystats', "df_kr")'), 6, 3)') " "'"'"'
				}
			}

			if missing(`testStat') {
				di as text substr("`bylabi'", 1, `swidth'-1) "{col `=`swidth'+1'}(Insufficient data)"
			}
			else {
				di as text substr("`bylabi'", 1, `swidth'-1) "{col `=`swidth'+1'}" as res "`testDist'" as text " = " as res `testStat_text' as text `df_text' "  p = " as res %5.3f `pvalue'
			}
		}
	}
	
	// display overall
	if `"`overall'"'==`""' {
		local testStat = .
		summ `obs' if `touse' `noxtext', meanonly		// will be last _USE==1 obs if cumulative; o/w will be _USE==5
		if r(N) {
			local testStat = `_ES'[`r(max)'] / `_seES'[`r(max)']
		}
		if "`df_kr'"!="" {
			local tdf = `df_kr'
		}
		else local tdf = `df_ov'			
		
		* Test statistic and distribution
		// chi2 distribution
		if "`chi2'"!="" {
			local testDist "chi{c 178}"
			local testStat `chi2'		// replaces default
			local pvalue = chi2tail(1, `testStat')
			local testStat_text `"%6.2f `testStat'"'
			local df_text `"" on " as res 1 as text " df,""'
		}

		// t distribution
		else if "`t'"!="" & `tdf'>0 & !missing(`tdf') {
			local testDist "t"
			local pvalue = 2*ttail(`tdf', abs(`testStat'))
			local testStat_text `"%7.3f `testStat'"'
			local df_fmt = cond("`df_kr'"!="", "%6.2f", "%3.0f")
			local df_text `"" on " as res `df_fmt' `tdf' as text " df,""'
		}
		
		// normal (z) distribution
		else {
			local testDist "z"
			local pvalue = 2*normal(-abs(`testStat'))
			local testStat_text `"%7.3f `testStat'"'
		}

		if missing(`testStat') {
			di as text "Overall{col `=`swidth'+1'}(Insufficient data)"
		}
		else {
			if `"`by'"'!=`""' & `"`subgroup'"'==`""' {
				di as text "Overall{col `=`swidth'+1'}" as res "`testDist'" as text " = " as res `testStat_text' as text `df_text' "  p = " as res %5.3f `pvalue'
			}
			else { 
				di as text _n "Test of overall `xtext'effect = " as res `null' as text ":  " as res "`testDist'" as text " = " ///
					as res `testStat_text' as text `df_text' "  p = " as res %5.3f `pvalue'			
			}
		}
	}
	
	if `"`het'"'==`""' {
	
		* Heterogeneity measures box: no subgroups
		if `"`overall'"'==`""' & (`"`by'"'==`""' | `"`subgroup'"'!=`""') {
			if "`sa'"!="" local extratext `" as res " (user-defined)""'
			di as text _n(2) "Heterogeneity Measures" `extratext'

			// Q, I2, H2
			if "`sa'"!="" {
				di as text "{hline `swidth'}{c TT}{hline 13}"
				di as text `"{col `=`swidth'+1'}{c |}{col `=`swidth'+7'}Value"'
				di as text "{hline `swidth'}{c +}{hline 13}"
			}
			else {
				local valuetxt = cond(`: word count `tausq''==0, "chi2", "Value")
				local stattxt = cond("`breslow'"!="", "Breslow-Day test", ///
					cond("`method'"=="mh", "Mantel-Haenszel Q", ///
					cond("`method'"=="peto", "Peto Q", "Cochran's Q")))
				di as text "{hline `swidth'}{c TT}{hline 35}"
				di as text `"{col `=`swidth'+1'}{c |}{col `=`swidth'+7'}`valuetxt'{col `=`swidth'+18'}df{col `=`swidth'+25'}p-value"'
				di as text "{hline `swidth'}{c +}{hline 35}"
				local qpval = chi2tail(`df_ov', `q')
				di as text "`stattxt' {col `=`swidth'+1'}{c |}{col `=`swidth'+5'}" ///
					as res %7.2f `q' "{col `=`swidth'+16'}" %3.0f `df_ov' "{col `=`swidth'+23'}" %7.3f `qpval'
			}
			if `: word count `tausq''==1 {
				di as text "I{c 178} (%) {col `=`swidth'+1'}{c |}{col `=`swidth'+4'}" as res %7.1f 100*`isq' "%"
				di as text "Modified H{c 178} {col `=`swidth'+1'}{c |}{col `=`swidth'+5'}" as res %7.3f `hsq'
				di as text "tau{c 178} {col `=`swidth'+1'}{c |}{col `=`swidth'+4'}" as res %8.4f `tausq'
			}
			else if `: word count `tausq''>1 {		// display second box with CIs for tausq etc.
				foreach x in isq hsq tausq {
					tokenize ``x''
					args `x'_est `x'_lci `x'_uci
				}
				di as text "{hline `swidth'}{c BT}{hline 35}"
				di as text _n "{hline `swidth'}{c TT}{hline 35}"
				di as text "{col `=`swidth'+1'}{c |}{col `=`swidth'+7'}Value{col `=`swidth'+15'}[`level'% Conf. Interval]"
				di as text "{hline `swidth'}{c +}{hline 35}"
				di as text "I{c 178} (%) {col `=`swidth'+1'}{c |}{col `=`swidth'+4'}" ///
					as res %7.1f 100*`isq_est' "%{col `=`swidth'+14'}" ///
					as res %7.1f 100*`isq_lci' "%{col `=`swidth'+24'}" %7.1f 100*`isq_uci' "%"
				di as text "Modified H{c 178} {col `=`swidth'+1'}{c |}{col `=`swidth'+5'}" ///
					as res %7.3f `hsq_est' "{col `=`swidth'+15'}" ///
					as res %7.3f `hsq_lci' "{col `=`swidth'+25'}" %7.3f `hsq_uci'
				di as text "tau{c 178} {col `=`swidth'+1'}{c |}{col `=`swidth'+4'}" ///
					as res %8.4f `tausq_est' "{col `=`swidth'+14'}" ///
					as res %8.4f `tausq_lci' "{col `=`swidth'+24'}" %8.4f `tausq_uci'
			}
			if "`sa'"!="" di as text "{hline `swidth'}{c BT}{hline 13}"
			else di as text "{hline `swidth'}{c BT}{hline 35}"
				
			// Display explanations
			if `: word count `tausq''>=1 {
				di as text _n `"I{c 178} = between-study variance (tau{c 178}) as a percentage of total variance"'
				di as text `"Modified H{c 178} = ratio of tau{c 178} to typical within-study variance"'
			}
		}

		* Heterogeneity measures box: subgroups (just present Q statistics)
		if `"`by'"'!=`""' & `"`subgroup'"'==`""' {

			local stattxt = cond("`breslow'"!="", "Breslow-Day homogeneity statistics", ///
				cond("`method'"=="mh", "Mantel-Haenszel Q", ///
				cond("`method'"=="peto", "Peto Q", "Cochran Q")))
			if "`breslow'"=="" local stattxt "`stattxt' statistics for heterogeneity"
			
			di as text _n(2) "`stattxt'"
			di as text "{hline `swidth'}{c TT}{hline 35}"
			di as text "{col `=`swidth'+1'}{c |}{col `=`swidth'+7'}Value{col `=`swidth'+17'}df{col `=`swidth'+24'}p-value"
			di as text "{hline `swidth'}{c +}{hline 35}"

			forvalues i=1/`nby' {
				local byi : word `i' of `bylist'
				if `"`bylab'"'!=`""' {
					local bylabi : label `bylab' `byi'
				}
				else local bylabi `"`byi'"'
				if `"`bylabi'"'!="." local bylabi = substr(`"`bylabi'"', 1, `swidth'-1)

				local Qi = `bystats'[`i', `=colnumb(`bystats', "Q")']
				local ki = `bystats'[`i', `=colnumb(`bystats', "k")']
				if !missing(`Qi') {
					local tdfi = `ki' - 1
					local qpval = chi2tail(`tdfi', `Qi')
					local dfcol = cond(`"`overall'"'==`""', 18, 16)
					di as text "`bylabi'{col `=`swidth'+1'}{c |}{col `=`swidth'+5'}" ///
						as res %7.2f `Qi' "{col `=`swidth'+`dfcol''}" %3.0f `tdfi' "{col `=`swidth'+23'}" %7.3f `qpval'
				}
				else di as text "`bylabi'{col `=`swidth'+1'}{c |}{col `=`swidth'+5'}(Insufficient data)"
			}
				
			if `"`overall'"'==`""' {
				local qpval = chi2tail(`df_ov', `q')
				di as text "Overall{col `=`swidth'+1'}{c |}{col `=`swidth'+5'}" ///
					as res %7.2f `q' "{col `=`swidth'+18'}" %3.0f `df_ov' "{col `=`swidth'+23'}" %7.3f `qpval'

				local qdiffpval = chi2tail(`nby'-1, `qdiff')
				di as text "Between{col `=`swidth'+1'}{c |}{col `=`swidth'+5'}" ///
					as res %7.2f `qdiff' "{col `=`swidth'+18'}" %3.0f `nby'-1 "{col `=`swidth'+23'}" %7.3f `qdiffpval'
					
				tempname Fstat
				scalar `Fstat' = (`qdiff'/(`nby' - 1)) / ((`q' - `qdiff')/(`df_ov' - `nby' + 1))
				local Fpval = Ftail(`nby' - 1, `k' - `nby', `Fstat')
				di as text "Between:Within (F){col `=`swidth'+1'}{c |}{col `=`swidth'+5'}" ///
					as res %7.2f `Fstat' "{col `=`swidth'+14'}" %3.0f `nby' - 1 as text "," as res %3.0f `df_ov' - `nby' + 1 "{col `=`swidth'+23'}" %7.3f `Fpval'
			}
			di as text "{hline `swidth'}{c BT}{hline 35}"
		}
	}	// end if `"`het'"'==`""'

end




**************************

* Subroutine to DrawTableAD: "spreads" titles out over multiple lines if appropriate
// Updated July 2014
// Copied directly to updated version of admetan.ado September 2015 without modification
// August 2016: identical program now used here, in forestplot.ado, and in ipdover.ado 
// May 2017: updated to accept substrings delineated by quotes (c.f. multi-line axis titles)

program define SpreadTitle, rclass

	syntax anything(name=title id="title string"), [TArget(integer 0) MAXWidth(integer 0) MAXLines(integer 0) noTRUNCate ]
	* Target = aim for this width, but allow expansion if alternative is wrapping "too early" (i.e before line is adequately filled)
	//         (may be replaced by `titlelen'/`maxlines' if `maxlines' and `notruncate' are also specified)
	* Maxwidth = absolute maximum width
	* Maxlines = maximum no. lines
	* noTruncate = don't truncate final line if "too long" (even if greater than `maxwidth')
	//             (also allows `maxlines' to adjust `target' upwards if necessary)

	if `"`title'"'==`""' {
		return scalar nlines = 0
		return scalar maxwidth = 0
		exit
	}
	
	if !`target' & !`maxwidth' & !`maxlines' {
		nois disp as err `"must specify at least one of {bf:target()}, {bf:maxwidth()} or {bf:maxlines()}"'
		exit 198
	}
	
	if `maxwidth' & !`maxlines' {
		cap assert `maxwidth'>=`target'
		if _rc {
			nois disp as err `"{bf:maxwidth()} must be greater than or equal to {bf:target()}"'
			exit 198
		}
	}
	
	// Finalise `target' and calculate `spread'
	local titlelen = length(`title')
	
	local target = cond(`target', ///
		cond(`maxlines' & "`truncate'"!="", max(`target', `titlelen'/`maxlines'), `target'), ///
		cond(`maxlines', `titlelen'/`maxlines', cond(`maxwidth', `maxwidth', .)))
	
	if missing(`target') {
		nois disp as err `"must specify at least one of {bf:target()}, {bf:maxwidth()} or {bf:maxlines()}"'
		exit 198
	}	
	
	local spread = cond(`maxlines', `maxlines', int(`titlelen'/`target') + 1)

		
	** If substrings are present, delineated by quotes, treat this as a line-break
	// Hence, need to first process each substring separately and obtain parameters,
	// then select the most appropriate overall parameters given the user-specified options,
	// and finally create the final line-by-line output strings.
	
	local line = 0
	local rest `title'

	while `"`rest'"'!=`""' {
		gettoken title rest : rest, bind qed(qed)
		if !`qed' {
			local title `"`title'`rest'"'
			local rest
		}
		
		local ++line
		local title`line' = word(`"`title'"', 1)
		local newwidth = length(`"`title`line''"')

		local count = 2
		local next = word(`"`title'"', `count')
		
		while `"`next'"' != "" {
			local check = trim(`"`title`line''"' + " " +`"`next'"')			// (potential) next iteration of `title`line''
			if length(`"`check'"') > `titlelen'/`spread' {					// if longer than ideal...
																			// ...and further from target than before, or greater than maxwidth
				if abs(length(`"`check'"')-(`titlelen'/`spread')) > abs(length(`"`title`line''"')-(`titlelen'/`spread')) ///
						| (`maxwidth' & length(`"`check'"') > `maxwidth') {
					if `maxlines' & `line'==`maxlines'  {					// if reached max no. of lines
						local title`line' `"`check'"'						//   - use next iteration anyway (to be truncated)
						continue, break										//   - break loop
					}
					else {													// otherwise:
						local ++line										//  - new line
						local title`line' `"`next'"'						//  - begin new line with next word
					}
				}
				else local title`line' `"`check'"'		// else use next iteration
				
			}
			else local title`line' `"`check'"'		// else use next iteration

			local ++count
			local next = word(`"`title'"', `count')
			local newwidth = max(`newwidth', length(`"`title`line''"'))		// update `newwidth'
		}																	// (N.B. won't be done if reached max no. of lines, as loop broken)
		
		if `maxlines' & `line'==`maxlines' continue, break					// break out of outer loop too
	}		
		

	* If last string is too long (including in above case), truncate
	if `newwidth' > `target' & "`truncate'"=="" {
		local maxwidth = cond(`maxwidth', min(`newwidth', `maxwidth'), `newwidth')
		if length(`"`title`line''"') > `maxwidth' local title`line' = substr(`"`title`line''"', 1, `maxwidth')
	}
	
	* Return strings
	forvalues i=1/`line' {
		return local title`i' = trim(`"`title`i''"')
	}
	return scalar nlines = `line'
	return scalar maxwidth = min(`newwidth', `maxwidth')
	
end





***********************************************



********************
* Mata subroutines *
********************

mata:


/* Kontopantelis's bootstrap DerSimonian-Laird estimator */
// (PLoS ONE 2013; 8(7): e69930, and also implemented in metaan)
// N.B. using originally estimated ES within the re-samples, as in Kontopantelis's paper */
void DLb(string scalar varlist, string scalar touse, string scalar wtvec,
	real scalar level, real scalar reps)
{
	// setup
	real colvector yi, se, vi, wi
	varlist = tokens(varlist)
	st_view(yi=., ., varlist[1], touse)
	if(length(yi)==0) exit(error(111))
	st_view(se=., ., varlist[2], touse)
	vi = se:^2
	wi = 1:/vi

	// calculate FE eff
	real scalar eff
	eff = mean(yi, wi)	

	// carry out bootstrap procedure
	transmorphic B, J
	real colvector report
	B = mm_bs(&ftausq(), (yi, vi), 1, reps, 0, 1, ., ., ., eff)
	J = mm_jk(&ftausq(), (yi, vi), 1, 1, ., ., ., ., ., eff)
	report = mm_bs_report(B, ("mean", "bca"), level, 0, J)

	// truncate at zero
	report = report:*(report:>0)
	
	// finalise tausq and confidence limits
	real scalar tausq
	tausq = report[1]
	st_numscalar("r(tausq)", tausq)
	st_numscalar("r(tsq_lci)", report[2])
	st_numscalar("r(tsq_uci)", report[3])
	
	// write new weights to Stata
	wi = 1:/(vi:+tausq)
	st_store(st_viewobs(yi), wtvec, wi)
}

real scalar ftausq(real matrix coeffs, real colvector weight, real scalar eff) {
	real colvector yi, vi, wi
	real scalar k, Q, c, tausq
	yi = select(coeffs[,1], weight)
	vi = select(coeffs[,2], weight)
	k = length(yi)
	wi = 1:/vi
	Q = crossdev(yi, eff, wi, yi, eff)
	c = sum(wi) - mean(wi, wi)
	tausq = max((0, (Q-(k-1))/c))
	return(tausq)
}



/* Mandel/Paule method (J Res Natl Bur Stand 1982; 87: 377-85) */
/* Generalised Q point estimate (e.g. DerSimonian & Kacker, Contemporary Clinical Trials 2007; 28: 105-114) */
/* extension to CI by Viechtbauer (Stat Med 2007; 26: 37-52) */
// ... can be shown to be equivalent to the "empirical Bayes" estimator
// (e.g. Sidik & Jonkman Stat Med 2007; 26: 1964-81)
// and converges more quickly
void MandelPaule(string scalar varlist, string scalar touse, string scalar wtvec,
	real scalar level, real rowvector iteropts)
{
	// setup
	real colvector yi, se, vi, wi
	varlist = tokens(varlist)
	st_view(yi=., ., varlist[1], touse)
	if(length(yi)==0) exit(error(111))
	st_view(se=., ., varlist[2], touse)
	vi = se:^2
	wi = 1:/vi

	real scalar maxtausq, itol, maxiter, maxtsq_uci
	maxtausq = iteropts[1]
	itol = iteropts[2]
	maxiter = iteropts[3]
	
	real scalar k, eff, Q
	k = length(yi)
	eff = mean(yi, wi)							// fixed-effects estimate
	Q = crossdev(yi, eff, wi, yi, eff)			// standard Cochran's Q heterogeneity statistic
	
	// finalise tausq (before going on to estimate confidence limits)
	real scalar rc_tausq, tausq
	rc_tausq = mm_root(tausq=., &Q_crit(), 0, maxtausq, itol, maxiter, yi, vi, k, k-1)
	st_numscalar("r(tausq)", tausq)
	st_numscalar("r(rc_tausq)", rc_tausq)

	// write new weights to Stata
	wi = 1:/(vi:+tausq)
	st_store(st_viewobs(yi), wtvec, wi)	
	
	// estimate tausq confidence limits
	real scalar Q_crit_hi, Q_crit_lo, tsq_lci, rc_tsq_lci, tsq_uci, rc_tsq_uci
	Q_crit_hi = invchi2(k-1, .5 + (level/200))	// higher critical value (0.975) to compare Q against (for *lower* bound of tausq)
	Q_crit_lo = invchi2(k-1, .5 - (level/200))	// lower critical value (0.025) to compare Q against (for *upper* bound of tausq)
	
	if (Q<Q_crit_lo) {			// if Q falls below the lower critical value, interval is set to null
		rc_tsq_lci = 2
		rc_tsq_uci = 2
		tsq_lci = 0
		tsq_uci = 0
	}	
	else {
		if (Q>Q_crit_hi) {		// Q is larger than the higher critical value, so can find lower bound using mm_root
			rc_tsq_lci = mm_root(tsq_lci=., &Q_crit(), 0, tausq - itol, itol, maxiter, yi, vi, k, Q_crit_hi)
		}
		else {
			rc_tsq_lci = 2
			tsq_lci = 0			// otherwise, the lower bound for tausq is 0
		}

		/* Now find upper bound for tausq using mm_root */
		rc_tsq_uci = mm_root(tsq_uci=., &Q_crit(), tausq + itol, 10*maxtausq, itol, maxiter, yi, vi, k, Q_crit_lo)
	}
	
	st_numscalar("r(tsq_lci)", tsq_lci)
	st_numscalar("r(tsq_uci)", tsq_uci)
	st_numscalar("r(rc_tsq_lci)", rc_tsq_lci)
	st_numscalar("r(rc_tsq_uci)", rc_tsq_uci)
}

real scalar Q_crit(real scalar tausq, real colvector yi, real colvector vi, real scalar k, real scalar crit) {
	real colvector wi
	real scalar eff, newtausq
	wi = 1:/(vi:+tausq)
	eff = mean(yi, wi)
	newtausq = (k/crit)*crossdev(yi, eff, wi, yi, eff)/sum(wi) - mean(vi, wi)	// corrected June 2015
	return(tausq - newtausq)
}


/* Confidence interval for tausq estimated using approximate Gamma distribution for Q */
/* based on paper by Biggerstaff and Tweedie (Stat Med 1997; 16: 753-768) */
// Point estimate of tausq is simply the D+L estimate
void Gamma(string scalar varlist, string scalar touse, string scalar wtvec,
	real scalar level, real rowvector iteropts, real scalar quadpts)
{
	// setup
	real colvector yi, se, vi, wi
	varlist = tokens(varlist)
	st_view(yi=., ., varlist[1], touse)
	if(length(yi)==0) exit(error(111))
	st_view(se=., ., varlist[2], touse)
	vi = se:^2
	wi = 1:/vi

	real scalar maxtausq, itol, maxiter, maxtsq_uci
	maxtausq = iteropts[1]
	itol = iteropts[2]
	maxiter = iteropts[3]

	/* Estimate variance of tausq */
	real scalar k, eff, Q, c, d, tausq_m, tausq, Q_var, tsq_var
	k = length(yi)
	eff = mean(yi, wi)					// fixed-effects estimate
	Q = crossdev(yi, eff, wi, yi, eff)	// standard Q heterogeneity statistic
	c = sum(wi) - mean(wi,wi)			// c = S1 - (S2/S1)
	d = cross(wi,wi) - 2*mean(wi:^2,wi) + (mean(wi,wi)^2)
	tausq_m = (Q - (k-1))/c				// untruncated D+L tausq

	/* Variance of Q and tausq (based on untruncated tausq) */
	Q_var = 2*(k-1) + 4*c*tausq_m + 2*d*(tausq_m^2)
	tsq_var = Q_var/(c^2)
	st_numscalar("r(tsq_var)", tsq_var)

	/* Find confidence limits for tausq */
	real scalar tsq_lci, rc_tsq_lci, tsq_uci, rc_tsq_uci
	rc_tsq_lci = mm_root(tsq_lci=., &gamma_crit(), 0, maxtausq, itol, maxiter, tausq_m, k, c, d, .5 + (level/200))
	st_numscalar("r(tsq_lci)", tsq_lci)
	st_numscalar("r(rc_tsq_lci)", rc_tsq_lci)

	rc_tsq_uci = mm_root(tsq_uci=., &gamma_crit(), tsq_lci + itol, 10*maxtausq, itol, maxiter, tausq_m, k, c, d, .5 - (level/200))
	st_numscalar("r(tsq_uci)", tsq_uci)
	st_numscalar("r(rc_tsq_uci)", rc_tsq_uci)
	
	/* Find weights and standard error for ES */
	real scalar lambda, r, se_eff
	lambda = ((k-1) + c*tausq_m)/(2*(k-1) + 4*c*tausq_m + 2*d*(tausq_m^2))
	r = ((k-1) + c*tausq_m)*lambda
	for(i=1; i<=k; i++) {
		params = (vi[i], lambda, r, c, k)
		if (i==1) wsi = integrate(&Intgrnd(), 0, ., quadpts, params)
		else wsi = wsi \ integrate(&Intgrnd(), 0, ., quadpts, params)
	}
	
	wi = wi*gammap(r, lambda*(k-1)) :+ wsi								// update weights
	st_store(st_viewobs(yi), wtvec, wi)									// write new weights to Stata

	se_eff = sqrt(sum(wi:*wi:*(vi :+ tausq_m)) / (sum(wi)^2))			// update se_eff
	st_numscalar("r(se_eff)", se_eff)									// return value to Stata
}

real scalar gamma_crit(real scalar tausq, real scalar tausq_m, real scalar k, real scalar c, real scalar d, real scalar crit) {
	real scalar lambda, r, limit
	lambda = ((k-1) + c*tausq)/(2*(k-1) + 4*c*tausq + 2*d*(tausq^2))
	r = ((k-1) + c*tausq)*lambda
	limit = lambda*(c*tausq_m + (k-1))
	return(gammap(r,limit) - crit)
}

real rowvector Intgrnd(real rowvector t, real rowvector params) {
	real scalar s, lambda, r, c, k, ans
	s = params[1,1]
	lambda = params[1,2]
	r = params[1,3]
	c = params[1,4]
	k = params[1,5]
	ans = c*(1:/(s:+t)) * (lambda^r / gamma(r)) :* (c*t :+ (k-1)):^(r-1) :* exp(-lambda*(c*t :+ (k-1)))
	return(ans)
}


/* ML + optional PL (for likelihood profiling for ES CI) */
// (N.B. pass wi back-and-forth as it needs to be calculated anyway for tausq likelihood profiling)
void MLPL(string scalar varlist, string scalar touse, string scalar wtvec,
	real scalar level, real rowvector iteropts, string scalar model)
{
	// setup
	real colvector yi, se, vi, wi, eff
	varlist = tokens(varlist)
	st_view(yi=., ., varlist[1], touse)
	if(length(yi)==0) exit(error(111))
	st_view(se=., ., varlist[2], touse)
	vi = se:^2
	wi = 1:/vi

	real scalar maxtausq, itol, maxiter, maxtsq_uci
	maxtausq = iteropts[1]
	itol = iteropts[2]
	maxiter = iteropts[3]
	
	// Iterative point estimates for tausq and ES using ML
	real scalar tausq, rc_tausq
	rc_tausq = mm_root(tausq=., &ML_est(), 0, maxtausq, itol, maxiter, yi, vi)
	st_numscalar("r(tausq)", tausq)
	st_numscalar("r(rc_tausq)", rc_tausq)

	// Update weights, and write to Stata
	wi = 1:/(vi:+tausq)
	st_store(st_viewobs(yi), wtvec, wi)
	
	// Calculate ML log-likelihood value
	real scalar ll, crit, tsq_lci, rc_tsq_lci, tsq_uci, rc_tsq_uci
	eff = mean(yi, wi)
	ll = 0.5*sum(ln(wi)) - 0.5*crossdev(yi, eff, wi, yi, eff)
	crit = ll - (invchi2(1, level/100)/2)

	// Confidence interval for tausq using likelihood profiling
	rc_tsq_lci = mm_root(tsq_lci=., &ML_profile_tausq(), 0, tausq - itol, itol, maxiter, yi, vi, crit)
	st_numscalar("r(tsq_lci)", tsq_lci)
	st_numscalar("r(rc_tsq_lci)", rc_tsq_lci)
	
	rc_tsq_uci = mm_root(tsq_uci=., &ML_profile_tausq(), tausq + itol, 10*maxtausq, itol, maxiter, yi, vi, crit)
	st_numscalar("r(tsq_uci)", tsq_uci)
	st_numscalar("r(rc_tsq_uci)", rc_tsq_uci)
	
	if (model=="pl") {
		// Confidence interval for ES using likelihood profiling
		// (use four times the ML lci and uci for search limits)
		real scalar llim, ulim
		llim = mean(yi, wi) - 4*1.96/sqrt(sum(wi))
		ulim = mean(yi, wi) + 4*1.96/sqrt(sum(wi))
		
		real scalar eff_lci, eff_uci, rc_eff_lci, rc_eff_uci
		rc_eff_lci = mm_root(eff_lci=., &ML_profile_eff(), llim, eff, itol, maxiter, yi, vi, crit, maxtausq, itol, maxiter)
		rc_eff_uci = mm_root(eff_uci=., &ML_profile_eff(), eff, ulim, itol, maxiter, yi, vi, crit, maxtausq, itol, maxiter)
		st_numscalar("r(eff_lci)", eff_lci)
		st_numscalar("r(eff_uci)", eff_uci)
		st_numscalar("r(rc_eff_lci)", rc_eff_lci)
		st_numscalar("r(rc_eff_uci)", rc_eff_uci)
	}
}

real scalar ML_est(real scalar tausq, real colvector yi, real colvector vi, | real scalar eff) {
	real colvector wi
	real scalar newtausq
	wi = 1:/(vi:+tausq)
	if (eff==.) eff = mean(yi, wi)
	newtausq = crossdev(yi, eff, wi:^2, yi, eff)/sum(wi:^2) - mean(vi, wi:^2)
	return(tausq - newtausq)
}

real scalar ML_profile_tausq(real scalar tausq, real colvector yi, real colvector vi, real scalar crit) {
	real colvector wi
	real scalar eff, ll
	wi = 1:/(vi:+tausq)
	eff = mean(yi, wi)
	ll = 0.5*sum(ln(wi)) - 0.5*crossdev(yi, eff, wi, yi, eff)
	return(ll - crit)
}

real scalar ML_profile_eff(real scalar eff, real colvector yi, real colvector vi, real scalar crit, real scalar maxtausq, real scalar itol, real scalar maxiter) {
	real colvector wi
	real scalar tausq, rc, ll
	rc = mm_root(tausq=., &ML_est(), 0, maxtausq, itol, maxiter, yi, vi, eff)
	wi = 1:/(vi:+tausq)
	ll = 0.5*sum(ln(wi)) - 0.5*crossdev(yi, eff, wi, yi, eff)
	return(ll - crit)
}


/* REML */
// (N.B. pass wi back-and-forth as it needs to be calculated anyway for tausq likelihood profiling)
void REML(string scalar varlist, string scalar touse, string scalar wtvec,
	real scalar level, real rowvector iteropts)
{
	// setup
	real colvector yi, se, vi, wi, eff
	varlist = tokens(varlist)
	st_view(yi=., ., varlist[1], touse)
	if(length(yi)==0) exit(error(111))
	st_view(se=., ., varlist[2], touse)
	vi = se:^2
	wi = 1:/vi
	
	real scalar maxtausq, itol, maxiter, maxtsq_uci
	maxtausq = iteropts[1]
	itol = iteropts[2]
	maxiter = iteropts[3]
	
	// Iterative tau-squared using REML
	real scalar tausq, rc_tausq
	rc_tausq = mm_root(tausq=., &REML_est(), 0, maxtausq, itol, maxiter, yi, vi)
	st_numscalar("r(tausq)", tausq)
	st_numscalar("r(rc_tausq)", rc_tausq)

	// Update weights, and write to Stata
	wi = 1:/(vi:+tausq)
	st_store(st_viewobs(yi), wtvec, wi)
	
	// Calculate REML log-likelihood value
	real scalar ll, tsq_lci, rc_tsq_lci, tsq_uci, rc_tsq_uci
	eff = mean(yi, wi)
	ll = 0.5*sum(ln(wi)) - 0.5*ln(sum(wi)) - 0.5*crossdev(yi, eff, wi, yi, eff)
	crit = ll - (invchi2(1, level/100)/2)

	// Confidence interval for tausq using likelihood profiling
	rc_tsq_lci = mm_root(tsq_lci=., &REML_profile_tausq(), 0, tausq - itol, itol, maxiter, yi, vi, crit)
	st_numscalar("r(tsq_lci)", tsq_lci)
	st_numscalar("r(rc_tsq_lci)", rc_tsq_lci)

	rc_tsq_uci = mm_root(tsq_uci=., &REML_profile_tausq(), tausq + itol, 10*maxtausq, itol, maxiter, yi, vi, crit)
	st_numscalar("r(tsq_uci)", tsq_uci)
	st_numscalar("r(rc_tsq_uci)", rc_tsq_uci)
}

real scalar REML_est(real scalar tausq, real colvector yi, real colvector vi) {
	real colvector wi
	real scalar eff, newtausq
	wi = 1:/(vi:+tausq)
	eff = mean(yi, wi)
	newtausq = crossdev(yi, eff, wi:^2, yi, eff)/sum(wi:^2) - mean(vi, wi:^2) + (1/sum(wi))
	return(tausq - newtausq)
}

real scalar REML_profile_tausq(real scalar tausq, real colvector yi, real colvector vi, real scalar crit) {
	real colvector wi
	real scalar eff, ll
	wi = 1:/(vi:+tausq)
	eff = mean(yi, wi)
	ll = 0.5*sum(ln(wi)) - 0.5*ln(sum(wi)) - 0.5*crossdev(yi, eff, wi, yi, eff)
	return(ll - crit)
}

end



