<pre>
.-
help for ^lms^                                         Michael Blasnik
.-
<p>
Least Median Squares Regression Fit
------------------------------------
<p>
^lms^ depvar varlist [^if^ exp] [^in^] [, ^G^en(^newvar^) ^slow^]
<p>
<p>
Description
------------
<p>
^lms^ fits a least median squares regression of varlist on depvar. Least  
Median Squares is a robust fitting approach which attempts to minimize
the median squared residual of the regression (equivalent to minimizing the 
median absolute residual). The algorithm here works by exactly fitting lines 
(or planes or hyperplanes) to random subsets of observations of size 
n=# parameters.  Based on the number of parameters, 300 to 3000 of these
random subsets are fit and the one with the minimum median residual is 
selected as best.  The algorithm is computationally intensive and
the results can vary each time the model is run (unless you set seed).  
<p>
This implementation does not, as yet, contain any estimates of the 
quality of the fit or estimated standard errors, diagnostics, etc..
The only purpose is to obtain robust estmates of coefficients.  
After estimation, you can access the coefficients in the standard way
and use ^predict^ to generate residuals and fitted values which could 
be used for identifying outliers or graphing.  
<p>
Warning: this algorithm can be quite slow.
<p>
<p>
Options
--------
<p>
^Gen(^newvar^)^ generates ^newvar^ which identifies the observations used
    in the best fit 
<p>
^slow^ increases the number of sampled replications by about four fold, 
    improving the odds that the best fit is found
<p>
<p>
Notes
------
A description of the least median of squares method is given
in Rousseeuw (1984). A user's manual for the fortran program 
PROGRESS, many examples, and the structure of the algorithm 
can be found in the book by Rousseeuw and Leroy (1987). 
<p>
This limited implementation generally follows the same fitting 
algorithm and number of sampled subsets as found in PROGRESS.  
It has not been tested by comparison to PROGRESS output and
does not include many other features of that program.  There 
is currently no provision to deal with collinearity problems which 
can occur in the sampled subsets and may lead to dropped variables.
You can simply try to run it again.
<p>
Rousseeuw, P.J. (1984), Least Median of Squares Regression,
      Journal of the American Statistical Association, 79, 871-880.
<p>
Rousseeuw, P.J. and Leroy, A.M. (1987), Robust Regression and
      Outlier Detection, Wiley-Interscience, New York.
<p>
<p>
Also see
---------
<p>
On-line:  help for other robust regression methods @qreg@ @rreg@ 
<p>
Author
-------
        Michael Blasnik
        mblas9@aol.com
</pre>