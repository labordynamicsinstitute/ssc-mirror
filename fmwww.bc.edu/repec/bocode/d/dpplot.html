<pre>
-------------------------------------------------------------------------------
help for <b>dpplot</b>
-------------------------------------------------------------------------------
<p>
<b><u>Density probability plots</u></b> 
<p>
        <b>dpplot</b> <i>varname</i> [<b>if</b> <i>exp</i>] [<b>in</b> <i>range</i>] [ <b>,</b> <b>a(</b><i>#</i><b>)</b> <b>dist(</b><i>name</i><b>)</b> <b>param(</b><i>numlist</i><b>)</b>
                 <b><u>gen</u></b><b>erate(</b><i>newvar1 newvar2</i><b>)</b> <b>line(</b><i>line_options</i><b>)</b> <i>graph_options</i>
                 <b>plot(</b><i>plot</i><b>)</b> ]
<p>
<p>
<b><u>Description</u></b>
<p>
    <b>dpplot</b> plots density probability plots for <i>varname</i> given a reference
    distribution, by default normal (Gaussian).
<p>
<p>
<b><u>Remarks</u></b>
<p>
    To establish notation, and to fix ideas with a concrete example: consider
    an observed variable <i>Y</i>, whose distribution we wish to compare with a
    normally distributed variable <i>X</i>. That variable has density function <i>f</i>(<i>X</i>),
    distribution function <i>P = F</i>(<i>X</i>) and quantile function <i>X = Q</i>(<i>P</i>).  (The
    distribution function and the quantile function are inverses of each
    other.) Clearly, this notation is fairly general and also covers other
    distributions, at least for continuous variables.
<p>
    The particular density function <i>f</i>(<i>X</i> | parameters) most pertinent to
    comparison with data for <i>Y</i> can be computed given values for its
    parameters, either estimates from data on <i>Y</i>, or parameter values chosen
    for some other good reason. In the case of a normal distribution, these
    parameters would usually be the mean and the standard deviation. Such
    density functions are often superimposed on histograms or other graphical
    displays.  In Stata, histogram has a <b>normal</b> option which adds the normal
    density curve corresponding to the mean and standard deviation of the
    data shown.
<p>
    The density function can also be computed indirectly via the quantile
    function as <i>f</i>(<i>Q</i>(<i>P</i>)). For example, if <i>P</i> were 0.5, then <i>f</i>(<i>Q</i>(0.5)) would be
    the density at the median. In practice <i>P</i> is calculated as so-called
    plotting positions <i>p_i</i> attached to values <i>y_</i>(<i>i</i>) of a sample of <i>Y</i> of size
    <i>n</i> which have rank <i>i</i>:  that is, the <i>y_</i>(<i>i</i>) are the order statistics <i>y_</i>(1)
    &lt;= ... &lt;= <i>y_</i>(<i>n</i>). One simple rule uses <i>p</i>_<i>i</i> = (<i>i</i> - 0.5) / <i>n</i>.  Most other
    rules follow one of a family (<i>i</i> - <i>a</i>) / (<i>n</i> - 2<i>a</i> + 1) indexed by <i>a</i>.
<p>
    Plotting both <i>f</i>(<i>X</i> | parameters) and <i>f</i>(<i>Q</i>(<i>P</i> = <i>p_i</i>)), calculated using
    plotting positions, versus observed <i>Y</i> gives two curves. In our example,
    the first is normal by construction and the second would be a good
    estimate of a normal density if <i>Y</i> were truly normal with the same
    parameters. In terms of Stata functions, the two curves are based on
    <b>normden(</b>(<i>X</i> - mean) / SD)<b>)</b> and <b>normden(invnorm(</b><i>p_i</i><b>))</b>. The match or
    mismatch between the curves allows graphical assessment of goodness or
    badness of fit. What is more, we can use experience from comparing
    frequency distributions, as shown on histograms, dot plots or other
    similar displays, in comparing or identifying location and scale
    differences, skewness, tail weight, tied values, gaps, outliers and so
    forth.
<p>
    Such <i>density probability plots</i> were suggested by Jones and Daly (1995).
    See also Jones (2004).  They are best seen as special-purpose plots, like
    normal quantile plots and their kin, rather than general-purpose plots,
    like histograms or dot plots.
<p>
    Extending the discussion in Jones and Daly (1995), the advantages (+) and
    limitations (-) of these plots include
<p>
        +1. No choices of binning or origin (cf. histograms, dot plots, etc.)
        or of kernel or of degree of smoothing (cf. density estimation) are
        required.
<p>
        +2. Some people find them easier to interpret than quantile-quantile
        plots.
<p>
        +3. They work well for a wide range of sample sizes. At the same
        time, as with any other method, a sample of at least moderate size is
        preferable (one rule of thumb is &gt;= 25).
<p>
        +4. If <i>X</i> has bounded support in one or both directions, then this
        should be clear on the plot.
<p>
        -1. Results may be difficult to decipher if observed and reference
        distributions differ in modality. For example, if the reference
        distribution is unimodal but the observed data hint at bimodality,
        nevertheless <i>f</i>(<i>Q</i>(<i>P</i>)) must be unimodal even though <i>f</i>(<i>Y</i>) may not be.
        Similarly, when the reference distribution is exponential, then
        <i>f</i>(<i>Q</i>(<i>P</i>)) must be monotone decreasing whatever the shape of <i>f</i>(<i>Y</i>).
<p>
        -2. It may be difficult to discern subtle differences in one or both
        tails of the observed and reference distributions.
<p>
        -3. Comparison is of a curve with a curve: some people argue that
        graphical references should where possible be linear (and ideally
        horizontal). (A linear reference is a clear advantage of quantile
        plots.)
<p>
        -4. There is no simple extension to comparison of two samples with
        each other.
<p>
    Programmers may wish to inspect the code and add code for other
    distributions.  If parameters are not estimated, then naturally their
    values must be supplied:  the order of parameters should seem natural or
    at least conventional.
<p>
<p>
<b><u>Options</u></b>
<p>
    <b>a()</b> specifies a family of plotting positions, as explained above. The
        default is 0.5. Choice of <b>a</b> is rarely material unless the sample size
        is very small, and then the exercise is moot whatever is done.
<p>
    <b>dist()</b> specifies a distribution to act as a reference.  The distributions
        implemented include <b>beta</b>, <b>exponential</b>, <b>gamma</b>, <b>Gumbel</b>, <b>lognormal</b>,
        <b>Weibull</b> and <b>normal</b>, the last being the default. <b>Gaussian</b> is a synonym
        for <b>normal</b>.
<p>
    <b>param()</b> specifies parameter values which give a reference distribution.
<p>
        With <b>dist(normal)</b> two parameters may be specified. The first is the
        mean and the second is the standard deviation.
<p>
        With <b>dist(Weibull)</b> two parameters may be specified. The first is a
        scale parameter <i>b</i> and the second a shape parameter <i>c</i>.  (The density
        function for a variable <i>x</i> is thus (<i>c</i>/<i>b</i>) (<i>x</i>/<i>b</i>)^(<i>c</i> - 1) exp(-(<i>x</i>/<i>b</i>)^<i>c</i>).)
<p>
        With <b>dist(lognormal)</b> two parameters may be specified. The first is
        the mean of logged values and the second is the standard deviation of
        logged values.
<p>
        With <b>dist(gumbel)</b> two parameters must be specified. The first is a
        scale parameter alpha and the second is a location parameter mu.
        (The density function for a variable <i>x</i> is thus (1 / alpha) * exp[-(<i>x</i>
        - mu) / alpha] * exp[-exp(-(<i>x</i> - mu) / alpha)].) gumbelfit is one
        program to estimate parameters.
<p>
        With <b>dist(gamma)</b> two parameters must be specified. The first is a
        shape parameter alpha and the second is a scale parameter beta.  (The
        density function for a variable <i>x</i> is thus [1 / (beta^alpha *
        Gamma(alpha))] <i>x</i>^(alpha - 1) exp(-<i>x</i> / beta), where Gamma() is the
        gamma function.) gammafit is one program to estimate parameters.
<p>
        With <b>dist(exponential)</b> one parameter may be specified, namely the
        mean.
<p>
        With <b>dist(beta)</b> two parameters must be specified, shape parameters
        alpha and beta.  (The density function for a variable <i>x</i> is thus [1 /
        Beta(alpha, beta)] <i>x</i>^(alpha - 1) (1 -<i>x</i>)^(beta - 1), where Beta() is
        the beta function.) betafit is one program to estimate parameters.
<p>
    <b>generate()</b> specifies two new variable names to hold the results of
        densities estimated from the data directly (as <i>f</i>() given parameters)
        and indirectly (as <i>f</i>(<i>Q</i>(<i>P</i>)) given parameters).
<p>
    <b>line(</b><i>line_options</i><b>)</b> are options of twoway mspline and twoway line, which
        may be used to control the rendition of the density function curve.
<p>
    <i>graph_options</i> are options of twoway.
<p>
    <b>plot(</b><i>plot</i><b>)</b> provides a way to add other plots to the generated graph; see
        help plot_option.
<p>
<p>
<b><u>Examples</u></b>
<p>
    . dpplot mpg
<p>
    . set obs 1000
    . gen rnd = invnorm(uniform())
    . dpplot rnd, param(0 1)
    . dpplot rnd, param(0 1) plot(histogram rnd, bcolor(none) width(0.2))
<p>
    . dpplot length, dist(lognormal) gen(density1 density2)
<p>
    . gammafit length
    . dpplot length, dist(gamma) param(`e(alpha)' `e(beta)')
<p>
<p>
<b><u>Author</u></b>
<p>
    Nicholas J. Cox, University of Durham, U.K.
    n.j.cox@durham.ac.uk
<p>
<p>
<b><u>Acknowledgements</u></b> 
<p>
    Tim Sofer found a bug.
<p>
<p>
<b><u>References</u></b> 
<p>
    Jones, M.C. 2004. Hazelton, M.L. (2003), "A graphical tool for assessing
        normality," <i>The American Statistician</i> 57: 285-288: Comment. <i>The</i>
        <i>American Statistician</i> 58: 176-177.
<p>
    Jones, M.C. and F. Daly. 1995. Density probability plots.  <i>Communications</i>
        <i>in Statistics, Simulation and Computation</i> 24: 911-927.
<p>
<p>
<b><u>Also see</u></b>
<p>
    On-line:  help for twoway, diagplots, gumbelfit (if installed), gammafit
             (if installed), betafit (if installed)
  
</pre>