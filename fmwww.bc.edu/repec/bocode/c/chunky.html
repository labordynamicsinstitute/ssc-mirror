<pre>
<b>help chunky</b>
-------------------------------------------------------------------------------
<p>
<b><u>Title</u></b>
<p>
    <b>chunky</b> -- Large text file chunking utility
<p>
<p>
<b><u>Syntax</u></b>
<p>
        <b>chunky</b> <b>using</b> <i>filename</i> [<b>,</b>[ [<b><u>p</u></b><b>eek(</b><i>#</i><b>)</b> <b><u>a</u></b><b>nalyze</b>] | [<b><u>c</u></b><b>hunksize(</b><i>#</i>.<i>#</i><b>)</b>
                <b><u>h</u></b><b>eader(</b><i>string</i><b>)</b> <b><u>s</u></b><b>tub(</b><i>string</i><b>)</b> <b>replace</b>] ]
<p>
    <i>options</i>                Description
    -------------------------------------------------------------------------
    pre-chunking options
      <b><u>p</u></b><b>eek(</b><i>#</i><b>)</b>               list the first # observations
      <b><u>a</u></b><b>nalyze</b>               checks the composition of <i>filename</i> in terms of
                             letters, numbers and special characters (which
                             can cause infiling problems)
    -------------------------------------------------------------------------
    chunking options
      <b><u>c</u></b><b>hunksize(</b><i>string</i><b>)</b>     size of chunk in bytes
      <b><u>h</u></b><b>eader(</b><i>string</i><b>)</b>        whether <i>filename</i> has a header and to include or
                             skip it
    -------------------------------------------------------------------------
    saving options
      <b><u>s</u></b><b>tub(</b><i>string</i><b>)</b>          filename stub for chunks
      <b>replace</b>               replace previously saved chunk filenames
<p>
<p>
<b><u>Description</u></b>
<p>
    Some users, especially those using 32-bit versions of Stata, may find
    themselves faced with a huge data download from a database that is too
    large for infiling.  In this situation, the huge file must be broken into
    smaller chunks that can be imported individually.
<p>
    <b>chunky</b> provides the user with two tools:
<p>
    1.  In preparation for chunking sometimes one just wants to get a sense
        of the file structure and variable names (if present) by peeking at
        just the first few lines. <b>chunky</b> can allow display of the first <i>n</i>
        lines of the file.  It can also provide a more complete analysis of
        the file including the number of observations, average line lengths
        and the presence of special characters that could be problematic for
        import.
    2.  Once the user has determined a chunking strategy, <b>chunky</b> will break
        the huge file into chunks of a size specified by the user and save
        them in serially numbered files.
<p>
    <b>chunky</b> returns the list of chunk filenames in <b>s(filelist)</b> for subsequent
    processing.
<p>
<p>
<b><u>Options</u></b>
<p>
        +--------------+
    ----+ Pre-chunking +-----------------------------------------------------
<p>
    <b><u>p</u></b><b>eek(</b><i>#</i><b>)</b> Listing the first few lines of a text file can be useful. You can
        use the type command but the <b>peek</b> option is an alternative and can be
        set to display a single line. It will display the end of line
        characters (for reference: EOL characters <i>0d0a</i> (CRLF) indicate
        Windows, <i>0a</i> (LF) Unix and <i>0d</i> (CR) Mac. <i>09</i> is the TAB character.)
<p>
    <b><u>a</u></b><b>nalyze</b> This option allows detailed examination of the input file looking
        for problems that may cause difficulty in chunking or with subsequent
        import of the chunks. <b>analyze</b> uses the hexdump routine which can
        identify the file format as binary or ascii and what operating system
        wrote the file (based on the end of line characters used) A small
        table is produced that gives rough approximations of the number of
        chunks that would be created at various <b>chunksize</b>s and the number of
        observations in each chunk.  This may help in planning one's chunking
        strategy.
<p>
    Note: The <b>peek(#)</b> and <b>analyze</b> options are intended to be used prior to
        chunking.  They may be used together but use of either of them takes
        precedent over any of the chunking commands which may still be
        specified, but will not run and a warning will be generated.
<p>
        +----------+
    ----+ Chunking +---------------------------------------------------------
<p>
    <b><u>c</u></b><b>hunksize(</b><i>#</i>.<i># </i>[[<i>k</i>|<i>kb</i>]|[<i>m</i>|<i>mb</i>]|[<i>g</i>|<i>gb</i>]]<b>)</b> The size of the chunk in bytes.
        For convenience, standard power of ten, case-insensitive, single or
        two-letter multiplier abbreviations are allowed.  When using the
        multiplier form, decimal numbers are allowed and a space can exist
        between number and multiplier.  <i>e.g.</i> 5000Kb = 5m = .005 GB
<p>
    <b><u>h</u></b><b>eader</b><b>(</b><b><u>n</u></b><b>one</b>|<b><u>i</u></b><b>nclude</b>|<b><u>s</u></b><b>kip)</b> Comma Separated Value (CSV) files frequently
        come with the variable names in the first line of the file.  For this
        type of file, the first line of names should be retained for all file
        chunks.  <b><u>h</u></b><b>eader</b><b>(</b><b><u>i</u></b><b>nclude)</b> writes out the first line of the using file
        at the beginning of each chunk.  This allows a subsequent insheet to
        be done easily on each chunk.  <b><u>h</u></b><b>eader</b><b>(</b><b><u>s</u></b><b>kip)</b> tells <b>chunky</b> that a
        header is present but to omit it. Finally, one may specify
        <b><u>h</u></b><b>eader</b><b>(</b><b><u>n</u></b><b>one)</b> to indicate the absence of a header row.  This is the
        default if <b><u>h</u></b><b>eader</b> is not specified. The header options may be
        minimally abbreviated as shown. <i>e.g.</i> h(s) h(i)
<p>
        +--------+
    ----+ Saving +-----------------------------------------------------------
<p>
    <b><u>s</u></b><b>tub(</b><i>string</i><b>)</b> Filename stub to use for individual chunks.  Stub may
        contain a directory path allowing chunks to be saved to a different
        directory (Default is to use the working directory). Chunks will be
        numbered consecutively using <i>stub</i>0001, <i>stub</i>0002, <i>stub</i>0003...
        Obviously this naming convention imposes a chunk maximum of 9999.
<p>
    <b>replace</b> Replace previously saved chunk file
<p>
    Note that if your <i>filename</i> or stub contains embedded spaces that they
      must be enclosed in double quotes.
<p>
<p>
<b><u>Examples</u></b>
<p>
   .<b>chunky using ReallyBig.csv, peek(5)</b>
<p>
   .<b>chunky using ReallyBig.csv, analyze</b>
<p>
   .<b>chunky using ReallyBig.csv, chunksize(100m) header(include) stub(part) repl</b>
<b>&gt; ace</b>
<p>
   .<b>chunky using "c:\rawfiles\dump_07_09.raw", chunksize(.5 GB) header(none) st</b>
<b>&gt; ub("07-09 data/import")</b>
<p>
<p>
<b><u>Cautions</u></b>
<p>
    This routine has not been tested in a Mac environment. Stata appears to
    be able to read and write files coming from Unix and Mac systems in a
    Windows environment but cross-OS testing has not been done at this point.
    The author welcomes any feedback in this regard.
<p>
<p>
<b><u>Notes</u></b>
<p>
    This version of <b>chunky</b> has been extensively rewritten and replaces the
    previous version which has been deprecated to become <b>chunky8</b>.  The
    routine now handles the consecutive naming of chunks and removes the need
    for the user to write the looping.  It uses a much more efficient
    chunking strategy and employs Mata functions for the file I/O.  The speed
    improvements on very large files and over network connections are very
    considerable.
<p>
    These changes have necessitated a complete change in the command syntax,
    but a single command now replaces what previously required a block of
    programming to loop through the chunks.  If a user still requires
    breaking a large file apart according to a fixed number of lines per
    chunk, chunky8 or Roy Wada's chewfile may be appropriate.
<p>
    Once the chunks have been created, it may be convenient to use an 
    infiling method appropriate to the storage format.  The returned
    s(filelist) can easily be processed:
<p>
    <b>foreach</b> <i>in_fn</i> <b>in</b> <i>`s(filelist)'</i> <b>{</b>
        <b>insheet using</b> <i>`"`in_fn'"'</i> <b>[,</b> <i>options</i> <b>]</b>
        // create a saving filename based on input filename minus the extension
        <b>local</b> save_fn  <b>= cond(regexm(</b>`"`in_fn'"',"(.*)[.].*$"<b>),regexs(</b>1<b>),</b>""<b>)</b>
        <b>if</b> `"`save_fn'"' <b>!=</b> "" <b>{</b>
            <b>save(</b><i>`"`save_fn'"'</i><b>)[,</b> <i>replace</i> <b>]</b>
            <b>}</b>
            <b>else {</b>
                <b>display</b> `"{err: Cannot extract savename from `in_fn'}"'
                <b>error</b>
                <b>}</b>
        <b>} </b>
<p>
    This will result in a number of individual data files being created.
    Subsets of data can then be appended together to create a larger working
    dataset.  A very useful tool for this purpose is Roger Newson's <b>dsconcat</b>
    (dsconcat if installed or describe dsconcat)
<p>
    Users are reminded that they can obtain a macrolist by creating an
    appropriate filemask with wildcards for use with the dir extended
    function:
<p>
    <b>local</b> my_filelist <b>: dir</b> . files "stub*.ext"
<p>
    Similarly, Nick Cox's <b>fs</b> (fs if installed or describe fs) can be used and
    returns a macrolist in r(files).
<p>
<p>
<b><u>Acknowledgements</u></b>
<p>
    I would like to thank Amresh Hanchate and Dan Blanchette for helpful
    feedback and beta-testing the routine.
<p>
<p>
<p>
<b><u>Author</u></b>
<p>
    David C. Elliott, Nova Scotia Department of Health, Halifax
</pre>